{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96699951",
   "metadata": {},
   "source": [
    "우주선 타이타닉은 한 달 전에 발사된 성간 여객선이었다. 거의 13,000명의 승객을 태운 이 배는 우리 태양계에서 인근 별을 도는 세 개의 새로 거주 가능한 외계 행성으로 이주하는 처녀 항해를 시작했습니다.\n",
    "\n",
    "첫 번째 목적지인 뜨거운 55 칸크리 E로 가는 도중에 알파 센타우리를 돌던 중 방치 않은 우주선 타이타닉은 먼지 구름 속에 숨겨진 시공간 이상과 충돌했다. 슬프게도, 그것은 1000년 전의 이름을 딴 것과 비슷한 운명을 맞이했다. 배는 온전하게 유지되었지만, 승객의 거의 절반이 대체 차원으로 이송되었습니다!\n",
    "\n",
    "승무원을 구출하고 잃어버린 승객을 회수하는 것을 돕기 위해 우주선의 손상된 컴퓨터 시스템에서 복구된 기록을 사용하여 어떤 승객이 이상에 의해 이송되었는지 예측해야 합니다.\n",
    "\n",
    "그들을 저장하고 기록을 변경하도록 도와주세요!\n",
    "\n",
    "평가\n",
    "link\n",
    "keyboard_arrow_up\n",
    "미터법\n",
    "\n",
    "제출물은 분류 정확도, 예측된 라벨의 정확한 비율에 따라 평가됩니다.\n",
    "\n",
    "제출 형식\n",
    "\n",
    "대회 제출 형식은 다음과 같은 형식의 csv 파일입니다.\n",
    "\n",
    "PassengerId,Transported\n",
    "0013_01,False\n",
    "0018_01,False\n",
    "0019_01,False\n",
    "0021_01,False\n",
    "etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da3e153",
   "metadata": {},
   "source": [
    "머신러닝 데이터 분석 파이프라인 정리\n",
    "머신러닝 프로젝트는 일반적으로 다음과 같은 체계적인 단계를 거쳐 진행됩니다:\n",
    "\n",
    "데이터 불러오기 및 초기 탐색 (Initial Data Loading & Inspection)\n",
    "\n",
    "목표: 데이터의 첫인상을 파악하고, 기본적인 구조와 문제점을 빠르게 확인합니다.\n",
    "주요 작업: df.head()로 데이터 상위 몇 줄 보기, df.info()로 컬럼별 데이터 타입과 결측치 유무 확인, df.describe()로 수치형 데이터의 통계량 요약 확인, df.isnull().sum()으로 컬럼별 결측치 개수 파악.\n",
    "EDA (Exploratory Data Analysis - 탐색적 데이터 분석)\n",
    "\n",
    "목표: 데이터를 깊이 있게 이해하고, 패턴, 관계, 이상치 등을 찾아내 모델링을 위한 인사이트를 얻습니다.\n",
    "주요 작업:\n",
    "각 피처의 분포 시각화 (히스토그램, 박스플롯 등).\n",
    "피처 간의 관계 탐색 (산점도, 상관계수 분석 등).\n",
    "피처와 타겟 변수 간의 관계 탐색 (그룹별 통계, 시각화).\n",
    "필요하다면, 상관계수 분석을 위해 최소한의 숫자 변환을 수행할 수 있습니다. 예를 들어, True/False 불리언 값을 1/0으로 바꾸거나, 범주형 문자열을 원-핫 인코딩하여 숫자로 변환하는 식이죠. 이 과정은 엄밀히 말해 전처리 단계에 속하지만, EDA를 위해 선행될 수 있습니다.\n",
    "데이터 전처리 (Data Preprocessing)\n",
    "\n",
    "목표: 원본 데이터를 머신러닝 모델이 학습할 수 있는 깨끗하고 적절한 형태로 변환합니다.\n",
    "주요 작업:\n",
    "결측치 처리: 평균, 중앙값, 최빈값, 또는 예측 모델 등으로 NaN 값을 채웁니다.\n",
    "범주형 피처 인코딩: 문자열 범주를 숫자로 변환합니다 (원-핫 인코딩, 라벨 인코딩).\n",
    "수치형 피처 스케일링/변환: 피처 값의 범위를 조정하거나(정규화, 표준화), 왜곡된 분포를 변환합니다.\n",
    "이상치 처리: 이상치를 제거하거나 변환합니다.\n",
    "피처 엔지니어링 (Feature Engineering)\n",
    "\n",
    "목표: 기존 피처들을 활용하여 모델의 성능을 향상시킬 수 있는 새로운, 더 의미 있는 피처를 생성합니다.\n",
    "주요 작업: 여러 피처를 조합하여 새 피처 만들기 (예: 객실 번호에서 갑판/측면 추출, 총 지출액 계산 등).\n",
    "데이터셋 분리 (Data Splitting)\n",
    "\n",
    "목표: 모델 학습에 사용할 데이터와 성능 검증에 사용할 데이터를 분리하여 모델의 일반화 능력을 평가합니다.\n",
    "주요 작업: train_test_split을 사용하여 학습 데이터, 검증 데이터, 테스트 데이터로 나눕니다.\n",
    "모델 선택 및 학습 (Model Selection & Training)\n",
    "\n",
    "목표: 문제의 유형(분류, 회귀 등)에 적합한 머신러닝 모델을 선택하고, 전처리된 학습 데이터로 모델을 훈련시킵니다.\n",
    "모델 평가 및 튜닝 (Model Evaluation & Tuning)\n",
    "\n",
    "목표: 훈련된 모델이 얼마나 잘 작동하는지 평가하고, 성능을 최적화하기 위해 모델의 하이퍼파라미터를 조정합니다.\n",
    "주요 작업: 정확도, 정밀도, 재현율, F1-점수 등 다양한 평가지표를 활용하고, 교차 검증(Cross-validation)을 통해 모델의 안정성을 확인합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6454f02",
   "metadata": {},
   "source": [
    "- ML 프로세스\n",
    "0. 문제 정의\n",
    "0-1. 목표 & 제출형식\n",
    "1. 데이터 불러오기\n",
    "2. 데이터 탐색(EDA) & 전처리\n",
    "3. 특징 공학\n",
    "4. 모델 선택 & 모델 학습 (모델 피처, 타겟 피처 선정)\n",
    "5. 모델 예측 & 모델 평가\n",
    "6. 모델 튜닝\n",
    "7. 모델 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758fc626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. 목표\n",
    "# PassengerId, Transported 열을 제출\n",
    "\n",
    "# 1. 데이터 불러오기\n",
    "import pandas as pd\n",
    "train = pd.read_csv('/Users/rick/Library/Mobile Documents/com~apple~CloudDocs/Study/통계&빅데이터/Kaggle/space_ship_titanic/data/train.csv')\n",
    "target = pd.read_csv('/Users/rick/Library/Mobile Documents/com~apple~CloudDocs/Study/통계&빅데이터/Kaggle/space_ship_titanic/data/test.csv')\n",
    "\n",
    "# train.head()\n",
    "# train.info()\n",
    "# PassengerId\n",
    "# HomePlanet  \n",
    "# CryoSleep    - 냉동수면 \n",
    "# Cabin        - 객실\n",
    "# Destination  - 목적지\n",
    "# Age         \n",
    "# VIP         \n",
    "# RoomService \n",
    "# FoodCourt   \n",
    "# ShoppingMall\n",
    "# Spa         \n",
    "# VRDeck      \n",
    "# Name        \n",
    "# Transported \n",
    "\n",
    "# 2. 데이터 탐색(EDA)\n",
    "# 2.1. 결측치 확인\n",
    "#train.isnull().sum()\n",
    "# 총 개수 : 8693\n",
    "# HomePlanet      201\n",
    "# CryoSleep       217\n",
    "# Cabin           199\n",
    "# Destination     182\n",
    "# Age             179\n",
    "# VIP             203\n",
    "# RoomService     181\n",
    "# FoodCourt       183\n",
    "# ShoppingMall    208\n",
    "# Spa             183\n",
    "# VRDeck          188\n",
    "# Name            200\n",
    "# 2.2. 열 탐색\n",
    "# 2.2.1.1. 범주형 cabin 열 탐색 (deck/num/side)\n",
    "train['Cabin'].head() # B/0/P, F/0/S...\n",
    "# 2.2.1.2. cabin 열 결측치 처리\n",
    "train['Cabin_fill'] = train['Cabin'].fillna(train['Cabin'].mode()[0]) # 최빈값으로 결측치 처리\n",
    "# 2.2.1.3. Cabin_fill 열 결측치 개수 확인\n",
    "train['Cabin_fill'].isnull().sum() # 0개\n",
    "# 2.2.1.4. Cabin_fill 열에서 /로 분리하여 새로운 열 생성\n",
    "train[['Deck', 'Num', 'Side']] = train['Cabin_fill'].str.split('/', expand=True)\n",
    "train[['Deck', 'Num', 'Side']].head()\n",
    "# 2.2.1.5. Cabin_fill 열 삭제\n",
    "train = train.drop(columns=['Cabin_fill'])\n",
    "train.info() # Cabin 열 삭제, Deck, Num, Side 열 추가 확인\n",
    "# 2.2.2.1. 범주형 CryoSleep 열 탐색\n",
    "train['CryoSleep'].unique() # [False, True, nan]\n",
    "train['CryoSleep'].value_counts(dropna=False) # False 5439, True 3037, naN 217\n",
    "# 2.2.2.2. CryoSleep 열 결측치 처리\n",
    "train['CryoSleep_map'] = train['CryoSleep'].map({True:1, False:0}) # True + False + naN 값으로 object 타입으로 지정되어, True는 1, False는 0으로 매핑\n",
    "train['CryoSleep_fill'] = train['CryoSleep_map'].fillna(train['CryoSleep_map'].mode()[0]).astype(int) # 최빈값으로 결측치 처리 (최빈값이었던 False이 0으로 매핑)\n",
    "train['CryoSleep_fill'].unique()\n",
    "# 2.2.2.3. CryoSleep_map 열 삭제\n",
    "train = train.drop(columns=['CryoSleep_map'])\n",
    "train.info() # CryoSleep 열 삭제, CryoSleep_fill 열 추가 확인\n",
    "# 2.2.3.1. 범주형 deck, side 열 탐색 및 전처리 (2.2.에서 전처리 진행)\n",
    "train['Deck'].value_counts(dropna=False) #F 2794 G 2758 E 876 B 779 C 747 D 478 A 256 T 5 \n",
    "train['Side'].value_counts(dropna=False) # S 4487 P 4206 \n",
    "# 2.2.3.2. 범주형 deck, side 열 인코딩 (범주형 값들이 순서 상관없어 원-핫 인코딩 진행)\n",
    "pd.get_dummies(train['Deck'], prefix='Deck_encode', drop_first=False).head() # Deck 열 원-핫 인코딩\n",
    "pd.get_dummies(train['Side'], prefix='Side_encode', drop_first=False).head() # Side 열 원-핫 인코딩\n",
    "pd.concat(\n",
    "    [train\n",
    "    ,pd.get_dummies(train['Deck'], prefix='Deck_encode', drop_first=False)\n",
    "    ,pd.get_dummies(train['Side'], prefix='Side_encode', drop_first=False)]\n",
    "    ,axis=1\n",
    ") # train에 인코딩된 열 추가(axis=1), 컬럼 새로 만들고, 원본 유지) 확인\n",
    "train = pd.concat(\n",
    "            [train\n",
    "            ,pd.get_dummies(train['Deck'], prefix='Deck_encode', drop_first=False)\n",
    "            ,pd.get_dummies(train['Side'], prefix='Side_encode', drop_first=False)]\n",
    "            ,axis=1\n",
    "        ) # 확인된 데이터 train 데이터프레임에 추가\n",
    "# 2.2.3.3. 범주형 deck, side 열 인-핫 인코딩으로 bool 타입으로 변환되어 int로 타입 변경\n",
    "train_bool_cols = train.select_dtypes(include=['bool'])\n",
    "train_one_hot_Pre = [col for col in train_bool_cols if col != 'Transported'] # transported 원본 저장을 위해 따로 진행.\n",
    "train[train_one_hot_Pre] = train[train_one_hot_Pre].astype(int)\n",
    "# 2.2.4. Age, VIP 전처리\n",
    "train['Age'].describe()\n",
    "#train['Age'].isnull().sum() # 179\n",
    "train['Age_fill'] = train['Age'].fillna(train['Age'].median()) # 나이 중앙값으로 결측치 처리\n",
    "train['VIP'].describe()\n",
    "# train['VIP'].isnull().sum() # 203\n",
    "train['VIP'].value_counts() # False 8291 True 199\n",
    "train['VIP_Pre'] = train['VIP'].map({True:1, False:0}) # Bool 형 1, 0으로 매핑\n",
    "train['VIP_fill'] = train['VIP_Pre'].fillna(train['VIP_Pre'].mode()[0]) # 결측치 최빈값으로 처리\n",
    "# 2.2.5. Transported 전처리\n",
    "train['Trainsported_Pre'] = train['Transported'].map({True:1, False:0})\n",
    "# 2.2.6. Target 전처리\n",
    "target['Cabin_fill'] = target['Cabin'].fillna(target['Cabin'].mode()[0]) # 최빈값으로 결측치 처리\n",
    "target['Cabin_fill'].isnull().sum() # 0개\n",
    "target[['Deck', 'Num', 'Side']] = target['Cabin_fill'].str.split('/', expand=True)\n",
    "target[['Deck', 'Num', 'Side']].head()\n",
    "target = target.drop(columns=['Cabin_fill'])\n",
    "target.info() # Cabin 열 삭제, Deck, Num, Side 열 추가 확인\n",
    "target['CryoSleep'].unique() # [False, True, nan]\n",
    "target['CryoSleep'].value_counts(dropna=False) # False 5439, True 3037, naN 217\n",
    "target['CryoSleep_map'] = target['CryoSleep'].map({True:1, False:0}) # True + False + naN 값으로 object 타입으로 지정되어, True는 1, False는 0으로 매핑\n",
    "target['CryoSleep_fill'] = target['CryoSleep_map'].fillna(target['CryoSleep_map'].mode()[0]).astype(int) # 최빈값으로 결측치 처리 (최빈값이었던 False이 0으로 매핑)\n",
    "target['CryoSleep_fill'].unique()\n",
    "target = target.drop(columns=['CryoSleep_map'])\n",
    "target.info() # CryoSleep 열 삭제, CryoSleep_fill 열 추가 확인\n",
    "target['Deck'].value_counts(dropna=False) #F 2794 G 2758 E 876 B 779 C 747 D 478 A 256 T 5 \n",
    "target['Side'].value_counts(dropna=False) # S 4487 P 4206 \n",
    "pd.get_dummies(target['Deck'], prefix='Deck_encode', drop_first=False).head() # Deck 열 원-핫 인코딩\n",
    "pd.get_dummies(target['Side'], prefix='Side_encode', drop_first=False).head() # Side 열 원-핫 인코딩\n",
    "pd.concat(\n",
    "    [target\n",
    "    ,pd.get_dummies(target['Deck'], prefix='Deck_encode', drop_first=False)\n",
    "    ,pd.get_dummies(target['Side'], prefix='Side_encode', drop_first=False)]\n",
    "    ,axis=1\n",
    ") # target에 인코딩된 열 추가(axis=1), 컬럼 새로 만들고, 원본 유지) 확인\n",
    "target = pd.concat(\n",
    "            [target\n",
    "            ,pd.get_dummies(target['Deck'], prefix='Deck_encode', drop_first=False)\n",
    "            ,pd.get_dummies(target['Side'], prefix='Side_encode', drop_first=False)]\n",
    "            ,axis=1\n",
    "        ) # 확인된 데이터 target 데이터프레임에 추가\n",
    "target_bool_cols = target.select_dtypes(include=['bool']).columns\n",
    "target_one_hot_Pre = [col for col in target_bool_cols if col != 'Transported']\n",
    "target[target_one_hot_Pre] = target[target_one_hot_Pre].astype(int)\n",
    "target['Age'].describe()\n",
    "#target['Age'].isnull().sum() # 179\n",
    "target['Age_fill'] = target['Age'].fillna(target['Age'].median()) # 나이 중앙값으로 결측치 처리\n",
    "target['VIP'].describe()\n",
    "# target['VIP'].isnull().sum() # 203\n",
    "target['VIP'].value_counts() # False 8291 True 199\n",
    "target['VIP_Pre'] = target['VIP'].map({True:1, False:0}) # Bool 형 1, 0으로 매핑\n",
    "target['VIP_fill'] = target['VIP_Pre'].fillna(target['VIP_Pre'].mode()[0]) # 결측치 최빈값으로 처리\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# 4.1.1. 모델 선택 전 상관계수 확인 피처 선정\n",
    "train_cols_correct = ['CryoSleep_fill', 'Deck_encode_A', 'Deck_encode_B', 'Deck_encode_C', 'Deck_encode_D', 'Deck_encode_E', 'Deck_encode_F', 'Deck_encode_G', 'Deck_encode_T', 'Side_encode_P', 'Side_encode_S', 'Age_fill', 'VIP_fill', 'Transported_Pre'\n",
    "] # Trainsported_Pre가 대상 피처인데 대상피처와 상관\n",
    "# 4.1.2. 상관계수 확인 피처 행렬 계산\n",
    "# correct_matrix = train[train_cols_correct].corr()\n",
    "# 4.1.3. 상관계수 행렬 히트맵 시각화\n",
    "#plt.figure(figsize=(14, 12)) # 히트맵 크기 조절\n",
    "#sns.heatmap(\n",
    "    # correct_matrix,\n",
    "    # annot=True,      # 각 셀에 상관계수 값 표시\n",
    "    # cmap='coolwarm', # 색상 팔레트 (양의 상관은 따뜻한 색, 음의 상관은 차가운 색)\n",
    "    # fmt=\".2f\",       # 소수점 둘째 자리까지 표시\n",
    "    # linewidths=.5    # 셀 간의 경계선\n",
    "#)\n",
    "# plt.title('Feature Correlation Matrix with Transported', fontsize=16)\n",
    "# plt.show()\n",
    "# 4.2. 모델 피처(X)와 타겟(y) 정의\n",
    "y = train['Trainsported_Pre'] # 전처리한 종속변수\n",
    "cols_correnct = [col for col in train_cols_correct if col != 'Transported_Pre']\n",
    "X = train[cols_correnct]\n",
    "# 상관계수 행렬 계산 시, 설정된 컬럼에서 종속변수 제외\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"X columns:\\n\", X.columns)\n",
    "\n",
    "# 4.3. 모델 선택 & 모델 학습\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# 옵션 1: RandomForestClassifier (추천 - 비선형 관계 포착에 유리)\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42) # n_estimators는 트리의 개수\n",
    "# 옵션 2: LogisticRegression (간단하고 해석 용이)\n",
    "# model = LogisticRegression(random_state=42, solver='liblinear') # solver는 알고리즘 선택, liblinear는 작은 데이터셋에 적합\n",
    "print(f\"\\n--- 모델 학습 시작 ({type(model).__name__}) ---\")\n",
    "model.fit(X, y) # train 데이터셋 전체(X, y)로 모델 학습\n",
    "print(\"--- 모델 학습 완료 ---\")\n",
    "\n",
    "# 5.1 모델 예측 수행.\n",
    "# X_test를 정의하기 위해 train에서 사용한 피처 컬럼 리스트를 재활용\n",
    "# (앞에서 정의한 features_for_X를 사용하면 됩니다)\n",
    "X_test = target[cols_correnct] # 'target'은 test.csv를 로드한 데이터프레임 이름입니다.\n",
    "print(\"\\n--- test 데이터 예측 시작 ---\")\n",
    "predictions = model.predict(X_test)\n",
    "print(\"--- test 데이터 예측 완료 ---\")\n",
    "# 예측 결과 확인 (첫 10개)\n",
    "print(\"\\nFirst 10 predictions for test data:\", predictions[:10])\n",
    "print(\"Prediction value counts:\", pd.Series(predictions).value_counts())\n",
    "# 5.2. 예측한 값 kaggle에 제출\n",
    "submission_df = pd.DataFrame({\n",
    "    'PassengerId': target['PassengerId'], # test.csv의 PassengerId 컬럼 사용\n",
    "    'Transported': predictions\n",
    "})\n",
    "# 예측 결과(0 또는 1)를 True/False (bool) 타입으로 변환\n",
    "# 1은 True로, 0은 False로 매핑합니다.\n",
    "submission_df['Transported'] = submission_df['Transported'].map({1: True, 0: False})\n",
    "# index=False는 DataFrame의 인덱스를 CSV 파일에 쓰지 않도록 합니다.\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"\\n--- submission.csv 파일이 성공적으로 생성되었습니다. ---\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0f3630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3. 예측한 값 평가지표 확인.\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "X_train = train[cols_correnct]\n",
    "# 정확도 (Accuracy)\n",
    "accuracy = accuracy_score(y, X_train)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 정밀도 (Precision), 재현율 (Recall), F1-Score\n",
    "# 각 클래스(0과 1)에 대한 지표를 보고 싶을 때 'average' 파라미터 조절 가능\n",
    "# 'weighted'는 각 클래스의 샘플 수에 따라 가중 평균\n",
    "# 'binary'는 이진 분류에서 긍정 클래스(1)에 대한 지표만 계산\n",
    "precision = precision_score(y, predictions, average='weighted')\n",
    "recall = recall_score(y, predictions, average='weighted')\n",
    "f1 = f1_score(y, predictions, average='weighted')\n",
    "\n",
    "print(f\"Precision (Weighted): {precision:.4f}\")\n",
    "print(f\"Recall (Weighted): {recall:.4f}\")\n",
    "print(f\"F1-Score (Weighted): {f1:.4f}\")\n",
    "\n",
    "# 분류 보고서 (Classification Report): 모든 지표를 한 번에 상세히 확인\n",
    "# 각 클래스별(0과 1) 정밀도, 재현율, F1-score 및 서포트(샘플 수)를 제공\n",
    "print(\"\\n--- Classification Report (학습 데이터 기준) ---\")\n",
    "print(classification_report(y, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89cccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train.columns\n",
    "target.info()\n",
    "#train['VIP'].head()\n",
    "#target.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MathPython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
