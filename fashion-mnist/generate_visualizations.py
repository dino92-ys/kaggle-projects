"""
Fashion MNIST CNN ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± ìŠ¤í¬ë¦½íŠ¸

ìƒì„±ë˜ëŠ” ì´ë¯¸ì§€:
1. ìƒ˜í”Œ ì´ë¯¸ì§€ (10ê°œ ì¹´í…Œê³ ë¦¬ë³„)
2. í•™ìŠµ ê³¡ì„  (accuracy & loss)
3. í˜¼ë™ í–‰ë ¬ (Confusion Matrix)

ëª¨ë“  ì´ë¯¸ì§€ëŠ” images/ í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤.
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.metrics import confusion_matrix
import os

# í•œê¸€ í°íŠ¸ ì„¤ì • (Mac)
plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False

# ì´ë¯¸ì§€ ì €ì¥ í´ë” ìƒì„±
os.makedirs('images', exist_ok=True)

# ============================================================
# 1. ë°ì´í„° ë¡œë”©
# ============================================================
print("ğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘...")

train_images_path = 'data/train-images-idx3-ubyte'
train_labels_path = 'data/train-labels-idx1-ubyte'
test_images_path = 'data/t10k-images-idx3-ubyte'
test_labels_path = 'data/t10k-labels-idx1-ubyte'

def load_mnist_images(path: str):
    with open(path, 'rb') as f:
        data = np.frombuffer(f.read(), dtype=np.uint8, offset=16)
    return data.reshape(-1, 28, 28)

def load_mnist_labels(path: str):
    with open(path, 'rb') as f:
        return np.frombuffer(f.read(), dtype=np.uint8, offset=8)

train_images = load_mnist_images(train_images_path)
train_labels = load_mnist_labels(train_labels_path)
test_images = load_mnist_images(test_images_path)
test_labels = load_mnist_labels(test_labels_path)

print(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: í›ˆë ¨ {len(train_images)}ê°œ, í…ŒìŠ¤íŠ¸ {len(test_images)}ê°œ")

# ============================================================
# 2. ë°ì´í„° ì „ì²˜ë¦¬
# ============================================================
print("ğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")

train_images_normalized = train_images.astype(np.float32) / 255.0
test_images_normalized = test_images.astype(np.float32) / 255.0

train_images_normalized = train_images_normalized[:, np.newaxis, :, :]
test_images_normalized = test_images_normalized[:, np.newaxis, :, :]

print("âœ… ì „ì²˜ë¦¬ ì™„ë£Œ")

# ============================================================
# 3. CNN ëª¨ë¸ ì •ì˜
# ============================================================
class FashionMNISTCNN(nn.Module):
    def __init__(self):
        super(FashionMNISTCNN, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.fc1 = nn.Linear(64 * 7 * 7, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = self.conv1(x)
        x = F.relu(x)
        x = self.pool1(x)
        x = self.conv2(x)
        x = F.relu(x)
        x = self.pool2(x)
        x = x.view(-1, 64 * 7 * 7)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# ============================================================
# 4. ëª¨ë¸ í•™ìŠµ
# ============================================================
print("ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")

device = "mps" if torch.backends.mps.is_available() else "cpu"
print(f"   ì¥ì¹˜: {device}")

model = FashionMNISTCNN().to(device)
loss_function = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.0008)

# ë°ì´í„°ë¡œë” ìƒì„±
train_images_tensor = torch.from_numpy(train_images_normalized)
train_labels_tensor = torch.from_numpy(train_labels).long()
train_dataset = TensorDataset(train_images_tensor, train_labels_tensor)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)

# í•™ìŠµ history ì €ì¥
history = {
    'train_loss': [],
    'train_acc': []
}

num_epochs = 20

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for batch_idx, (images, labels) in enumerate(train_loader):
        images = images.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = loss_function(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    avg_loss = running_loss / len(train_loader)
    accuracy = 100 * correct / total

    history['train_loss'].append(avg_loss)
    history['train_acc'].append(accuracy)

    print(f"   Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%")

print("âœ… í•™ìŠµ ì™„ë£Œ!")

# ============================================================
# 5. ëª¨ë¸ í‰ê°€
# ============================================================
print("ğŸ“Š ëª¨ë¸ í‰ê°€ ì¤‘...")

test_images_tensor = torch.from_numpy(test_images_normalized)
test_labels_tensor = torch.from_numpy(test_labels).long()
test_dataset = TensorDataset(test_images_tensor, test_labels_tensor)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

model.eval()
correct_predictions = 0
total_samples = 0
all_predictions = []
all_labels = []

with torch.no_grad():
    for images, labels in test_loader:
        images = images.to(device)
        labels = labels.to(device)

        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)

        total_samples += labels.size(0)
        correct_predictions += (predicted == labels).sum().item()

        all_predictions.extend(predicted.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

accuracy = 100 * correct_predictions / total_samples
print(f"âœ… í…ŒìŠ¤íŠ¸ ì •í™•ë„: {accuracy:.2f}%")

# ============================================================
# 6. ì‹œê°í™” 1: ìƒ˜í”Œ ì´ë¯¸ì§€ (10ê°œ ì¹´í…Œê³ ë¦¬)
# ============================================================
print("ğŸ¨ ì‹œê°í™” 1: ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„± ì¤‘...")

class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

class_names_kr = ['í‹°ì…”ì¸ /íƒ‘', 'ë°”ì§€', 'í’€ì˜¤ë²„', 'ë“œë ˆìŠ¤', 'ì½”íŠ¸',
                  'ìƒŒë“¤', 'ì…”ì¸ ', 'ìŠ¤ë‹ˆì»¤ì¦ˆ', 'ê°€ë°©', 'ì•µí´ë¶€ì¸ ']

fig, axes = plt.subplots(2, 5, figsize=(15, 6))
fig.suptitle('Fashion MNIST ìƒ˜í”Œ ì´ë¯¸ì§€ (ì¹´í…Œê³ ë¦¬ë³„)', fontsize=16, fontweight='bold')

for i in range(10):
    # ê° í´ë˜ìŠ¤ì˜ ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ì°¾ê¸°
    idx = np.where(train_labels == i)[0][0]
    ax = axes[i // 5, i % 5]
    ax.imshow(train_images[idx], cmap='gray')
    ax.set_title(f'{i}: {class_names_kr[i]}', fontsize=11)
    ax.axis('off')

plt.tight_layout()
plt.savefig('images/ìƒ˜í”Œì´ë¯¸ì§€.png', dpi=150, bbox_inches='tight')
plt.close()
print("   âœ… ì €ì¥: images/ìƒ˜í”Œì´ë¯¸ì§€.png")

# ============================================================
# 7. ì‹œê°í™” 2: í•™ìŠµ ê³¡ì„ 
# ============================================================
print("ğŸ¨ ì‹œê°í™” 2: í•™ìŠµ ê³¡ì„  ìƒì„± ì¤‘...")

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

# Loss ê·¸ë˜í”„
ax1.plot(range(1, num_epochs + 1), history['train_loss'], 'b-', linewidth=2, label='Training Loss')
ax1.set_xlabel('Epoch', fontsize=12)
ax1.set_ylabel('Loss', fontsize=12)
ax1.set_title('í•™ìŠµ ì†ì‹¤(Loss) ë³€í™”', fontsize=14, fontweight='bold')
ax1.legend()
ax1.grid(True, alpha=0.3)

# Accuracy ê·¸ë˜í”„
ax2.plot(range(1, num_epochs + 1), history['train_acc'], 'g-', linewidth=2, label='Training Accuracy')
ax2.set_xlabel('Epoch', fontsize=12)
ax2.set_ylabel('Accuracy (%)', fontsize=12)
ax2.set_title('í•™ìŠµ ì •í™•ë„(Accuracy) ë³€í™”', fontsize=14, fontweight='bold')
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('images/í•™ìŠµê³¡ì„ .png', dpi=150, bbox_inches='tight')
plt.close()
print("   âœ… ì €ì¥: images/í•™ìŠµê³¡ì„ .png")

# ============================================================
# 8. ì‹œê°í™” 3: í˜¼ë™ í–‰ë ¬
# ============================================================
print("ğŸ¨ ì‹œê°í™” 3: í˜¼ë™ í–‰ë ¬ ìƒì„± ì¤‘...")

cm = confusion_matrix(all_labels, all_predictions)

plt.figure(figsize=(12, 10))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_names_kr,
            yticklabels=class_names_kr,
            cbar_kws={'label': 'ì˜ˆì¸¡ ê°œìˆ˜'})
plt.xlabel('ì˜ˆì¸¡ ë¼ë²¨', fontsize=12)
plt.ylabel('ì‹¤ì œ ë¼ë²¨', fontsize=12)
plt.title(f'í˜¼ë™ í–‰ë ¬ (Confusion Matrix)\ní…ŒìŠ¤íŠ¸ ì •í™•ë„: {accuracy:.2f}%',
          fontsize=14, fontweight='bold')
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)
plt.tight_layout()
plt.savefig('images/í˜¼ë™í–‰ë ¬.png', dpi=150, bbox_inches='tight')
plt.close()
print("   âœ… ì €ì¥: images/í˜¼ë™í–‰ë ¬.png")

# ============================================================
# 9. ì¶”ê°€ ì‹œê°í™”: ì˜ˆì¸¡ ìƒ˜í”Œ
# ============================================================
print("ğŸ¨ ì¶”ê°€ ì‹œê°í™”: ì˜ˆì¸¡ ìƒ˜í”Œ ìƒì„± ì¤‘...")

fig, axes = plt.subplots(3, 5, figsize=(15, 9))
fig.suptitle('ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ ìƒ˜í”Œ (ì •ë‹µ vs ì˜ˆì¸¡)', fontsize=16, fontweight='bold')

# í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ëœë¤í•˜ê²Œ 15ê°œ ì„ íƒ
np.random.seed(42)
sample_indices = np.random.choice(len(test_images), 15, replace=False)

for i, idx in enumerate(sample_indices):
    ax = axes[i // 5, i % 5]
    ax.imshow(test_images[idx], cmap='gray')

    true_label = test_labels[idx]
    pred_label = all_predictions[idx]

    color = 'green' if true_label == pred_label else 'red'
    ax.set_title(f'ì‹¤ì œ: {class_names_kr[true_label]}\nì˜ˆì¸¡: {class_names_kr[pred_label]}',
                 fontsize=10, color=color, fontweight='bold')
    ax.axis('off')

plt.tight_layout()
plt.savefig('images/ì˜ˆì¸¡ìƒ˜í”Œ.png', dpi=150, bbox_inches='tight')
plt.close()
print("   âœ… ì €ì¥: images/ì˜ˆì¸¡ìƒ˜í”Œ.png")

# ============================================================
# 10. ì™„ë£Œ
# ============================================================
print("\n" + "="*60)
print("ğŸ‰ ëª¨ë“  ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!")
print("="*60)
print("\nìƒì„±ëœ íŒŒì¼:")
print("  1. images/ìƒ˜í”Œì´ë¯¸ì§€.png - 10ê°œ ì¹´í…Œê³ ë¦¬ë³„ ìƒ˜í”Œ")
print("  2. images/í•™ìŠµê³¡ì„ .png - Loss & Accuracy ë³€í™”")
print("  3. images/í˜¼ë™í–‰ë ¬.png - Confusion Matrix")
print("  4. images/ì˜ˆì¸¡ìƒ˜í”Œ.png - ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ ìƒ˜í”Œ")
print(f"\nìµœì¢… í…ŒìŠ¤íŠ¸ ì •í™•ë„: {accuracy:.2f}%")
print("\në‹¤ìŒ ë‹¨ê³„: README.md ì‘ì„±")
