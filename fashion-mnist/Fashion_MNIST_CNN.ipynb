{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae3d0d4",
   "metadata": {},
   "source": [
    " <!-- test -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33f70b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d208934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "채널 추가 후 훈련 데이터 형태:  (60000, 1, 28, 28)\n",
      "채널 추가 후 테스트 데이터 형태:  (10000, 1, 28, 28)\n",
      "Using mps device\n",
      "FashionMNISTCNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/lmw_kzfn5hq4h_p45q6m9_6r0000gn/T/ipykernel_74638/2242808179.py:189: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/miniforge3/conda-bld/libtorch_1741738245208/work/torch/csrc/utils/tensor_numpy.cpp:212.)\n",
      "  train_labels_tensor = torch.from_numpy(train_labels).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts...\n",
      "Epoch [1/20], Batch [10/938], Loss: 1.8449\n",
      "Epoch [1/20], Batch [20/938], Loss: 1.0643\n",
      "Epoch [1/20], Batch [30/938], Loss: 0.7816\n",
      "Epoch [1/20], Batch [40/938], Loss: 1.0920\n",
      "Epoch [1/20], Batch [50/938], Loss: 0.8703\n",
      "Epoch [1/20], Batch [60/938], Loss: 0.7007\n",
      "Epoch [1/20], Batch [70/938], Loss: 0.8289\n",
      "Epoch [1/20], Batch [80/938], Loss: 0.8765\n",
      "Epoch [1/20], Batch [90/938], Loss: 0.4563\n",
      "Epoch [1/20], Batch [100/938], Loss: 0.5473\n",
      "Epoch [1/20], Batch [110/938], Loss: 0.5415\n",
      "Epoch [1/20], Batch [120/938], Loss: 0.4965\n",
      "Epoch [1/20], Batch [130/938], Loss: 0.8569\n",
      "Epoch [1/20], Batch [140/938], Loss: 0.4902\n",
      "Epoch [1/20], Batch [150/938], Loss: 0.7561\n",
      "Epoch [1/20], Batch [160/938], Loss: 0.7555\n",
      "Epoch [1/20], Batch [170/938], Loss: 0.5305\n",
      "Epoch [1/20], Batch [180/938], Loss: 0.6105\n",
      "Epoch [1/20], Batch [190/938], Loss: 0.6307\n",
      "Epoch [1/20], Batch [200/938], Loss: 0.4338\n",
      "Epoch [1/20], Batch [210/938], Loss: 0.4473\n",
      "Epoch [1/20], Batch [220/938], Loss: 0.5881\n",
      "Epoch [1/20], Batch [230/938], Loss: 0.4923\n",
      "Epoch [1/20], Batch [240/938], Loss: 0.4378\n",
      "Epoch [1/20], Batch [250/938], Loss: 0.7097\n",
      "Epoch [1/20], Batch [260/938], Loss: 0.3403\n",
      "Epoch [1/20], Batch [270/938], Loss: 0.5712\n",
      "Epoch [1/20], Batch [280/938], Loss: 0.6225\n",
      "Epoch [1/20], Batch [290/938], Loss: 0.5519\n",
      "Epoch [1/20], Batch [300/938], Loss: 0.2815\n",
      "Epoch [1/20], Batch [310/938], Loss: 0.5267\n",
      "Epoch [1/20], Batch [320/938], Loss: 0.5747\n",
      "Epoch [1/20], Batch [330/938], Loss: 0.5203\n",
      "Epoch [1/20], Batch [340/938], Loss: 0.5798\n",
      "Epoch [1/20], Batch [350/938], Loss: 0.4708\n",
      "Epoch [1/20], Batch [360/938], Loss: 0.4425\n",
      "Epoch [1/20], Batch [370/938], Loss: 0.5123\n",
      "Epoch [1/20], Batch [380/938], Loss: 0.3341\n",
      "Epoch [1/20], Batch [390/938], Loss: 0.4003\n",
      "Epoch [1/20], Batch [400/938], Loss: 0.2251\n",
      "Epoch [1/20], Batch [410/938], Loss: 0.3487\n",
      "Epoch [1/20], Batch [420/938], Loss: 0.5409\n",
      "Epoch [1/20], Batch [430/938], Loss: 0.3143\n",
      "Epoch [1/20], Batch [440/938], Loss: 0.4591\n",
      "Epoch [1/20], Batch [450/938], Loss: 0.5330\n",
      "Epoch [1/20], Batch [460/938], Loss: 0.5783\n",
      "Epoch [1/20], Batch [470/938], Loss: 0.3025\n",
      "Epoch [1/20], Batch [480/938], Loss: 0.4178\n",
      "Epoch [1/20], Batch [490/938], Loss: 0.3755\n",
      "Epoch [1/20], Batch [500/938], Loss: 0.3602\n",
      "Epoch [1/20], Batch [510/938], Loss: 0.4865\n",
      "Epoch [1/20], Batch [520/938], Loss: 0.4389\n",
      "Epoch [1/20], Batch [530/938], Loss: 0.3668\n",
      "Epoch [1/20], Batch [540/938], Loss: 0.3760\n",
      "Epoch [1/20], Batch [550/938], Loss: 0.3860\n",
      "Epoch [1/20], Batch [560/938], Loss: 0.4863\n",
      "Epoch [1/20], Batch [570/938], Loss: 0.3039\n",
      "Epoch [1/20], Batch [580/938], Loss: 0.4262\n",
      "Epoch [1/20], Batch [590/938], Loss: 0.5762\n",
      "Epoch [1/20], Batch [600/938], Loss: 0.2485\n",
      "Epoch [1/20], Batch [610/938], Loss: 0.3735\n",
      "Epoch [1/20], Batch [620/938], Loss: 0.2987\n",
      "Epoch [1/20], Batch [630/938], Loss: 0.3901\n",
      "Epoch [1/20], Batch [640/938], Loss: 0.2994\n",
      "Epoch [1/20], Batch [650/938], Loss: 0.4507\n",
      "Epoch [1/20], Batch [660/938], Loss: 0.3952\n",
      "Epoch [1/20], Batch [670/938], Loss: 0.5235\n",
      "Epoch [1/20], Batch [680/938], Loss: 0.5861\n",
      "Epoch [1/20], Batch [690/938], Loss: 0.2594\n",
      "Epoch [1/20], Batch [700/938], Loss: 0.5973\n",
      "Epoch [1/20], Batch [710/938], Loss: 0.3307\n",
      "Epoch [1/20], Batch [720/938], Loss: 0.2262\n",
      "Epoch [1/20], Batch [730/938], Loss: 0.4077\n",
      "Epoch [1/20], Batch [740/938], Loss: 0.4207\n",
      "Epoch [1/20], Batch [750/938], Loss: 0.3507\n",
      "Epoch [1/20], Batch [760/938], Loss: 0.4606\n",
      "Epoch [1/20], Batch [770/938], Loss: 0.3344\n",
      "Epoch [1/20], Batch [780/938], Loss: 0.4369\n",
      "Epoch [1/20], Batch [790/938], Loss: 0.3593\n",
      "Epoch [1/20], Batch [800/938], Loss: 0.2151\n",
      "Epoch [1/20], Batch [810/938], Loss: 0.2040\n",
      "Epoch [1/20], Batch [820/938], Loss: 0.3421\n",
      "Epoch [1/20], Batch [830/938], Loss: 0.3199\n",
      "Epoch [1/20], Batch [840/938], Loss: 0.2839\n",
      "Epoch [1/20], Batch [850/938], Loss: 0.3398\n",
      "Epoch [1/20], Batch [860/938], Loss: 0.2581\n",
      "Epoch [1/20], Batch [870/938], Loss: 0.3453\n",
      "Epoch [1/20], Batch [880/938], Loss: 0.2157\n",
      "Epoch [1/20], Batch [890/938], Loss: 0.4736\n",
      "Epoch [1/20], Batch [900/938], Loss: 0.3513\n",
      "Epoch [1/20], Batch [910/938], Loss: 0.3600\n",
      "Epoch [1/20], Batch [920/938], Loss: 0.3296\n",
      "Epoch [1/20], Batch [930/938], Loss: 0.2909\n",
      "Epoch [1/20], Average Loss: 0.4804\n",
      "------------------------------------------------------------\n",
      "Epoch [2/20], Batch [10/938], Loss: 0.3465\n",
      "Epoch [2/20], Batch [20/938], Loss: 0.3414\n",
      "Epoch [2/20], Batch [30/938], Loss: 0.4280\n",
      "Epoch [2/20], Batch [40/938], Loss: 0.3078\n",
      "Epoch [2/20], Batch [50/938], Loss: 0.3412\n",
      "Epoch [2/20], Batch [60/938], Loss: 0.4827\n",
      "Epoch [2/20], Batch [70/938], Loss: 0.4246\n",
      "Epoch [2/20], Batch [80/938], Loss: 0.3426\n",
      "Epoch [2/20], Batch [90/938], Loss: 0.3019\n",
      "Epoch [2/20], Batch [100/938], Loss: 0.4103\n",
      "Epoch [2/20], Batch [110/938], Loss: 0.3159\n",
      "Epoch [2/20], Batch [120/938], Loss: 0.5163\n",
      "Epoch [2/20], Batch [130/938], Loss: 0.3645\n",
      "Epoch [2/20], Batch [140/938], Loss: 0.2436\n",
      "Epoch [2/20], Batch [150/938], Loss: 0.3038\n",
      "Epoch [2/20], Batch [160/938], Loss: 0.2864\n",
      "Epoch [2/20], Batch [170/938], Loss: 0.3130\n",
      "Epoch [2/20], Batch [180/938], Loss: 0.2667\n",
      "Epoch [2/20], Batch [190/938], Loss: 0.2009\n",
      "Epoch [2/20], Batch [200/938], Loss: 0.3170\n",
      "Epoch [2/20], Batch [210/938], Loss: 0.3192\n",
      "Epoch [2/20], Batch [220/938], Loss: 0.3464\n",
      "Epoch [2/20], Batch [230/938], Loss: 0.4033\n",
      "Epoch [2/20], Batch [240/938], Loss: 0.2567\n",
      "Epoch [2/20], Batch [250/938], Loss: 0.3389\n",
      "Epoch [2/20], Batch [260/938], Loss: 0.4074\n",
      "Epoch [2/20], Batch [270/938], Loss: 0.4318\n",
      "Epoch [2/20], Batch [280/938], Loss: 0.2308\n",
      "Epoch [2/20], Batch [290/938], Loss: 0.2523\n",
      "Epoch [2/20], Batch [300/938], Loss: 0.3330\n",
      "Epoch [2/20], Batch [310/938], Loss: 0.2383\n",
      "Epoch [2/20], Batch [320/938], Loss: 0.4294\n",
      "Epoch [2/20], Batch [330/938], Loss: 0.4179\n",
      "Epoch [2/20], Batch [340/938], Loss: 0.3919\n",
      "Epoch [2/20], Batch [350/938], Loss: 0.4789\n",
      "Epoch [2/20], Batch [360/938], Loss: 0.2745\n",
      "Epoch [2/20], Batch [370/938], Loss: 0.3567\n",
      "Epoch [2/20], Batch [380/938], Loss: 0.2942\n",
      "Epoch [2/20], Batch [390/938], Loss: 0.3166\n",
      "Epoch [2/20], Batch [400/938], Loss: 0.3958\n",
      "Epoch [2/20], Batch [410/938], Loss: 0.2129\n",
      "Epoch [2/20], Batch [420/938], Loss: 0.2048\n",
      "Epoch [2/20], Batch [430/938], Loss: 0.2478\n",
      "Epoch [2/20], Batch [440/938], Loss: 0.2977\n",
      "Epoch [2/20], Batch [450/938], Loss: 0.3073\n",
      "Epoch [2/20], Batch [460/938], Loss: 0.3330\n",
      "Epoch [2/20], Batch [470/938], Loss: 0.2250\n",
      "Epoch [2/20], Batch [480/938], Loss: 0.2796\n",
      "Epoch [2/20], Batch [490/938], Loss: 0.3596\n",
      "Epoch [2/20], Batch [500/938], Loss: 0.2680\n",
      "Epoch [2/20], Batch [510/938], Loss: 0.3113\n",
      "Epoch [2/20], Batch [520/938], Loss: 0.3416\n",
      "Epoch [2/20], Batch [530/938], Loss: 0.3159\n",
      "Epoch [2/20], Batch [540/938], Loss: 0.3516\n",
      "Epoch [2/20], Batch [550/938], Loss: 0.2779\n",
      "Epoch [2/20], Batch [560/938], Loss: 0.3670\n",
      "Epoch [2/20], Batch [570/938], Loss: 0.2507\n",
      "Epoch [2/20], Batch [580/938], Loss: 0.4612\n",
      "Epoch [2/20], Batch [590/938], Loss: 0.2670\n",
      "Epoch [2/20], Batch [600/938], Loss: 0.3298\n",
      "Epoch [2/20], Batch [610/938], Loss: 0.4232\n",
      "Epoch [2/20], Batch [620/938], Loss: 0.2169\n",
      "Epoch [2/20], Batch [630/938], Loss: 0.2191\n",
      "Epoch [2/20], Batch [640/938], Loss: 0.2337\n",
      "Epoch [2/20], Batch [650/938], Loss: 0.2260\n",
      "Epoch [2/20], Batch [660/938], Loss: 0.3554\n",
      "Epoch [2/20], Batch [670/938], Loss: 0.3109\n",
      "Epoch [2/20], Batch [680/938], Loss: 0.4276\n",
      "Epoch [2/20], Batch [690/938], Loss: 0.3632\n",
      "Epoch [2/20], Batch [700/938], Loss: 0.2358\n",
      "Epoch [2/20], Batch [710/938], Loss: 0.1590\n",
      "Epoch [2/20], Batch [720/938], Loss: 0.4705\n",
      "Epoch [2/20], Batch [730/938], Loss: 0.3177\n",
      "Epoch [2/20], Batch [740/938], Loss: 0.2203\n",
      "Epoch [2/20], Batch [750/938], Loss: 0.3472\n",
      "Epoch [2/20], Batch [760/938], Loss: 0.1600\n",
      "Epoch [2/20], Batch [770/938], Loss: 0.2489\n",
      "Epoch [2/20], Batch [780/938], Loss: 0.1632\n",
      "Epoch [2/20], Batch [790/938], Loss: 0.4283\n",
      "Epoch [2/20], Batch [800/938], Loss: 0.1806\n",
      "Epoch [2/20], Batch [810/938], Loss: 0.3197\n",
      "Epoch [2/20], Batch [820/938], Loss: 0.1983\n",
      "Epoch [2/20], Batch [830/938], Loss: 0.3470\n",
      "Epoch [2/20], Batch [840/938], Loss: 0.3395\n",
      "Epoch [2/20], Batch [850/938], Loss: 0.2546\n",
      "Epoch [2/20], Batch [860/938], Loss: 0.2791\n",
      "Epoch [2/20], Batch [870/938], Loss: 0.3682\n",
      "Epoch [2/20], Batch [880/938], Loss: 0.2284\n",
      "Epoch [2/20], Batch [890/938], Loss: 0.2225\n",
      "Epoch [2/20], Batch [900/938], Loss: 0.2772\n",
      "Epoch [2/20], Batch [910/938], Loss: 0.2122\n",
      "Epoch [2/20], Batch [920/938], Loss: 0.2532\n",
      "Epoch [2/20], Batch [930/938], Loss: 0.3617\n",
      "Epoch [2/20], Average Loss: 0.3096\n",
      "------------------------------------------------------------\n",
      "Epoch [3/20], Batch [10/938], Loss: 0.4255\n",
      "Epoch [3/20], Batch [20/938], Loss: 0.2047\n",
      "Epoch [3/20], Batch [30/938], Loss: 0.2062\n",
      "Epoch [3/20], Batch [40/938], Loss: 0.1913\n",
      "Epoch [3/20], Batch [50/938], Loss: 0.1465\n",
      "Epoch [3/20], Batch [60/938], Loss: 0.2024\n",
      "Epoch [3/20], Batch [70/938], Loss: 0.2607\n",
      "Epoch [3/20], Batch [80/938], Loss: 0.2096\n",
      "Epoch [3/20], Batch [90/938], Loss: 0.2608\n",
      "Epoch [3/20], Batch [100/938], Loss: 0.3762\n",
      "Epoch [3/20], Batch [110/938], Loss: 0.4250\n",
      "Epoch [3/20], Batch [120/938], Loss: 0.1983\n",
      "Epoch [3/20], Batch [130/938], Loss: 0.2894\n",
      "Epoch [3/20], Batch [140/938], Loss: 0.3678\n",
      "Epoch [3/20], Batch [150/938], Loss: 0.2026\n",
      "Epoch [3/20], Batch [160/938], Loss: 0.3148\n",
      "Epoch [3/20], Batch [170/938], Loss: 0.2886\n",
      "Epoch [3/20], Batch [180/938], Loss: 0.2090\n",
      "Epoch [3/20], Batch [190/938], Loss: 0.2872\n",
      "Epoch [3/20], Batch [200/938], Loss: 0.3472\n",
      "Epoch [3/20], Batch [210/938], Loss: 0.2126\n",
      "Epoch [3/20], Batch [220/938], Loss: 0.3275\n",
      "Epoch [3/20], Batch [230/938], Loss: 0.2815\n",
      "Epoch [3/20], Batch [240/938], Loss: 0.3470\n",
      "Epoch [3/20], Batch [250/938], Loss: 0.2234\n",
      "Epoch [3/20], Batch [260/938], Loss: 0.1665\n",
      "Epoch [3/20], Batch [270/938], Loss: 0.2624\n",
      "Epoch [3/20], Batch [280/938], Loss: 0.3027\n",
      "Epoch [3/20], Batch [290/938], Loss: 0.2063\n",
      "Epoch [3/20], Batch [300/938], Loss: 0.2783\n",
      "Epoch [3/20], Batch [310/938], Loss: 0.3953\n",
      "Epoch [3/20], Batch [320/938], Loss: 0.2282\n",
      "Epoch [3/20], Batch [330/938], Loss: 0.1971\n",
      "Epoch [3/20], Batch [340/938], Loss: 0.2960\n",
      "Epoch [3/20], Batch [350/938], Loss: 0.2632\n",
      "Epoch [3/20], Batch [360/938], Loss: 0.1908\n",
      "Epoch [3/20], Batch [370/938], Loss: 0.2275\n",
      "Epoch [3/20], Batch [380/938], Loss: 0.2584\n",
      "Epoch [3/20], Batch [390/938], Loss: 0.2782\n",
      "Epoch [3/20], Batch [400/938], Loss: 0.2980\n",
      "Epoch [3/20], Batch [410/938], Loss: 0.2153\n",
      "Epoch [3/20], Batch [420/938], Loss: 0.1947\n",
      "Epoch [3/20], Batch [430/938], Loss: 0.1464\n",
      "Epoch [3/20], Batch [440/938], Loss: 0.1870\n",
      "Epoch [3/20], Batch [450/938], Loss: 0.1554\n",
      "Epoch [3/20], Batch [460/938], Loss: 0.2390\n",
      "Epoch [3/20], Batch [470/938], Loss: 0.3987\n",
      "Epoch [3/20], Batch [480/938], Loss: 0.2954\n",
      "Epoch [3/20], Batch [490/938], Loss: 0.1253\n",
      "Epoch [3/20], Batch [500/938], Loss: 0.4471\n",
      "Epoch [3/20], Batch [510/938], Loss: 0.3184\n",
      "Epoch [3/20], Batch [520/938], Loss: 0.3823\n",
      "Epoch [3/20], Batch [530/938], Loss: 0.2637\n",
      "Epoch [3/20], Batch [540/938], Loss: 0.1785\n",
      "Epoch [3/20], Batch [550/938], Loss: 0.3293\n",
      "Epoch [3/20], Batch [560/938], Loss: 0.1080\n",
      "Epoch [3/20], Batch [570/938], Loss: 0.2428\n",
      "Epoch [3/20], Batch [580/938], Loss: 0.2255\n",
      "Epoch [3/20], Batch [590/938], Loss: 0.2004\n",
      "Epoch [3/20], Batch [600/938], Loss: 0.5567\n",
      "Epoch [3/20], Batch [610/938], Loss: 0.2974\n",
      "Epoch [3/20], Batch [620/938], Loss: 0.2180\n",
      "Epoch [3/20], Batch [630/938], Loss: 0.2387\n",
      "Epoch [3/20], Batch [640/938], Loss: 0.2505\n",
      "Epoch [3/20], Batch [650/938], Loss: 0.1777\n",
      "Epoch [3/20], Batch [660/938], Loss: 0.2863\n",
      "Epoch [3/20], Batch [670/938], Loss: 0.3385\n",
      "Epoch [3/20], Batch [680/938], Loss: 0.2379\n",
      "Epoch [3/20], Batch [690/938], Loss: 0.1696\n",
      "Epoch [3/20], Batch [700/938], Loss: 0.1836\n",
      "Epoch [3/20], Batch [710/938], Loss: 0.0881\n",
      "Epoch [3/20], Batch [720/938], Loss: 0.1507\n",
      "Epoch [3/20], Batch [730/938], Loss: 0.2088\n",
      "Epoch [3/20], Batch [740/938], Loss: 0.2299\n",
      "Epoch [3/20], Batch [750/938], Loss: 0.2209\n",
      "Epoch [3/20], Batch [760/938], Loss: 0.2545\n",
      "Epoch [3/20], Batch [770/938], Loss: 0.2161\n",
      "Epoch [3/20], Batch [780/938], Loss: 0.2891\n",
      "Epoch [3/20], Batch [790/938], Loss: 0.2083\n",
      "Epoch [3/20], Batch [800/938], Loss: 0.3505\n",
      "Epoch [3/20], Batch [810/938], Loss: 0.1789\n",
      "Epoch [3/20], Batch [820/938], Loss: 0.2163\n",
      "Epoch [3/20], Batch [830/938], Loss: 0.2023\n",
      "Epoch [3/20], Batch [840/938], Loss: 0.3596\n",
      "Epoch [3/20], Batch [850/938], Loss: 0.4168\n",
      "Epoch [3/20], Batch [860/938], Loss: 0.2166\n",
      "Epoch [3/20], Batch [870/938], Loss: 0.1993\n",
      "Epoch [3/20], Batch [880/938], Loss: 0.2814\n",
      "Epoch [3/20], Batch [890/938], Loss: 0.1288\n",
      "Epoch [3/20], Batch [900/938], Loss: 0.2741\n",
      "Epoch [3/20], Batch [910/938], Loss: 0.1759\n",
      "Epoch [3/20], Batch [920/938], Loss: 0.3986\n",
      "Epoch [3/20], Batch [930/938], Loss: 0.3341\n",
      "Epoch [3/20], Average Loss: 0.2614\n",
      "------------------------------------------------------------\n",
      "Epoch [4/20], Batch [10/938], Loss: 0.1909\n",
      "Epoch [4/20], Batch [20/938], Loss: 0.1942\n",
      "Epoch [4/20], Batch [30/938], Loss: 0.2018\n",
      "Epoch [4/20], Batch [40/938], Loss: 0.2422\n",
      "Epoch [4/20], Batch [50/938], Loss: 0.3497\n",
      "Epoch [4/20], Batch [60/938], Loss: 0.2486\n",
      "Epoch [4/20], Batch [70/938], Loss: 0.0696\n",
      "Epoch [4/20], Batch [80/938], Loss: 0.1559\n",
      "Epoch [4/20], Batch [90/938], Loss: 0.3323\n",
      "Epoch [4/20], Batch [100/938], Loss: 0.2409\n",
      "Epoch [4/20], Batch [110/938], Loss: 0.1852\n",
      "Epoch [4/20], Batch [120/938], Loss: 0.2468\n",
      "Epoch [4/20], Batch [130/938], Loss: 0.2546\n",
      "Epoch [4/20], Batch [140/938], Loss: 0.1884\n",
      "Epoch [4/20], Batch [150/938], Loss: 0.2804\n",
      "Epoch [4/20], Batch [160/938], Loss: 0.3227\n",
      "Epoch [4/20], Batch [170/938], Loss: 0.2628\n",
      "Epoch [4/20], Batch [180/938], Loss: 0.2439\n",
      "Epoch [4/20], Batch [190/938], Loss: 0.2608\n",
      "Epoch [4/20], Batch [200/938], Loss: 0.2461\n",
      "Epoch [4/20], Batch [210/938], Loss: 0.2408\n",
      "Epoch [4/20], Batch [220/938], Loss: 0.1813\n",
      "Epoch [4/20], Batch [230/938], Loss: 0.2159\n",
      "Epoch [4/20], Batch [240/938], Loss: 0.2142\n",
      "Epoch [4/20], Batch [250/938], Loss: 0.3542\n",
      "Epoch [4/20], Batch [260/938], Loss: 0.2837\n",
      "Epoch [4/20], Batch [270/938], Loss: 0.1883\n",
      "Epoch [4/20], Batch [280/938], Loss: 0.1997\n",
      "Epoch [4/20], Batch [290/938], Loss: 0.1918\n",
      "Epoch [4/20], Batch [300/938], Loss: 0.2154\n",
      "Epoch [4/20], Batch [310/938], Loss: 0.3772\n",
      "Epoch [4/20], Batch [320/938], Loss: 0.2041\n",
      "Epoch [4/20], Batch [330/938], Loss: 0.1012\n",
      "Epoch [4/20], Batch [340/938], Loss: 0.2356\n",
      "Epoch [4/20], Batch [350/938], Loss: 0.1317\n",
      "Epoch [4/20], Batch [360/938], Loss: 0.4133\n",
      "Epoch [4/20], Batch [370/938], Loss: 0.1840\n",
      "Epoch [4/20], Batch [380/938], Loss: 0.2891\n",
      "Epoch [4/20], Batch [390/938], Loss: 0.2076\n",
      "Epoch [4/20], Batch [400/938], Loss: 0.2002\n",
      "Epoch [4/20], Batch [410/938], Loss: 0.1948\n",
      "Epoch [4/20], Batch [420/938], Loss: 0.3627\n",
      "Epoch [4/20], Batch [430/938], Loss: 0.3176\n",
      "Epoch [4/20], Batch [440/938], Loss: 0.2183\n",
      "Epoch [4/20], Batch [450/938], Loss: 0.2219\n",
      "Epoch [4/20], Batch [460/938], Loss: 0.1994\n",
      "Epoch [4/20], Batch [470/938], Loss: 0.2760\n",
      "Epoch [4/20], Batch [480/938], Loss: 0.1742\n",
      "Epoch [4/20], Batch [490/938], Loss: 0.3087\n",
      "Epoch [4/20], Batch [500/938], Loss: 0.2119\n",
      "Epoch [4/20], Batch [510/938], Loss: 0.1986\n",
      "Epoch [4/20], Batch [520/938], Loss: 0.3409\n",
      "Epoch [4/20], Batch [530/938], Loss: 0.3758\n",
      "Epoch [4/20], Batch [540/938], Loss: 0.1429\n",
      "Epoch [4/20], Batch [550/938], Loss: 0.2788\n",
      "Epoch [4/20], Batch [560/938], Loss: 0.1535\n",
      "Epoch [4/20], Batch [570/938], Loss: 0.4194\n",
      "Epoch [4/20], Batch [580/938], Loss: 0.2252\n",
      "Epoch [4/20], Batch [590/938], Loss: 0.2495\n",
      "Epoch [4/20], Batch [600/938], Loss: 0.2112\n",
      "Epoch [4/20], Batch [610/938], Loss: 0.2036\n",
      "Epoch [4/20], Batch [620/938], Loss: 0.2162\n",
      "Epoch [4/20], Batch [630/938], Loss: 0.2874\n",
      "Epoch [4/20], Batch [640/938], Loss: 0.3703\n",
      "Epoch [4/20], Batch [650/938], Loss: 0.2661\n",
      "Epoch [4/20], Batch [660/938], Loss: 0.1907\n",
      "Epoch [4/20], Batch [670/938], Loss: 0.1985\n",
      "Epoch [4/20], Batch [680/938], Loss: 0.2286\n",
      "Epoch [4/20], Batch [690/938], Loss: 0.2392\n",
      "Epoch [4/20], Batch [700/938], Loss: 0.0811\n",
      "Epoch [4/20], Batch [710/938], Loss: 0.3077\n",
      "Epoch [4/20], Batch [720/938], Loss: 0.3783\n",
      "Epoch [4/20], Batch [730/938], Loss: 0.2745\n",
      "Epoch [4/20], Batch [740/938], Loss: 0.2761\n",
      "Epoch [4/20], Batch [750/938], Loss: 0.2085\n",
      "Epoch [4/20], Batch [760/938], Loss: 0.1909\n",
      "Epoch [4/20], Batch [770/938], Loss: 0.1752\n",
      "Epoch [4/20], Batch [780/938], Loss: 0.2436\n",
      "Epoch [4/20], Batch [790/938], Loss: 0.1248\n",
      "Epoch [4/20], Batch [800/938], Loss: 0.2396\n",
      "Epoch [4/20], Batch [810/938], Loss: 0.1811\n",
      "Epoch [4/20], Batch [820/938], Loss: 0.3050\n",
      "Epoch [4/20], Batch [830/938], Loss: 0.2742\n",
      "Epoch [4/20], Batch [840/938], Loss: 0.3130\n",
      "Epoch [4/20], Batch [850/938], Loss: 0.1336\n",
      "Epoch [4/20], Batch [860/938], Loss: 0.0686\n",
      "Epoch [4/20], Batch [870/938], Loss: 0.1972\n",
      "Epoch [4/20], Batch [880/938], Loss: 0.3051\n",
      "Epoch [4/20], Batch [890/938], Loss: 0.1954\n",
      "Epoch [4/20], Batch [900/938], Loss: 0.0680\n",
      "Epoch [4/20], Batch [910/938], Loss: 0.2533\n",
      "Epoch [4/20], Batch [920/938], Loss: 0.2007\n",
      "Epoch [4/20], Batch [930/938], Loss: 0.2817\n",
      "Epoch [4/20], Average Loss: 0.2318\n",
      "------------------------------------------------------------\n",
      "Epoch [5/20], Batch [10/938], Loss: 0.1948\n",
      "Epoch [5/20], Batch [20/938], Loss: 0.1305\n",
      "Epoch [5/20], Batch [30/938], Loss: 0.1100\n",
      "Epoch [5/20], Batch [40/938], Loss: 0.1734\n",
      "Epoch [5/20], Batch [50/938], Loss: 0.2889\n",
      "Epoch [5/20], Batch [60/938], Loss: 0.2610\n",
      "Epoch [5/20], Batch [70/938], Loss: 0.2093\n",
      "Epoch [5/20], Batch [80/938], Loss: 0.3140\n",
      "Epoch [5/20], Batch [90/938], Loss: 0.1808\n",
      "Epoch [5/20], Batch [100/938], Loss: 0.1496\n",
      "Epoch [5/20], Batch [110/938], Loss: 0.2551\n",
      "Epoch [5/20], Batch [120/938], Loss: 0.0863\n",
      "Epoch [5/20], Batch [130/938], Loss: 0.0767\n",
      "Epoch [5/20], Batch [140/938], Loss: 0.1909\n",
      "Epoch [5/20], Batch [150/938], Loss: 0.1780\n",
      "Epoch [5/20], Batch [160/938], Loss: 0.2058\n",
      "Epoch [5/20], Batch [170/938], Loss: 0.2263\n",
      "Epoch [5/20], Batch [180/938], Loss: 0.1966\n",
      "Epoch [5/20], Batch [190/938], Loss: 0.1032\n",
      "Epoch [5/20], Batch [200/938], Loss: 0.2493\n",
      "Epoch [5/20], Batch [210/938], Loss: 0.1558\n",
      "Epoch [5/20], Batch [220/938], Loss: 0.1535\n",
      "Epoch [5/20], Batch [230/938], Loss: 0.1931\n",
      "Epoch [5/20], Batch [240/938], Loss: 0.1549\n",
      "Epoch [5/20], Batch [250/938], Loss: 0.2627\n",
      "Epoch [5/20], Batch [260/938], Loss: 0.1990\n",
      "Epoch [5/20], Batch [270/938], Loss: 0.1106\n",
      "Epoch [5/20], Batch [280/938], Loss: 0.2296\n",
      "Epoch [5/20], Batch [290/938], Loss: 0.2218\n",
      "Epoch [5/20], Batch [300/938], Loss: 0.3053\n",
      "Epoch [5/20], Batch [310/938], Loss: 0.1465\n",
      "Epoch [5/20], Batch [320/938], Loss: 0.2022\n",
      "Epoch [5/20], Batch [330/938], Loss: 0.2451\n",
      "Epoch [5/20], Batch [340/938], Loss: 0.2211\n",
      "Epoch [5/20], Batch [350/938], Loss: 0.2626\n",
      "Epoch [5/20], Batch [360/938], Loss: 0.1818\n",
      "Epoch [5/20], Batch [370/938], Loss: 0.3143\n",
      "Epoch [5/20], Batch [380/938], Loss: 0.0712\n",
      "Epoch [5/20], Batch [390/938], Loss: 0.2129\n",
      "Epoch [5/20], Batch [400/938], Loss: 0.1560\n",
      "Epoch [5/20], Batch [410/938], Loss: 0.1542\n",
      "Epoch [5/20], Batch [420/938], Loss: 0.1537\n",
      "Epoch [5/20], Batch [430/938], Loss: 0.1775\n",
      "Epoch [5/20], Batch [440/938], Loss: 0.2943\n",
      "Epoch [5/20], Batch [450/938], Loss: 0.1536\n",
      "Epoch [5/20], Batch [460/938], Loss: 0.1627\n",
      "Epoch [5/20], Batch [470/938], Loss: 0.1466\n",
      "Epoch [5/20], Batch [480/938], Loss: 0.1005\n",
      "Epoch [5/20], Batch [490/938], Loss: 0.1639\n",
      "Epoch [5/20], Batch [500/938], Loss: 0.1283\n",
      "Epoch [5/20], Batch [510/938], Loss: 0.2202\n",
      "Epoch [5/20], Batch [520/938], Loss: 0.1802\n",
      "Epoch [5/20], Batch [530/938], Loss: 0.1687\n",
      "Epoch [5/20], Batch [540/938], Loss: 0.1778\n",
      "Epoch [5/20], Batch [550/938], Loss: 0.1685\n",
      "Epoch [5/20], Batch [560/938], Loss: 0.1060\n",
      "Epoch [5/20], Batch [570/938], Loss: 0.1938\n",
      "Epoch [5/20], Batch [580/938], Loss: 0.2441\n",
      "Epoch [5/20], Batch [590/938], Loss: 0.1790\n",
      "Epoch [5/20], Batch [600/938], Loss: 0.1899\n",
      "Epoch [5/20], Batch [610/938], Loss: 0.2701\n",
      "Epoch [5/20], Batch [620/938], Loss: 0.2415\n",
      "Epoch [5/20], Batch [630/938], Loss: 0.1615\n",
      "Epoch [5/20], Batch [640/938], Loss: 0.2845\n",
      "Epoch [5/20], Batch [650/938], Loss: 0.1310\n",
      "Epoch [5/20], Batch [660/938], Loss: 0.1518\n",
      "Epoch [5/20], Batch [670/938], Loss: 0.2072\n",
      "Epoch [5/20], Batch [680/938], Loss: 0.2673\n",
      "Epoch [5/20], Batch [690/938], Loss: 0.1717\n",
      "Epoch [5/20], Batch [700/938], Loss: 0.3412\n",
      "Epoch [5/20], Batch [710/938], Loss: 0.1122\n",
      "Epoch [5/20], Batch [720/938], Loss: 0.2288\n",
      "Epoch [5/20], Batch [730/938], Loss: 0.1820\n",
      "Epoch [5/20], Batch [740/938], Loss: 0.0830\n",
      "Epoch [5/20], Batch [750/938], Loss: 0.1759\n",
      "Epoch [5/20], Batch [760/938], Loss: 0.1408\n",
      "Epoch [5/20], Batch [770/938], Loss: 0.2254\n",
      "Epoch [5/20], Batch [780/938], Loss: 0.1933\n",
      "Epoch [5/20], Batch [790/938], Loss: 0.1998\n",
      "Epoch [5/20], Batch [800/938], Loss: 0.2611\n",
      "Epoch [5/20], Batch [810/938], Loss: 0.1779\n",
      "Epoch [5/20], Batch [820/938], Loss: 0.1784\n",
      "Epoch [5/20], Batch [830/938], Loss: 0.1051\n",
      "Epoch [5/20], Batch [840/938], Loss: 0.1827\n",
      "Epoch [5/20], Batch [850/938], Loss: 0.3298\n",
      "Epoch [5/20], Batch [860/938], Loss: 0.2034\n",
      "Epoch [5/20], Batch [870/938], Loss: 0.1427\n",
      "Epoch [5/20], Batch [880/938], Loss: 0.1129\n",
      "Epoch [5/20], Batch [890/938], Loss: 0.2431\n",
      "Epoch [5/20], Batch [900/938], Loss: 0.2075\n",
      "Epoch [5/20], Batch [910/938], Loss: 0.1454\n",
      "Epoch [5/20], Batch [920/938], Loss: 0.2183\n",
      "Epoch [5/20], Batch [930/938], Loss: 0.1141\n",
      "Epoch [5/20], Average Loss: 0.2075\n",
      "------------------------------------------------------------\n",
      "Epoch [6/20], Batch [10/938], Loss: 0.0790\n",
      "Epoch [6/20], Batch [20/938], Loss: 0.0890\n",
      "Epoch [6/20], Batch [30/938], Loss: 0.2165\n",
      "Epoch [6/20], Batch [40/938], Loss: 0.1569\n",
      "Epoch [6/20], Batch [50/938], Loss: 0.1488\n",
      "Epoch [6/20], Batch [60/938], Loss: 0.1349\n",
      "Epoch [6/20], Batch [70/938], Loss: 0.0965\n",
      "Epoch [6/20], Batch [80/938], Loss: 0.1183\n",
      "Epoch [6/20], Batch [90/938], Loss: 0.1681\n",
      "Epoch [6/20], Batch [100/938], Loss: 0.1499\n",
      "Epoch [6/20], Batch [110/938], Loss: 0.1518\n",
      "Epoch [6/20], Batch [120/938], Loss: 0.2221\n",
      "Epoch [6/20], Batch [130/938], Loss: 0.2340\n",
      "Epoch [6/20], Batch [140/938], Loss: 0.1874\n",
      "Epoch [6/20], Batch [150/938], Loss: 0.2431\n",
      "Epoch [6/20], Batch [160/938], Loss: 0.1561\n",
      "Epoch [6/20], Batch [170/938], Loss: 0.1461\n",
      "Epoch [6/20], Batch [180/938], Loss: 0.1979\n",
      "Epoch [6/20], Batch [190/938], Loss: 0.1133\n",
      "Epoch [6/20], Batch [200/938], Loss: 0.2300\n",
      "Epoch [6/20], Batch [210/938], Loss: 0.1021\n",
      "Epoch [6/20], Batch [220/938], Loss: 0.3624\n",
      "Epoch [6/20], Batch [230/938], Loss: 0.3048\n",
      "Epoch [6/20], Batch [240/938], Loss: 0.2265\n",
      "Epoch [6/20], Batch [250/938], Loss: 0.1701\n",
      "Epoch [6/20], Batch [260/938], Loss: 0.2405\n",
      "Epoch [6/20], Batch [270/938], Loss: 0.1892\n",
      "Epoch [6/20], Batch [280/938], Loss: 0.1719\n",
      "Epoch [6/20], Batch [290/938], Loss: 0.1402\n",
      "Epoch [6/20], Batch [300/938], Loss: 0.1166\n",
      "Epoch [6/20], Batch [310/938], Loss: 0.2460\n",
      "Epoch [6/20], Batch [320/938], Loss: 0.3411\n",
      "Epoch [6/20], Batch [330/938], Loss: 0.2071\n",
      "Epoch [6/20], Batch [340/938], Loss: 0.0981\n",
      "Epoch [6/20], Batch [350/938], Loss: 0.2072\n",
      "Epoch [6/20], Batch [360/938], Loss: 0.1461\n",
      "Epoch [6/20], Batch [370/938], Loss: 0.1286\n",
      "Epoch [6/20], Batch [380/938], Loss: 0.1557\n",
      "Epoch [6/20], Batch [390/938], Loss: 0.1828\n",
      "Epoch [6/20], Batch [400/938], Loss: 0.1479\n",
      "Epoch [6/20], Batch [410/938], Loss: 0.1965\n",
      "Epoch [6/20], Batch [420/938], Loss: 0.2356\n",
      "Epoch [6/20], Batch [430/938], Loss: 0.1281\n",
      "Epoch [6/20], Batch [440/938], Loss: 0.2140\n",
      "Epoch [6/20], Batch [450/938], Loss: 0.2644\n",
      "Epoch [6/20], Batch [460/938], Loss: 0.1506\n",
      "Epoch [6/20], Batch [470/938], Loss: 0.1608\n",
      "Epoch [6/20], Batch [480/938], Loss: 0.1969\n",
      "Epoch [6/20], Batch [490/938], Loss: 0.1424\n",
      "Epoch [6/20], Batch [500/938], Loss: 0.2417\n",
      "Epoch [6/20], Batch [510/938], Loss: 0.2193\n",
      "Epoch [6/20], Batch [520/938], Loss: 0.3147\n",
      "Epoch [6/20], Batch [530/938], Loss: 0.2000\n",
      "Epoch [6/20], Batch [540/938], Loss: 0.2407\n",
      "Epoch [6/20], Batch [550/938], Loss: 0.1493\n",
      "Epoch [6/20], Batch [560/938], Loss: 0.1283\n",
      "Epoch [6/20], Batch [570/938], Loss: 0.1040\n",
      "Epoch [6/20], Batch [580/938], Loss: 0.2454\n",
      "Epoch [6/20], Batch [590/938], Loss: 0.1078\n",
      "Epoch [6/20], Batch [600/938], Loss: 0.1396\n",
      "Epoch [6/20], Batch [610/938], Loss: 0.2217\n",
      "Epoch [6/20], Batch [620/938], Loss: 0.1917\n",
      "Epoch [6/20], Batch [630/938], Loss: 0.1825\n",
      "Epoch [6/20], Batch [640/938], Loss: 0.2601\n",
      "Epoch [6/20], Batch [650/938], Loss: 0.1632\n",
      "Epoch [6/20], Batch [660/938], Loss: 0.1411\n",
      "Epoch [6/20], Batch [670/938], Loss: 0.2276\n",
      "Epoch [6/20], Batch [680/938], Loss: 0.2074\n",
      "Epoch [6/20], Batch [690/938], Loss: 0.2164\n",
      "Epoch [6/20], Batch [700/938], Loss: 0.1144\n",
      "Epoch [6/20], Batch [710/938], Loss: 0.2345\n",
      "Epoch [6/20], Batch [720/938], Loss: 0.0737\n",
      "Epoch [6/20], Batch [730/938], Loss: 0.2504\n",
      "Epoch [6/20], Batch [740/938], Loss: 0.1374\n",
      "Epoch [6/20], Batch [750/938], Loss: 0.2758\n",
      "Epoch [6/20], Batch [760/938], Loss: 0.2548\n",
      "Epoch [6/20], Batch [770/938], Loss: 0.2513\n",
      "Epoch [6/20], Batch [780/938], Loss: 0.1039\n",
      "Epoch [6/20], Batch [790/938], Loss: 0.2365\n",
      "Epoch [6/20], Batch [800/938], Loss: 0.0663\n",
      "Epoch [6/20], Batch [810/938], Loss: 0.1958\n",
      "Epoch [6/20], Batch [820/938], Loss: 0.1435\n",
      "Epoch [6/20], Batch [830/938], Loss: 0.1027\n",
      "Epoch [6/20], Batch [840/938], Loss: 0.1556\n",
      "Epoch [6/20], Batch [850/938], Loss: 0.2084\n",
      "Epoch [6/20], Batch [860/938], Loss: 0.2207\n",
      "Epoch [6/20], Batch [870/938], Loss: 0.1271\n",
      "Epoch [6/20], Batch [880/938], Loss: 0.3524\n",
      "Epoch [6/20], Batch [890/938], Loss: 0.2290\n",
      "Epoch [6/20], Batch [900/938], Loss: 0.2204\n",
      "Epoch [6/20], Batch [910/938], Loss: 0.2106\n",
      "Epoch [6/20], Batch [920/938], Loss: 0.1376\n",
      "Epoch [6/20], Batch [930/938], Loss: 0.0662\n",
      "Epoch [6/20], Average Loss: 0.1871\n",
      "------------------------------------------------------------\n",
      "Epoch [7/20], Batch [10/938], Loss: 0.1228\n",
      "Epoch [7/20], Batch [20/938], Loss: 0.1271\n",
      "Epoch [7/20], Batch [30/938], Loss: 0.3070\n",
      "Epoch [7/20], Batch [40/938], Loss: 0.1722\n",
      "Epoch [7/20], Batch [50/938], Loss: 0.1220\n",
      "Epoch [7/20], Batch [60/938], Loss: 0.1514\n",
      "Epoch [7/20], Batch [70/938], Loss: 0.0899\n",
      "Epoch [7/20], Batch [80/938], Loss: 0.1543\n",
      "Epoch [7/20], Batch [90/938], Loss: 0.1125\n",
      "Epoch [7/20], Batch [100/938], Loss: 0.1060\n",
      "Epoch [7/20], Batch [110/938], Loss: 0.0513\n",
      "Epoch [7/20], Batch [120/938], Loss: 0.1320\n",
      "Epoch [7/20], Batch [130/938], Loss: 0.1999\n",
      "Epoch [7/20], Batch [140/938], Loss: 0.1169\n",
      "Epoch [7/20], Batch [150/938], Loss: 0.1922\n",
      "Epoch [7/20], Batch [160/938], Loss: 0.2172\n",
      "Epoch [7/20], Batch [170/938], Loss: 0.2160\n",
      "Epoch [7/20], Batch [180/938], Loss: 0.1343\n",
      "Epoch [7/20], Batch [190/938], Loss: 0.1084\n",
      "Epoch [7/20], Batch [200/938], Loss: 0.1570\n",
      "Epoch [7/20], Batch [210/938], Loss: 0.1462\n",
      "Epoch [7/20], Batch [220/938], Loss: 0.2071\n",
      "Epoch [7/20], Batch [230/938], Loss: 0.3216\n",
      "Epoch [7/20], Batch [240/938], Loss: 0.1344\n",
      "Epoch [7/20], Batch [250/938], Loss: 0.2612\n",
      "Epoch [7/20], Batch [260/938], Loss: 0.0665\n",
      "Epoch [7/20], Batch [270/938], Loss: 0.3004\n",
      "Epoch [7/20], Batch [280/938], Loss: 0.2489\n",
      "Epoch [7/20], Batch [290/938], Loss: 0.1526\n",
      "Epoch [7/20], Batch [300/938], Loss: 0.1196\n",
      "Epoch [7/20], Batch [310/938], Loss: 0.1698\n",
      "Epoch [7/20], Batch [320/938], Loss: 0.1744\n",
      "Epoch [7/20], Batch [330/938], Loss: 0.1574\n",
      "Epoch [7/20], Batch [340/938], Loss: 0.3800\n",
      "Epoch [7/20], Batch [350/938], Loss: 0.1471\n",
      "Epoch [7/20], Batch [360/938], Loss: 0.2059\n",
      "Epoch [7/20], Batch [370/938], Loss: 0.2117\n",
      "Epoch [7/20], Batch [380/938], Loss: 0.1295\n",
      "Epoch [7/20], Batch [390/938], Loss: 0.1309\n",
      "Epoch [7/20], Batch [400/938], Loss: 0.0695\n",
      "Epoch [7/20], Batch [410/938], Loss: 0.1704\n",
      "Epoch [7/20], Batch [420/938], Loss: 0.1836\n",
      "Epoch [7/20], Batch [430/938], Loss: 0.1932\n",
      "Epoch [7/20], Batch [440/938], Loss: 0.1837\n",
      "Epoch [7/20], Batch [450/938], Loss: 0.1123\n",
      "Epoch [7/20], Batch [460/938], Loss: 0.2142\n",
      "Epoch [7/20], Batch [470/938], Loss: 0.0755\n",
      "Epoch [7/20], Batch [480/938], Loss: 0.2788\n",
      "Epoch [7/20], Batch [490/938], Loss: 0.0730\n",
      "Epoch [7/20], Batch [500/938], Loss: 0.1959\n",
      "Epoch [7/20], Batch [510/938], Loss: 0.2493\n",
      "Epoch [7/20], Batch [520/938], Loss: 0.1529\n",
      "Epoch [7/20], Batch [530/938], Loss: 0.2497\n",
      "Epoch [7/20], Batch [540/938], Loss: 0.2120\n",
      "Epoch [7/20], Batch [550/938], Loss: 0.1052\n",
      "Epoch [7/20], Batch [560/938], Loss: 0.2016\n",
      "Epoch [7/20], Batch [570/938], Loss: 0.1062\n",
      "Epoch [7/20], Batch [580/938], Loss: 0.1154\n",
      "Epoch [7/20], Batch [590/938], Loss: 0.1580\n",
      "Epoch [7/20], Batch [600/938], Loss: 0.1215\n",
      "Epoch [7/20], Batch [610/938], Loss: 0.2623\n",
      "Epoch [7/20], Batch [620/938], Loss: 0.1941\n",
      "Epoch [7/20], Batch [630/938], Loss: 0.1078\n",
      "Epoch [7/20], Batch [640/938], Loss: 0.2929\n",
      "Epoch [7/20], Batch [650/938], Loss: 0.1115\n",
      "Epoch [7/20], Batch [660/938], Loss: 0.1959\n",
      "Epoch [7/20], Batch [670/938], Loss: 0.2535\n",
      "Epoch [7/20], Batch [680/938], Loss: 0.0929\n",
      "Epoch [7/20], Batch [690/938], Loss: 0.1718\n",
      "Epoch [7/20], Batch [700/938], Loss: 0.2795\n",
      "Epoch [7/20], Batch [710/938], Loss: 0.0844\n",
      "Epoch [7/20], Batch [720/938], Loss: 0.2248\n",
      "Epoch [7/20], Batch [730/938], Loss: 0.1386\n",
      "Epoch [7/20], Batch [740/938], Loss: 0.1218\n",
      "Epoch [7/20], Batch [750/938], Loss: 0.1718\n",
      "Epoch [7/20], Batch [760/938], Loss: 0.1654\n",
      "Epoch [7/20], Batch [770/938], Loss: 0.0835\n",
      "Epoch [7/20], Batch [780/938], Loss: 0.1326\n",
      "Epoch [7/20], Batch [790/938], Loss: 0.1599\n",
      "Epoch [7/20], Batch [800/938], Loss: 0.1724\n",
      "Epoch [7/20], Batch [810/938], Loss: 0.2072\n",
      "Epoch [7/20], Batch [820/938], Loss: 0.2582\n",
      "Epoch [7/20], Batch [830/938], Loss: 0.2119\n",
      "Epoch [7/20], Batch [840/938], Loss: 0.2028\n",
      "Epoch [7/20], Batch [850/938], Loss: 0.0732\n",
      "Epoch [7/20], Batch [860/938], Loss: 0.1018\n",
      "Epoch [7/20], Batch [870/938], Loss: 0.2533\n",
      "Epoch [7/20], Batch [880/938], Loss: 0.0533\n",
      "Epoch [7/20], Batch [890/938], Loss: 0.1662\n",
      "Epoch [7/20], Batch [900/938], Loss: 0.3083\n",
      "Epoch [7/20], Batch [910/938], Loss: 0.1424\n",
      "Epoch [7/20], Batch [920/938], Loss: 0.1035\n",
      "Epoch [7/20], Batch [930/938], Loss: 0.1209\n",
      "Epoch [7/20], Average Loss: 0.1692\n",
      "------------------------------------------------------------\n",
      "Epoch [8/20], Batch [10/938], Loss: 0.1974\n",
      "Epoch [8/20], Batch [20/938], Loss: 0.2222\n",
      "Epoch [8/20], Batch [30/938], Loss: 0.1380\n",
      "Epoch [8/20], Batch [40/938], Loss: 0.1115\n",
      "Epoch [8/20], Batch [50/938], Loss: 0.1113\n",
      "Epoch [8/20], Batch [60/938], Loss: 0.1722\n",
      "Epoch [8/20], Batch [70/938], Loss: 0.2203\n",
      "Epoch [8/20], Batch [80/938], Loss: 0.2870\n",
      "Epoch [8/20], Batch [90/938], Loss: 0.1340\n",
      "Epoch [8/20], Batch [100/938], Loss: 0.2932\n",
      "Epoch [8/20], Batch [110/938], Loss: 0.0323\n",
      "Epoch [8/20], Batch [120/938], Loss: 0.2806\n",
      "Epoch [8/20], Batch [130/938], Loss: 0.3545\n",
      "Epoch [8/20], Batch [140/938], Loss: 0.1469\n",
      "Epoch [8/20], Batch [150/938], Loss: 0.1845\n",
      "Epoch [8/20], Batch [160/938], Loss: 0.0673\n",
      "Epoch [8/20], Batch [170/938], Loss: 0.1761\n",
      "Epoch [8/20], Batch [180/938], Loss: 0.1904\n",
      "Epoch [8/20], Batch [190/938], Loss: 0.1914\n",
      "Epoch [8/20], Batch [200/938], Loss: 0.1684\n",
      "Epoch [8/20], Batch [210/938], Loss: 0.2323\n",
      "Epoch [8/20], Batch [220/938], Loss: 0.0835\n",
      "Epoch [8/20], Batch [230/938], Loss: 0.1796\n",
      "Epoch [8/20], Batch [240/938], Loss: 0.1188\n",
      "Epoch [8/20], Batch [250/938], Loss: 0.1786\n",
      "Epoch [8/20], Batch [260/938], Loss: 0.1324\n",
      "Epoch [8/20], Batch [270/938], Loss: 0.1413\n",
      "Epoch [8/20], Batch [280/938], Loss: 0.1755\n",
      "Epoch [8/20], Batch [290/938], Loss: 0.1147\n",
      "Epoch [8/20], Batch [300/938], Loss: 0.1070\n",
      "Epoch [8/20], Batch [310/938], Loss: 0.1405\n",
      "Epoch [8/20], Batch [320/938], Loss: 0.1990\n",
      "Epoch [8/20], Batch [330/938], Loss: 0.1062\n",
      "Epoch [8/20], Batch [340/938], Loss: 0.2358\n",
      "Epoch [8/20], Batch [350/938], Loss: 0.0785\n",
      "Epoch [8/20], Batch [360/938], Loss: 0.1577\n",
      "Epoch [8/20], Batch [370/938], Loss: 0.1395\n",
      "Epoch [8/20], Batch [380/938], Loss: 0.1975\n",
      "Epoch [8/20], Batch [390/938], Loss: 0.2335\n",
      "Epoch [8/20], Batch [400/938], Loss: 0.2501\n",
      "Epoch [8/20], Batch [410/938], Loss: 0.1503\n",
      "Epoch [8/20], Batch [420/938], Loss: 0.1660\n",
      "Epoch [8/20], Batch [430/938], Loss: 0.2466\n",
      "Epoch [8/20], Batch [440/938], Loss: 0.2535\n",
      "Epoch [8/20], Batch [450/938], Loss: 0.1137\n",
      "Epoch [8/20], Batch [460/938], Loss: 0.1274\n",
      "Epoch [8/20], Batch [470/938], Loss: 0.0767\n",
      "Epoch [8/20], Batch [480/938], Loss: 0.1348\n",
      "Epoch [8/20], Batch [490/938], Loss: 0.1983\n",
      "Epoch [8/20], Batch [500/938], Loss: 0.2000\n",
      "Epoch [8/20], Batch [510/938], Loss: 0.1255\n",
      "Epoch [8/20], Batch [520/938], Loss: 0.1739\n",
      "Epoch [8/20], Batch [530/938], Loss: 0.1912\n",
      "Epoch [8/20], Batch [540/938], Loss: 0.0743\n",
      "Epoch [8/20], Batch [550/938], Loss: 0.3215\n",
      "Epoch [8/20], Batch [560/938], Loss: 0.2526\n",
      "Epoch [8/20], Batch [570/938], Loss: 0.1797\n",
      "Epoch [8/20], Batch [580/938], Loss: 0.1663\n",
      "Epoch [8/20], Batch [590/938], Loss: 0.1115\n",
      "Epoch [8/20], Batch [600/938], Loss: 0.2106\n",
      "Epoch [8/20], Batch [610/938], Loss: 0.2471\n",
      "Epoch [8/20], Batch [620/938], Loss: 0.1595\n",
      "Epoch [8/20], Batch [630/938], Loss: 0.2216\n",
      "Epoch [8/20], Batch [640/938], Loss: 0.1822\n",
      "Epoch [8/20], Batch [650/938], Loss: 0.1556\n",
      "Epoch [8/20], Batch [660/938], Loss: 0.1521\n",
      "Epoch [8/20], Batch [670/938], Loss: 0.1042\n",
      "Epoch [8/20], Batch [680/938], Loss: 0.1841\n",
      "Epoch [8/20], Batch [690/938], Loss: 0.1652\n",
      "Epoch [8/20], Batch [700/938], Loss: 0.1374\n",
      "Epoch [8/20], Batch [710/938], Loss: 0.1251\n",
      "Epoch [8/20], Batch [720/938], Loss: 0.0878\n",
      "Epoch [8/20], Batch [730/938], Loss: 0.2074\n",
      "Epoch [8/20], Batch [740/938], Loss: 0.0897\n",
      "Epoch [8/20], Batch [750/938], Loss: 0.2778\n",
      "Epoch [8/20], Batch [760/938], Loss: 0.1134\n",
      "Epoch [8/20], Batch [770/938], Loss: 0.2169\n",
      "Epoch [8/20], Batch [780/938], Loss: 0.1315\n",
      "Epoch [8/20], Batch [790/938], Loss: 0.1211\n",
      "Epoch [8/20], Batch [800/938], Loss: 0.1670\n",
      "Epoch [8/20], Batch [810/938], Loss: 0.1940\n",
      "Epoch [8/20], Batch [820/938], Loss: 0.0971\n",
      "Epoch [8/20], Batch [830/938], Loss: 0.1164\n",
      "Epoch [8/20], Batch [840/938], Loss: 0.0925\n",
      "Epoch [8/20], Batch [850/938], Loss: 0.1360\n",
      "Epoch [8/20], Batch [860/938], Loss: 0.1023\n",
      "Epoch [8/20], Batch [870/938], Loss: 0.1779\n",
      "Epoch [8/20], Batch [880/938], Loss: 0.1564\n",
      "Epoch [8/20], Batch [890/938], Loss: 0.1042\n",
      "Epoch [8/20], Batch [900/938], Loss: 0.2628\n",
      "Epoch [8/20], Batch [910/938], Loss: 0.2430\n",
      "Epoch [8/20], Batch [920/938], Loss: 0.0997\n",
      "Epoch [8/20], Batch [930/938], Loss: 0.2204\n",
      "Epoch [8/20], Average Loss: 0.1522\n",
      "------------------------------------------------------------\n",
      "Epoch [9/20], Batch [10/938], Loss: 0.1302\n",
      "Epoch [9/20], Batch [20/938], Loss: 0.1588\n",
      "Epoch [9/20], Batch [30/938], Loss: 0.0790\n",
      "Epoch [9/20], Batch [40/938], Loss: 0.1534\n",
      "Epoch [9/20], Batch [50/938], Loss: 0.0833\n",
      "Epoch [9/20], Batch [60/938], Loss: 0.1854\n",
      "Epoch [9/20], Batch [70/938], Loss: 0.2356\n",
      "Epoch [9/20], Batch [80/938], Loss: 0.0753\n",
      "Epoch [9/20], Batch [90/938], Loss: 0.1878\n",
      "Epoch [9/20], Batch [100/938], Loss: 0.0884\n",
      "Epoch [9/20], Batch [110/938], Loss: 0.1324\n",
      "Epoch [9/20], Batch [120/938], Loss: 0.0780\n",
      "Epoch [9/20], Batch [130/938], Loss: 0.0638\n",
      "Epoch [9/20], Batch [140/938], Loss: 0.1299\n",
      "Epoch [9/20], Batch [150/938], Loss: 0.1187\n",
      "Epoch [9/20], Batch [160/938], Loss: 0.2901\n",
      "Epoch [9/20], Batch [170/938], Loss: 0.3024\n",
      "Epoch [9/20], Batch [180/938], Loss: 0.1056\n",
      "Epoch [9/20], Batch [190/938], Loss: 0.0549\n",
      "Epoch [9/20], Batch [200/938], Loss: 0.0829\n",
      "Epoch [9/20], Batch [210/938], Loss: 0.0478\n",
      "Epoch [9/20], Batch [220/938], Loss: 0.1324\n",
      "Epoch [9/20], Batch [230/938], Loss: 0.1872\n",
      "Epoch [9/20], Batch [240/938], Loss: 0.0699\n",
      "Epoch [9/20], Batch [250/938], Loss: 0.1273\n",
      "Epoch [9/20], Batch [260/938], Loss: 0.1520\n",
      "Epoch [9/20], Batch [270/938], Loss: 0.1098\n",
      "Epoch [9/20], Batch [280/938], Loss: 0.0448\n",
      "Epoch [9/20], Batch [290/938], Loss: 0.1485\n",
      "Epoch [9/20], Batch [300/938], Loss: 0.1521\n",
      "Epoch [9/20], Batch [310/938], Loss: 0.0909\n",
      "Epoch [9/20], Batch [320/938], Loss: 0.2079\n",
      "Epoch [9/20], Batch [330/938], Loss: 0.1141\n",
      "Epoch [9/20], Batch [340/938], Loss: 0.0769\n",
      "Epoch [9/20], Batch [350/938], Loss: 0.1743\n",
      "Epoch [9/20], Batch [360/938], Loss: 0.1407\n",
      "Epoch [9/20], Batch [370/938], Loss: 0.0957\n",
      "Epoch [9/20], Batch [380/938], Loss: 0.2177\n",
      "Epoch [9/20], Batch [390/938], Loss: 0.1364\n",
      "Epoch [9/20], Batch [400/938], Loss: 0.0937\n",
      "Epoch [9/20], Batch [410/938], Loss: 0.0772\n",
      "Epoch [9/20], Batch [420/938], Loss: 0.1902\n",
      "Epoch [9/20], Batch [430/938], Loss: 0.1062\n",
      "Epoch [9/20], Batch [440/938], Loss: 0.1364\n",
      "Epoch [9/20], Batch [450/938], Loss: 0.1876\n",
      "Epoch [9/20], Batch [460/938], Loss: 0.1344\n",
      "Epoch [9/20], Batch [470/938], Loss: 0.0980\n",
      "Epoch [9/20], Batch [480/938], Loss: 0.1734\n",
      "Epoch [9/20], Batch [490/938], Loss: 0.0745\n",
      "Epoch [9/20], Batch [500/938], Loss: 0.1123\n",
      "Epoch [9/20], Batch [510/938], Loss: 0.0391\n",
      "Epoch [9/20], Batch [520/938], Loss: 0.2071\n",
      "Epoch [9/20], Batch [530/938], Loss: 0.2236\n",
      "Epoch [9/20], Batch [540/938], Loss: 0.1980\n",
      "Epoch [9/20], Batch [550/938], Loss: 0.1753\n",
      "Epoch [9/20], Batch [560/938], Loss: 0.2906\n",
      "Epoch [9/20], Batch [570/938], Loss: 0.1541\n",
      "Epoch [9/20], Batch [580/938], Loss: 0.0872\n",
      "Epoch [9/20], Batch [590/938], Loss: 0.1704\n",
      "Epoch [9/20], Batch [600/938], Loss: 0.1275\n",
      "Epoch [9/20], Batch [610/938], Loss: 0.1203\n",
      "Epoch [9/20], Batch [620/938], Loss: 0.2690\n",
      "Epoch [9/20], Batch [630/938], Loss: 0.0680\n",
      "Epoch [9/20], Batch [640/938], Loss: 0.0397\n",
      "Epoch [9/20], Batch [650/938], Loss: 0.1026\n",
      "Epoch [9/20], Batch [660/938], Loss: 0.1384\n",
      "Epoch [9/20], Batch [670/938], Loss: 0.1131\n",
      "Epoch [9/20], Batch [680/938], Loss: 0.1724\n",
      "Epoch [9/20], Batch [690/938], Loss: 0.1189\n",
      "Epoch [9/20], Batch [700/938], Loss: 0.0947\n",
      "Epoch [9/20], Batch [710/938], Loss: 0.0464\n",
      "Epoch [9/20], Batch [720/938], Loss: 0.1574\n",
      "Epoch [9/20], Batch [730/938], Loss: 0.1833\n",
      "Epoch [9/20], Batch [740/938], Loss: 0.1477\n",
      "Epoch [9/20], Batch [750/938], Loss: 0.0841\n",
      "Epoch [9/20], Batch [760/938], Loss: 0.1411\n",
      "Epoch [9/20], Batch [770/938], Loss: 0.1943\n",
      "Epoch [9/20], Batch [780/938], Loss: 0.2027\n",
      "Epoch [9/20], Batch [790/938], Loss: 0.1586\n",
      "Epoch [9/20], Batch [800/938], Loss: 0.2169\n",
      "Epoch [9/20], Batch [810/938], Loss: 0.1499\n",
      "Epoch [9/20], Batch [820/938], Loss: 0.1485\n",
      "Epoch [9/20], Batch [830/938], Loss: 0.0873\n",
      "Epoch [9/20], Batch [840/938], Loss: 0.0946\n",
      "Epoch [9/20], Batch [850/938], Loss: 0.3790\n",
      "Epoch [9/20], Batch [860/938], Loss: 0.0636\n",
      "Epoch [9/20], Batch [870/938], Loss: 0.0752\n",
      "Epoch [9/20], Batch [880/938], Loss: 0.1168\n",
      "Epoch [9/20], Batch [890/938], Loss: 0.0979\n",
      "Epoch [9/20], Batch [900/938], Loss: 0.3768\n",
      "Epoch [9/20], Batch [910/938], Loss: 0.1388\n",
      "Epoch [9/20], Batch [920/938], Loss: 0.2296\n",
      "Epoch [9/20], Batch [930/938], Loss: 0.0684\n",
      "Epoch [9/20], Average Loss: 0.1361\n",
      "------------------------------------------------------------\n",
      "Epoch [10/20], Batch [10/938], Loss: 0.0480\n",
      "Epoch [10/20], Batch [20/938], Loss: 0.0241\n",
      "Epoch [10/20], Batch [30/938], Loss: 0.0814\n",
      "Epoch [10/20], Batch [40/938], Loss: 0.2078\n",
      "Epoch [10/20], Batch [50/938], Loss: 0.0557\n",
      "Epoch [10/20], Batch [60/938], Loss: 0.1303\n",
      "Epoch [10/20], Batch [70/938], Loss: 0.1905\n",
      "Epoch [10/20], Batch [80/938], Loss: 0.1223\n",
      "Epoch [10/20], Batch [90/938], Loss: 0.1238\n",
      "Epoch [10/20], Batch [100/938], Loss: 0.1334\n",
      "Epoch [10/20], Batch [110/938], Loss: 0.0410\n",
      "Epoch [10/20], Batch [120/938], Loss: 0.1229\n",
      "Epoch [10/20], Batch [130/938], Loss: 0.0997\n",
      "Epoch [10/20], Batch [140/938], Loss: 0.0705\n",
      "Epoch [10/20], Batch [150/938], Loss: 0.0579\n",
      "Epoch [10/20], Batch [160/938], Loss: 0.1308\n",
      "Epoch [10/20], Batch [170/938], Loss: 0.0438\n",
      "Epoch [10/20], Batch [180/938], Loss: 0.0932\n",
      "Epoch [10/20], Batch [190/938], Loss: 0.1390\n",
      "Epoch [10/20], Batch [200/938], Loss: 0.1976\n",
      "Epoch [10/20], Batch [210/938], Loss: 0.0949\n",
      "Epoch [10/20], Batch [220/938], Loss: 0.0966\n",
      "Epoch [10/20], Batch [230/938], Loss: 0.1299\n",
      "Epoch [10/20], Batch [240/938], Loss: 0.2195\n",
      "Epoch [10/20], Batch [250/938], Loss: 0.0548\n",
      "Epoch [10/20], Batch [260/938], Loss: 0.1562\n",
      "Epoch [10/20], Batch [270/938], Loss: 0.1326\n",
      "Epoch [10/20], Batch [280/938], Loss: 0.1606\n",
      "Epoch [10/20], Batch [290/938], Loss: 0.1200\n",
      "Epoch [10/20], Batch [300/938], Loss: 0.1276\n",
      "Epoch [10/20], Batch [310/938], Loss: 0.1071\n",
      "Epoch [10/20], Batch [320/938], Loss: 0.2892\n",
      "Epoch [10/20], Batch [330/938], Loss: 0.1386\n",
      "Epoch [10/20], Batch [340/938], Loss: 0.1028\n",
      "Epoch [10/20], Batch [350/938], Loss: 0.1045\n",
      "Epoch [10/20], Batch [360/938], Loss: 0.1539\n",
      "Epoch [10/20], Batch [370/938], Loss: 0.0728\n",
      "Epoch [10/20], Batch [380/938], Loss: 0.0374\n",
      "Epoch [10/20], Batch [390/938], Loss: 0.1276\n",
      "Epoch [10/20], Batch [400/938], Loss: 0.0766\n",
      "Epoch [10/20], Batch [410/938], Loss: 0.0782\n",
      "Epoch [10/20], Batch [420/938], Loss: 0.1517\n",
      "Epoch [10/20], Batch [430/938], Loss: 0.3206\n",
      "Epoch [10/20], Batch [440/938], Loss: 0.1223\n",
      "Epoch [10/20], Batch [450/938], Loss: 0.1004\n",
      "Epoch [10/20], Batch [460/938], Loss: 0.1101\n",
      "Epoch [10/20], Batch [470/938], Loss: 0.3653\n",
      "Epoch [10/20], Batch [480/938], Loss: 0.1121\n",
      "Epoch [10/20], Batch [490/938], Loss: 0.1201\n",
      "Epoch [10/20], Batch [500/938], Loss: 0.1112\n",
      "Epoch [10/20], Batch [510/938], Loss: 0.1932\n",
      "Epoch [10/20], Batch [520/938], Loss: 0.0510\n",
      "Epoch [10/20], Batch [530/938], Loss: 0.1558\n",
      "Epoch [10/20], Batch [540/938], Loss: 0.1232\n",
      "Epoch [10/20], Batch [550/938], Loss: 0.0629\n",
      "Epoch [10/20], Batch [560/938], Loss: 0.0888\n",
      "Epoch [10/20], Batch [570/938], Loss: 0.1910\n",
      "Epoch [10/20], Batch [580/938], Loss: 0.1112\n",
      "Epoch [10/20], Batch [590/938], Loss: 0.2460\n",
      "Epoch [10/20], Batch [600/938], Loss: 0.1633\n",
      "Epoch [10/20], Batch [610/938], Loss: 0.0813\n",
      "Epoch [10/20], Batch [620/938], Loss: 0.1272\n",
      "Epoch [10/20], Batch [630/938], Loss: 0.0731\n",
      "Epoch [10/20], Batch [640/938], Loss: 0.0990\n",
      "Epoch [10/20], Batch [650/938], Loss: 0.1321\n",
      "Epoch [10/20], Batch [660/938], Loss: 0.1240\n",
      "Epoch [10/20], Batch [670/938], Loss: 0.1668\n",
      "Epoch [10/20], Batch [680/938], Loss: 0.1464\n",
      "Epoch [10/20], Batch [690/938], Loss: 0.0749\n",
      "Epoch [10/20], Batch [700/938], Loss: 0.1095\n",
      "Epoch [10/20], Batch [710/938], Loss: 0.0976\n",
      "Epoch [10/20], Batch [720/938], Loss: 0.1803\n",
      "Epoch [10/20], Batch [730/938], Loss: 0.1209\n",
      "Epoch [10/20], Batch [740/938], Loss: 0.1631\n",
      "Epoch [10/20], Batch [750/938], Loss: 0.0756\n",
      "Epoch [10/20], Batch [760/938], Loss: 0.1090\n",
      "Epoch [10/20], Batch [770/938], Loss: 0.1340\n",
      "Epoch [10/20], Batch [780/938], Loss: 0.1420\n",
      "Epoch [10/20], Batch [790/938], Loss: 0.0259\n",
      "Epoch [10/20], Batch [800/938], Loss: 0.0869\n",
      "Epoch [10/20], Batch [810/938], Loss: 0.1306\n",
      "Epoch [10/20], Batch [820/938], Loss: 0.0419\n",
      "Epoch [10/20], Batch [830/938], Loss: 0.0334\n",
      "Epoch [10/20], Batch [840/938], Loss: 0.1135\n",
      "Epoch [10/20], Batch [850/938], Loss: 0.1105\n",
      "Epoch [10/20], Batch [860/938], Loss: 0.1670\n",
      "Epoch [10/20], Batch [870/938], Loss: 0.1368\n",
      "Epoch [10/20], Batch [880/938], Loss: 0.0568\n",
      "Epoch [10/20], Batch [890/938], Loss: 0.2012\n",
      "Epoch [10/20], Batch [900/938], Loss: 0.0715\n",
      "Epoch [10/20], Batch [910/938], Loss: 0.1244\n",
      "Epoch [10/20], Batch [920/938], Loss: 0.0799\n",
      "Epoch [10/20], Batch [930/938], Loss: 0.0751\n",
      "Epoch [10/20], Average Loss: 0.1220\n",
      "------------------------------------------------------------\n",
      "Epoch [11/20], Batch [10/938], Loss: 0.1397\n",
      "Epoch [11/20], Batch [20/938], Loss: 0.1019\n",
      "Epoch [11/20], Batch [30/938], Loss: 0.0690\n",
      "Epoch [11/20], Batch [40/938], Loss: 0.0518\n",
      "Epoch [11/20], Batch [50/938], Loss: 0.1053\n",
      "Epoch [11/20], Batch [60/938], Loss: 0.0738\n",
      "Epoch [11/20], Batch [70/938], Loss: 0.1587\n",
      "Epoch [11/20], Batch [80/938], Loss: 0.0347\n",
      "Epoch [11/20], Batch [90/938], Loss: 0.0616\n",
      "Epoch [11/20], Batch [100/938], Loss: 0.1231\n",
      "Epoch [11/20], Batch [110/938], Loss: 0.1095\n",
      "Epoch [11/20], Batch [120/938], Loss: 0.1030\n",
      "Epoch [11/20], Batch [130/938], Loss: 0.0553\n",
      "Epoch [11/20], Batch [140/938], Loss: 0.1220\n",
      "Epoch [11/20], Batch [150/938], Loss: 0.0882\n",
      "Epoch [11/20], Batch [160/938], Loss: 0.1894\n",
      "Epoch [11/20], Batch [170/938], Loss: 0.1644\n",
      "Epoch [11/20], Batch [180/938], Loss: 0.0648\n",
      "Epoch [11/20], Batch [190/938], Loss: 0.0642\n",
      "Epoch [11/20], Batch [200/938], Loss: 0.1993\n",
      "Epoch [11/20], Batch [210/938], Loss: 0.0380\n",
      "Epoch [11/20], Batch [220/938], Loss: 0.0700\n",
      "Epoch [11/20], Batch [230/938], Loss: 0.1415\n",
      "Epoch [11/20], Batch [240/938], Loss: 0.0411\n",
      "Epoch [11/20], Batch [250/938], Loss: 0.0948\n",
      "Epoch [11/20], Batch [260/938], Loss: 0.1289\n",
      "Epoch [11/20], Batch [270/938], Loss: 0.0693\n",
      "Epoch [11/20], Batch [280/938], Loss: 0.1562\n",
      "Epoch [11/20], Batch [290/938], Loss: 0.0808\n",
      "Epoch [11/20], Batch [300/938], Loss: 0.1148\n",
      "Epoch [11/20], Batch [310/938], Loss: 0.0973\n",
      "Epoch [11/20], Batch [320/938], Loss: 0.0713\n",
      "Epoch [11/20], Batch [330/938], Loss: 0.1316\n",
      "Epoch [11/20], Batch [340/938], Loss: 0.0983\n",
      "Epoch [11/20], Batch [350/938], Loss: 0.0757\n",
      "Epoch [11/20], Batch [360/938], Loss: 0.1250\n",
      "Epoch [11/20], Batch [370/938], Loss: 0.0628\n",
      "Epoch [11/20], Batch [380/938], Loss: 0.1081\n",
      "Epoch [11/20], Batch [390/938], Loss: 0.2003\n",
      "Epoch [11/20], Batch [400/938], Loss: 0.0666\n",
      "Epoch [11/20], Batch [410/938], Loss: 0.2114\n",
      "Epoch [11/20], Batch [420/938], Loss: 0.1085\n",
      "Epoch [11/20], Batch [430/938], Loss: 0.1597\n",
      "Epoch [11/20], Batch [440/938], Loss: 0.1849\n",
      "Epoch [11/20], Batch [450/938], Loss: 0.0694\n",
      "Epoch [11/20], Batch [460/938], Loss: 0.1284\n",
      "Epoch [11/20], Batch [470/938], Loss: 0.1333\n",
      "Epoch [11/20], Batch [480/938], Loss: 0.0841\n",
      "Epoch [11/20], Batch [490/938], Loss: 0.0468\n",
      "Epoch [11/20], Batch [500/938], Loss: 0.1181\n",
      "Epoch [11/20], Batch [510/938], Loss: 0.0287\n",
      "Epoch [11/20], Batch [520/938], Loss: 0.0819\n",
      "Epoch [11/20], Batch [530/938], Loss: 0.1637\n",
      "Epoch [11/20], Batch [540/938], Loss: 0.1207\n",
      "Epoch [11/20], Batch [550/938], Loss: 0.1299\n",
      "Epoch [11/20], Batch [560/938], Loss: 0.0658\n",
      "Epoch [11/20], Batch [570/938], Loss: 0.0737\n",
      "Epoch [11/20], Batch [580/938], Loss: 0.0614\n",
      "Epoch [11/20], Batch [590/938], Loss: 0.1227\n",
      "Epoch [11/20], Batch [600/938], Loss: 0.1138\n",
      "Epoch [11/20], Batch [610/938], Loss: 0.2009\n",
      "Epoch [11/20], Batch [620/938], Loss: 0.1154\n",
      "Epoch [11/20], Batch [630/938], Loss: 0.1235\n",
      "Epoch [11/20], Batch [640/938], Loss: 0.2746\n",
      "Epoch [11/20], Batch [650/938], Loss: 0.1154\n",
      "Epoch [11/20], Batch [660/938], Loss: 0.1263\n",
      "Epoch [11/20], Batch [670/938], Loss: 0.0387\n",
      "Epoch [11/20], Batch [680/938], Loss: 0.1981\n",
      "Epoch [11/20], Batch [690/938], Loss: 0.1085\n",
      "Epoch [11/20], Batch [700/938], Loss: 0.1366\n",
      "Epoch [11/20], Batch [710/938], Loss: 0.1589\n",
      "Epoch [11/20], Batch [720/938], Loss: 0.0818\n",
      "Epoch [11/20], Batch [730/938], Loss: 0.1544\n",
      "Epoch [11/20], Batch [740/938], Loss: 0.0747\n",
      "Epoch [11/20], Batch [750/938], Loss: 0.0252\n",
      "Epoch [11/20], Batch [760/938], Loss: 0.0312\n",
      "Epoch [11/20], Batch [770/938], Loss: 0.1770\n",
      "Epoch [11/20], Batch [780/938], Loss: 0.0586\n",
      "Epoch [11/20], Batch [790/938], Loss: 0.0986\n",
      "Epoch [11/20], Batch [800/938], Loss: 0.1460\n",
      "Epoch [11/20], Batch [810/938], Loss: 0.1523\n",
      "Epoch [11/20], Batch [820/938], Loss: 0.0491\n",
      "Epoch [11/20], Batch [830/938], Loss: 0.0902\n",
      "Epoch [11/20], Batch [840/938], Loss: 0.1395\n",
      "Epoch [11/20], Batch [850/938], Loss: 0.1762\n",
      "Epoch [11/20], Batch [860/938], Loss: 0.1067\n",
      "Epoch [11/20], Batch [870/938], Loss: 0.1555\n",
      "Epoch [11/20], Batch [880/938], Loss: 0.1681\n",
      "Epoch [11/20], Batch [890/938], Loss: 0.0247\n",
      "Epoch [11/20], Batch [900/938], Loss: 0.0749\n",
      "Epoch [11/20], Batch [910/938], Loss: 0.1579\n",
      "Epoch [11/20], Batch [920/938], Loss: 0.0877\n",
      "Epoch [11/20], Batch [930/938], Loss: 0.1404\n",
      "Epoch [11/20], Average Loss: 0.1072\n",
      "------------------------------------------------------------\n",
      "Epoch [12/20], Batch [10/938], Loss: 0.0334\n",
      "Epoch [12/20], Batch [20/938], Loss: 0.0506\n",
      "Epoch [12/20], Batch [30/938], Loss: 0.0898\n",
      "Epoch [12/20], Batch [40/938], Loss: 0.1159\n",
      "Epoch [12/20], Batch [50/938], Loss: 0.0902\n",
      "Epoch [12/20], Batch [60/938], Loss: 0.0643\n",
      "Epoch [12/20], Batch [70/938], Loss: 0.0534\n",
      "Epoch [12/20], Batch [80/938], Loss: 0.1410\n",
      "Epoch [12/20], Batch [90/938], Loss: 0.0603\n",
      "Epoch [12/20], Batch [100/938], Loss: 0.0591\n",
      "Epoch [12/20], Batch [110/938], Loss: 0.0307\n",
      "Epoch [12/20], Batch [120/938], Loss: 0.0866\n",
      "Epoch [12/20], Batch [130/938], Loss: 0.1021\n",
      "Epoch [12/20], Batch [140/938], Loss: 0.0945\n",
      "Epoch [12/20], Batch [150/938], Loss: 0.0808\n",
      "Epoch [12/20], Batch [160/938], Loss: 0.0868\n",
      "Epoch [12/20], Batch [170/938], Loss: 0.1181\n",
      "Epoch [12/20], Batch [180/938], Loss: 0.1621\n",
      "Epoch [12/20], Batch [190/938], Loss: 0.0958\n",
      "Epoch [12/20], Batch [200/938], Loss: 0.0687\n",
      "Epoch [12/20], Batch [210/938], Loss: 0.0967\n",
      "Epoch [12/20], Batch [220/938], Loss: 0.1104\n",
      "Epoch [12/20], Batch [230/938], Loss: 0.0747\n",
      "Epoch [12/20], Batch [240/938], Loss: 0.0825\n",
      "Epoch [12/20], Batch [250/938], Loss: 0.1511\n",
      "Epoch [12/20], Batch [260/938], Loss: 0.1060\n",
      "Epoch [12/20], Batch [270/938], Loss: 0.0688\n",
      "Epoch [12/20], Batch [280/938], Loss: 0.0524\n",
      "Epoch [12/20], Batch [290/938], Loss: 0.0387\n",
      "Epoch [12/20], Batch [300/938], Loss: 0.1283\n",
      "Epoch [12/20], Batch [310/938], Loss: 0.0609\n",
      "Epoch [12/20], Batch [320/938], Loss: 0.0404\n",
      "Epoch [12/20], Batch [330/938], Loss: 0.1092\n",
      "Epoch [12/20], Batch [340/938], Loss: 0.1132\n",
      "Epoch [12/20], Batch [350/938], Loss: 0.0413\n",
      "Epoch [12/20], Batch [360/938], Loss: 0.1175\n",
      "Epoch [12/20], Batch [370/938], Loss: 0.1190\n",
      "Epoch [12/20], Batch [380/938], Loss: 0.0408\n",
      "Epoch [12/20], Batch [390/938], Loss: 0.0511\n",
      "Epoch [12/20], Batch [400/938], Loss: 0.1029\n",
      "Epoch [12/20], Batch [410/938], Loss: 0.0528\n",
      "Epoch [12/20], Batch [420/938], Loss: 0.0435\n",
      "Epoch [12/20], Batch [430/938], Loss: 0.0948\n",
      "Epoch [12/20], Batch [440/938], Loss: 0.0346\n",
      "Epoch [12/20], Batch [450/938], Loss: 0.0441\n",
      "Epoch [12/20], Batch [460/938], Loss: 0.0330\n",
      "Epoch [12/20], Batch [470/938], Loss: 0.0370\n",
      "Epoch [12/20], Batch [480/938], Loss: 0.1418\n",
      "Epoch [12/20], Batch [490/938], Loss: 0.1549\n",
      "Epoch [12/20], Batch [500/938], Loss: 0.1432\n",
      "Epoch [12/20], Batch [510/938], Loss: 0.0301\n",
      "Epoch [12/20], Batch [520/938], Loss: 0.1225\n",
      "Epoch [12/20], Batch [530/938], Loss: 0.1492\n",
      "Epoch [12/20], Batch [540/938], Loss: 0.0981\n",
      "Epoch [12/20], Batch [550/938], Loss: 0.0535\n",
      "Epoch [12/20], Batch [560/938], Loss: 0.1084\n",
      "Epoch [12/20], Batch [570/938], Loss: 0.1432\n",
      "Epoch [12/20], Batch [580/938], Loss: 0.1156\n",
      "Epoch [12/20], Batch [590/938], Loss: 0.0742\n",
      "Epoch [12/20], Batch [600/938], Loss: 0.0371\n",
      "Epoch [12/20], Batch [610/938], Loss: 0.0559\n",
      "Epoch [12/20], Batch [620/938], Loss: 0.0874\n",
      "Epoch [12/20], Batch [630/938], Loss: 0.1441\n",
      "Epoch [12/20], Batch [640/938], Loss: 0.0479\n",
      "Epoch [12/20], Batch [650/938], Loss: 0.0480\n",
      "Epoch [12/20], Batch [660/938], Loss: 0.0692\n",
      "Epoch [12/20], Batch [670/938], Loss: 0.0911\n",
      "Epoch [12/20], Batch [680/938], Loss: 0.0714\n",
      "Epoch [12/20], Batch [690/938], Loss: 0.0555\n",
      "Epoch [12/20], Batch [700/938], Loss: 0.0472\n",
      "Epoch [12/20], Batch [710/938], Loss: 0.0710\n",
      "Epoch [12/20], Batch [720/938], Loss: 0.1176\n",
      "Epoch [12/20], Batch [730/938], Loss: 0.0544\n",
      "Epoch [12/20], Batch [740/938], Loss: 0.0660\n",
      "Epoch [12/20], Batch [750/938], Loss: 0.0515\n",
      "Epoch [12/20], Batch [760/938], Loss: 0.0490\n",
      "Epoch [12/20], Batch [770/938], Loss: 0.1197\n",
      "Epoch [12/20], Batch [780/938], Loss: 0.2309\n",
      "Epoch [12/20], Batch [790/938], Loss: 0.1337\n",
      "Epoch [12/20], Batch [800/938], Loss: 0.0737\n",
      "Epoch [12/20], Batch [810/938], Loss: 0.1709\n",
      "Epoch [12/20], Batch [820/938], Loss: 0.2206\n",
      "Epoch [12/20], Batch [830/938], Loss: 0.1109\n",
      "Epoch [12/20], Batch [840/938], Loss: 0.0656\n",
      "Epoch [12/20], Batch [850/938], Loss: 0.1389\n",
      "Epoch [12/20], Batch [860/938], Loss: 0.1113\n",
      "Epoch [12/20], Batch [870/938], Loss: 0.0698\n",
      "Epoch [12/20], Batch [880/938], Loss: 0.1031\n",
      "Epoch [12/20], Batch [890/938], Loss: 0.0970\n",
      "Epoch [12/20], Batch [900/938], Loss: 0.0960\n",
      "Epoch [12/20], Batch [910/938], Loss: 0.1437\n",
      "Epoch [12/20], Batch [920/938], Loss: 0.0911\n",
      "Epoch [12/20], Batch [930/938], Loss: 0.0368\n",
      "Epoch [12/20], Average Loss: 0.0972\n",
      "------------------------------------------------------------\n",
      "Epoch [13/20], Batch [10/938], Loss: 0.1588\n",
      "Epoch [13/20], Batch [20/938], Loss: 0.0381\n",
      "Epoch [13/20], Batch [30/938], Loss: 0.0732\n",
      "Epoch [13/20], Batch [40/938], Loss: 0.0997\n",
      "Epoch [13/20], Batch [50/938], Loss: 0.0594\n",
      "Epoch [13/20], Batch [60/938], Loss: 0.0866\n",
      "Epoch [13/20], Batch [70/938], Loss: 0.0625\n",
      "Epoch [13/20], Batch [80/938], Loss: 0.1050\n",
      "Epoch [13/20], Batch [90/938], Loss: 0.0780\n",
      "Epoch [13/20], Batch [100/938], Loss: 0.0951\n",
      "Epoch [13/20], Batch [110/938], Loss: 0.1529\n",
      "Epoch [13/20], Batch [120/938], Loss: 0.0653\n",
      "Epoch [13/20], Batch [130/938], Loss: 0.2137\n",
      "Epoch [13/20], Batch [140/938], Loss: 0.0395\n",
      "Epoch [13/20], Batch [150/938], Loss: 0.1681\n",
      "Epoch [13/20], Batch [160/938], Loss: 0.1061\n",
      "Epoch [13/20], Batch [170/938], Loss: 0.0588\n",
      "Epoch [13/20], Batch [180/938], Loss: 0.0698\n",
      "Epoch [13/20], Batch [190/938], Loss: 0.0941\n",
      "Epoch [13/20], Batch [200/938], Loss: 0.2086\n",
      "Epoch [13/20], Batch [210/938], Loss: 0.1230\n",
      "Epoch [13/20], Batch [220/938], Loss: 0.0680\n",
      "Epoch [13/20], Batch [230/938], Loss: 0.0640\n",
      "Epoch [13/20], Batch [240/938], Loss: 0.0402\n",
      "Epoch [13/20], Batch [250/938], Loss: 0.0969\n",
      "Epoch [13/20], Batch [260/938], Loss: 0.0835\n",
      "Epoch [13/20], Batch [270/938], Loss: 0.0224\n",
      "Epoch [13/20], Batch [280/938], Loss: 0.0608\n",
      "Epoch [13/20], Batch [290/938], Loss: 0.0483\n",
      "Epoch [13/20], Batch [300/938], Loss: 0.0839\n",
      "Epoch [13/20], Batch [310/938], Loss: 0.0277\n",
      "Epoch [13/20], Batch [320/938], Loss: 0.1507\n",
      "Epoch [13/20], Batch [330/938], Loss: 0.0797\n",
      "Epoch [13/20], Batch [340/938], Loss: 0.0748\n",
      "Epoch [13/20], Batch [350/938], Loss: 0.1388\n",
      "Epoch [13/20], Batch [360/938], Loss: 0.0925\n",
      "Epoch [13/20], Batch [370/938], Loss: 0.0589\n",
      "Epoch [13/20], Batch [380/938], Loss: 0.0918\n",
      "Epoch [13/20], Batch [390/938], Loss: 0.0683\n",
      "Epoch [13/20], Batch [400/938], Loss: 0.0772\n",
      "Epoch [13/20], Batch [410/938], Loss: 0.0598\n",
      "Epoch [13/20], Batch [420/938], Loss: 0.0658\n",
      "Epoch [13/20], Batch [430/938], Loss: 0.0871\n",
      "Epoch [13/20], Batch [440/938], Loss: 0.1094\n",
      "Epoch [13/20], Batch [450/938], Loss: 0.0232\n",
      "Epoch [13/20], Batch [460/938], Loss: 0.1533\n",
      "Epoch [13/20], Batch [470/938], Loss: 0.0296\n",
      "Epoch [13/20], Batch [480/938], Loss: 0.0896\n",
      "Epoch [13/20], Batch [490/938], Loss: 0.0468\n",
      "Epoch [13/20], Batch [500/938], Loss: 0.1033\n",
      "Epoch [13/20], Batch [510/938], Loss: 0.1505\n",
      "Epoch [13/20], Batch [520/938], Loss: 0.0766\n",
      "Epoch [13/20], Batch [530/938], Loss: 0.0495\n",
      "Epoch [13/20], Batch [540/938], Loss: 0.0695\n",
      "Epoch [13/20], Batch [550/938], Loss: 0.0738\n",
      "Epoch [13/20], Batch [560/938], Loss: 0.0831\n",
      "Epoch [13/20], Batch [570/938], Loss: 0.0701\n",
      "Epoch [13/20], Batch [580/938], Loss: 0.0813\n",
      "Epoch [13/20], Batch [590/938], Loss: 0.1026\n",
      "Epoch [13/20], Batch [600/938], Loss: 0.1441\n",
      "Epoch [13/20], Batch [610/938], Loss: 0.0640\n",
      "Epoch [13/20], Batch [620/938], Loss: 0.1118\n",
      "Epoch [13/20], Batch [630/938], Loss: 0.1036\n",
      "Epoch [13/20], Batch [640/938], Loss: 0.1604\n",
      "Epoch [13/20], Batch [650/938], Loss: 0.1066\n",
      "Epoch [13/20], Batch [660/938], Loss: 0.0301\n",
      "Epoch [13/20], Batch [670/938], Loss: 0.0247\n",
      "Epoch [13/20], Batch [680/938], Loss: 0.1482\n",
      "Epoch [13/20], Batch [690/938], Loss: 0.0657\n",
      "Epoch [13/20], Batch [700/938], Loss: 0.0592\n",
      "Epoch [13/20], Batch [710/938], Loss: 0.0938\n",
      "Epoch [13/20], Batch [720/938], Loss: 0.0342\n",
      "Epoch [13/20], Batch [730/938], Loss: 0.0436\n",
      "Epoch [13/20], Batch [740/938], Loss: 0.0832\n",
      "Epoch [13/20], Batch [750/938], Loss: 0.0672\n",
      "Epoch [13/20], Batch [760/938], Loss: 0.0370\n",
      "Epoch [13/20], Batch [770/938], Loss: 0.0927\n",
      "Epoch [13/20], Batch [780/938], Loss: 0.0747\n",
      "Epoch [13/20], Batch [790/938], Loss: 0.1020\n",
      "Epoch [13/20], Batch [800/938], Loss: 0.0346\n",
      "Epoch [13/20], Batch [810/938], Loss: 0.0452\n",
      "Epoch [13/20], Batch [820/938], Loss: 0.1234\n",
      "Epoch [13/20], Batch [830/938], Loss: 0.1794\n",
      "Epoch [13/20], Batch [840/938], Loss: 0.0134\n",
      "Epoch [13/20], Batch [850/938], Loss: 0.0334\n",
      "Epoch [13/20], Batch [860/938], Loss: 0.0765\n",
      "Epoch [13/20], Batch [870/938], Loss: 0.0563\n",
      "Epoch [13/20], Batch [880/938], Loss: 0.0443\n",
      "Epoch [13/20], Batch [890/938], Loss: 0.0592\n",
      "Epoch [13/20], Batch [900/938], Loss: 0.0278\n",
      "Epoch [13/20], Batch [910/938], Loss: 0.0678\n",
      "Epoch [13/20], Batch [920/938], Loss: 0.1138\n",
      "Epoch [13/20], Batch [930/938], Loss: 0.1228\n",
      "Epoch [13/20], Average Loss: 0.0823\n",
      "------------------------------------------------------------\n",
      "Epoch [14/20], Batch [10/938], Loss: 0.0764\n",
      "Epoch [14/20], Batch [20/938], Loss: 0.0673\n",
      "Epoch [14/20], Batch [30/938], Loss: 0.0599\n",
      "Epoch [14/20], Batch [40/938], Loss: 0.0160\n",
      "Epoch [14/20], Batch [50/938], Loss: 0.0155\n",
      "Epoch [14/20], Batch [60/938], Loss: 0.0456\n",
      "Epoch [14/20], Batch [70/938], Loss: 0.0387\n",
      "Epoch [14/20], Batch [80/938], Loss: 0.0505\n",
      "Epoch [14/20], Batch [90/938], Loss: 0.0138\n",
      "Epoch [14/20], Batch [100/938], Loss: 0.0667\n",
      "Epoch [14/20], Batch [110/938], Loss: 0.0416\n",
      "Epoch [14/20], Batch [120/938], Loss: 0.0329\n",
      "Epoch [14/20], Batch [130/938], Loss: 0.0190\n",
      "Epoch [14/20], Batch [140/938], Loss: 0.0849\n",
      "Epoch [14/20], Batch [150/938], Loss: 0.0690\n",
      "Epoch [14/20], Batch [160/938], Loss: 0.0908\n",
      "Epoch [14/20], Batch [170/938], Loss: 0.0526\n",
      "Epoch [14/20], Batch [180/938], Loss: 0.0379\n",
      "Epoch [14/20], Batch [190/938], Loss: 0.1059\n",
      "Epoch [14/20], Batch [200/938], Loss: 0.0351\n",
      "Epoch [14/20], Batch [210/938], Loss: 0.0296\n",
      "Epoch [14/20], Batch [220/938], Loss: 0.1127\n",
      "Epoch [14/20], Batch [230/938], Loss: 0.0303\n",
      "Epoch [14/20], Batch [240/938], Loss: 0.0696\n",
      "Epoch [14/20], Batch [250/938], Loss: 0.1375\n",
      "Epoch [14/20], Batch [260/938], Loss: 0.1095\n",
      "Epoch [14/20], Batch [270/938], Loss: 0.0968\n",
      "Epoch [14/20], Batch [280/938], Loss: 0.0596\n",
      "Epoch [14/20], Batch [290/938], Loss: 0.0357\n",
      "Epoch [14/20], Batch [300/938], Loss: 0.0282\n",
      "Epoch [14/20], Batch [310/938], Loss: 0.0869\n",
      "Epoch [14/20], Batch [320/938], Loss: 0.0507\n",
      "Epoch [14/20], Batch [330/938], Loss: 0.0662\n",
      "Epoch [14/20], Batch [340/938], Loss: 0.0640\n",
      "Epoch [14/20], Batch [350/938], Loss: 0.0906\n",
      "Epoch [14/20], Batch [360/938], Loss: 0.0555\n",
      "Epoch [14/20], Batch [370/938], Loss: 0.0418\n",
      "Epoch [14/20], Batch [380/938], Loss: 0.0940\n",
      "Epoch [14/20], Batch [390/938], Loss: 0.0441\n",
      "Epoch [14/20], Batch [400/938], Loss: 0.0724\n",
      "Epoch [14/20], Batch [410/938], Loss: 0.0593\n",
      "Epoch [14/20], Batch [420/938], Loss: 0.0645\n",
      "Epoch [14/20], Batch [430/938], Loss: 0.0619\n",
      "Epoch [14/20], Batch [440/938], Loss: 0.1001\n",
      "Epoch [14/20], Batch [450/938], Loss: 0.0889\n",
      "Epoch [14/20], Batch [460/938], Loss: 0.0751\n",
      "Epoch [14/20], Batch [470/938], Loss: 0.1807\n",
      "Epoch [14/20], Batch [480/938], Loss: 0.0785\n",
      "Epoch [14/20], Batch [490/938], Loss: 0.1897\n",
      "Epoch [14/20], Batch [500/938], Loss: 0.1224\n",
      "Epoch [14/20], Batch [510/938], Loss: 0.0558\n",
      "Epoch [14/20], Batch [520/938], Loss: 0.0716\n",
      "Epoch [14/20], Batch [530/938], Loss: 0.1457\n",
      "Epoch [14/20], Batch [540/938], Loss: 0.1076\n",
      "Epoch [14/20], Batch [550/938], Loss: 0.0615\n",
      "Epoch [14/20], Batch [560/938], Loss: 0.0640\n",
      "Epoch [14/20], Batch [570/938], Loss: 0.0697\n",
      "Epoch [14/20], Batch [580/938], Loss: 0.0820\n",
      "Epoch [14/20], Batch [590/938], Loss: 0.0889\n",
      "Epoch [14/20], Batch [600/938], Loss: 0.0222\n",
      "Epoch [14/20], Batch [610/938], Loss: 0.0680\n",
      "Epoch [14/20], Batch [620/938], Loss: 0.0513\n",
      "Epoch [14/20], Batch [630/938], Loss: 0.0782\n",
      "Epoch [14/20], Batch [640/938], Loss: 0.1005\n",
      "Epoch [14/20], Batch [650/938], Loss: 0.1061\n",
      "Epoch [14/20], Batch [660/938], Loss: 0.0718\n",
      "Epoch [14/20], Batch [670/938], Loss: 0.0499\n",
      "Epoch [14/20], Batch [680/938], Loss: 0.1082\n",
      "Epoch [14/20], Batch [690/938], Loss: 0.0759\n",
      "Epoch [14/20], Batch [700/938], Loss: 0.0682\n",
      "Epoch [14/20], Batch [710/938], Loss: 0.0782\n",
      "Epoch [14/20], Batch [720/938], Loss: 0.1128\n",
      "Epoch [14/20], Batch [730/938], Loss: 0.0756\n",
      "Epoch [14/20], Batch [740/938], Loss: 0.0745\n",
      "Epoch [14/20], Batch [750/938], Loss: 0.0273\n",
      "Epoch [14/20], Batch [760/938], Loss: 0.0754\n",
      "Epoch [14/20], Batch [770/938], Loss: 0.0616\n",
      "Epoch [14/20], Batch [780/938], Loss: 0.1256\n",
      "Epoch [14/20], Batch [790/938], Loss: 0.1137\n",
      "Epoch [14/20], Batch [800/938], Loss: 0.0497\n",
      "Epoch [14/20], Batch [810/938], Loss: 0.0442\n",
      "Epoch [14/20], Batch [820/938], Loss: 0.1422\n",
      "Epoch [14/20], Batch [830/938], Loss: 0.0318\n",
      "Epoch [14/20], Batch [840/938], Loss: 0.1517\n",
      "Epoch [14/20], Batch [850/938], Loss: 0.1149\n",
      "Epoch [14/20], Batch [860/938], Loss: 0.0992\n",
      "Epoch [14/20], Batch [870/938], Loss: 0.0185\n",
      "Epoch [14/20], Batch [880/938], Loss: 0.0611\n",
      "Epoch [14/20], Batch [890/938], Loss: 0.0622\n",
      "Epoch [14/20], Batch [900/938], Loss: 0.0864\n",
      "Epoch [14/20], Batch [910/938], Loss: 0.0946\n",
      "Epoch [14/20], Batch [920/938], Loss: 0.0824\n",
      "Epoch [14/20], Batch [930/938], Loss: 0.0473\n",
      "Epoch [14/20], Average Loss: 0.0731\n",
      "------------------------------------------------------------\n",
      "Epoch [15/20], Batch [10/938], Loss: 0.0290\n",
      "Epoch [15/20], Batch [20/938], Loss: 0.0882\n",
      "Epoch [15/20], Batch [30/938], Loss: 0.0339\n",
      "Epoch [15/20], Batch [40/938], Loss: 0.0609\n",
      "Epoch [15/20], Batch [50/938], Loss: 0.0687\n",
      "Epoch [15/20], Batch [60/938], Loss: 0.0129\n",
      "Epoch [15/20], Batch [70/938], Loss: 0.0569\n",
      "Epoch [15/20], Batch [80/938], Loss: 0.0496\n",
      "Epoch [15/20], Batch [90/938], Loss: 0.0347\n",
      "Epoch [15/20], Batch [100/938], Loss: 0.0275\n",
      "Epoch [15/20], Batch [110/938], Loss: 0.0720\n",
      "Epoch [15/20], Batch [120/938], Loss: 0.0647\n",
      "Epoch [15/20], Batch [130/938], Loss: 0.0467\n",
      "Epoch [15/20], Batch [140/938], Loss: 0.0472\n",
      "Epoch [15/20], Batch [150/938], Loss: 0.0194\n",
      "Epoch [15/20], Batch [160/938], Loss: 0.0570\n",
      "Epoch [15/20], Batch [170/938], Loss: 0.0953\n",
      "Epoch [15/20], Batch [180/938], Loss: 0.0734\n",
      "Epoch [15/20], Batch [190/938], Loss: 0.0546\n",
      "Epoch [15/20], Batch [200/938], Loss: 0.0274\n",
      "Epoch [15/20], Batch [210/938], Loss: 0.0316\n",
      "Epoch [15/20], Batch [220/938], Loss: 0.0246\n",
      "Epoch [15/20], Batch [230/938], Loss: 0.0801\n",
      "Epoch [15/20], Batch [240/938], Loss: 0.0469\n",
      "Epoch [15/20], Batch [250/938], Loss: 0.0414\n",
      "Epoch [15/20], Batch [260/938], Loss: 0.0373\n",
      "Epoch [15/20], Batch [270/938], Loss: 0.0433\n",
      "Epoch [15/20], Batch [280/938], Loss: 0.1008\n",
      "Epoch [15/20], Batch [290/938], Loss: 0.0533\n",
      "Epoch [15/20], Batch [300/938], Loss: 0.0306\n",
      "Epoch [15/20], Batch [310/938], Loss: 0.0888\n",
      "Epoch [15/20], Batch [320/938], Loss: 0.0246\n",
      "Epoch [15/20], Batch [330/938], Loss: 0.0810\n",
      "Epoch [15/20], Batch [340/938], Loss: 0.0658\n",
      "Epoch [15/20], Batch [350/938], Loss: 0.0324\n",
      "Epoch [15/20], Batch [360/938], Loss: 0.0252\n",
      "Epoch [15/20], Batch [370/938], Loss: 0.0253\n",
      "Epoch [15/20], Batch [380/938], Loss: 0.0394\n",
      "Epoch [15/20], Batch [390/938], Loss: 0.0052\n",
      "Epoch [15/20], Batch [400/938], Loss: 0.0506\n",
      "Epoch [15/20], Batch [410/938], Loss: 0.0935\n",
      "Epoch [15/20], Batch [420/938], Loss: 0.2389\n",
      "Epoch [15/20], Batch [430/938], Loss: 0.0607\n",
      "Epoch [15/20], Batch [440/938], Loss: 0.0409\n",
      "Epoch [15/20], Batch [450/938], Loss: 0.0686\n",
      "Epoch [15/20], Batch [460/938], Loss: 0.0494\n",
      "Epoch [15/20], Batch [470/938], Loss: 0.0818\n",
      "Epoch [15/20], Batch [480/938], Loss: 0.0824\n",
      "Epoch [15/20], Batch [490/938], Loss: 0.0360\n",
      "Epoch [15/20], Batch [500/938], Loss: 0.1182\n",
      "Epoch [15/20], Batch [510/938], Loss: 0.0541\n",
      "Epoch [15/20], Batch [520/938], Loss: 0.0929\n",
      "Epoch [15/20], Batch [530/938], Loss: 0.0755\n",
      "Epoch [15/20], Batch [540/938], Loss: 0.0264\n",
      "Epoch [15/20], Batch [550/938], Loss: 0.0188\n",
      "Epoch [15/20], Batch [560/938], Loss: 0.0539\n",
      "Epoch [15/20], Batch [570/938], Loss: 0.0767\n",
      "Epoch [15/20], Batch [580/938], Loss: 0.0896\n",
      "Epoch [15/20], Batch [590/938], Loss: 0.0250\n",
      "Epoch [15/20], Batch [600/938], Loss: 0.0364\n",
      "Epoch [15/20], Batch [610/938], Loss: 0.1057\n",
      "Epoch [15/20], Batch [620/938], Loss: 0.0699\n",
      "Epoch [15/20], Batch [630/938], Loss: 0.0169\n",
      "Epoch [15/20], Batch [640/938], Loss: 0.0680\n",
      "Epoch [15/20], Batch [650/938], Loss: 0.1099\n",
      "Epoch [15/20], Batch [660/938], Loss: 0.0342\n",
      "Epoch [15/20], Batch [670/938], Loss: 0.0680\n",
      "Epoch [15/20], Batch [680/938], Loss: 0.0141\n",
      "Epoch [15/20], Batch [690/938], Loss: 0.1490\n",
      "Epoch [15/20], Batch [700/938], Loss: 0.0387\n",
      "Epoch [15/20], Batch [710/938], Loss: 0.0981\n",
      "Epoch [15/20], Batch [720/938], Loss: 0.1088\n",
      "Epoch [15/20], Batch [730/938], Loss: 0.0442\n",
      "Epoch [15/20], Batch [740/938], Loss: 0.0516\n",
      "Epoch [15/20], Batch [750/938], Loss: 0.0278\n",
      "Epoch [15/20], Batch [760/938], Loss: 0.0710\n",
      "Epoch [15/20], Batch [770/938], Loss: 0.0784\n",
      "Epoch [15/20], Batch [780/938], Loss: 0.1474\n",
      "Epoch [15/20], Batch [790/938], Loss: 0.0803\n",
      "Epoch [15/20], Batch [800/938], Loss: 0.0308\n",
      "Epoch [15/20], Batch [810/938], Loss: 0.0278\n",
      "Epoch [15/20], Batch [820/938], Loss: 0.0133\n",
      "Epoch [15/20], Batch [830/938], Loss: 0.0446\n",
      "Epoch [15/20], Batch [840/938], Loss: 0.0912\n",
      "Epoch [15/20], Batch [850/938], Loss: 0.0723\n",
      "Epoch [15/20], Batch [860/938], Loss: 0.0567\n",
      "Epoch [15/20], Batch [870/938], Loss: 0.0203\n",
      "Epoch [15/20], Batch [880/938], Loss: 0.0328\n",
      "Epoch [15/20], Batch [890/938], Loss: 0.0477\n",
      "Epoch [15/20], Batch [900/938], Loss: 0.0774\n",
      "Epoch [15/20], Batch [910/938], Loss: 0.1179\n",
      "Epoch [15/20], Batch [920/938], Loss: 0.0633\n",
      "Epoch [15/20], Batch [930/938], Loss: 0.1617\n",
      "Epoch [15/20], Average Loss: 0.0629\n",
      "------------------------------------------------------------\n",
      "Epoch [16/20], Batch [10/938], Loss: 0.0824\n",
      "Epoch [16/20], Batch [20/938], Loss: 0.0758\n",
      "Epoch [16/20], Batch [30/938], Loss: 0.0409\n",
      "Epoch [16/20], Batch [40/938], Loss: 0.0282\n",
      "Epoch [16/20], Batch [50/938], Loss: 0.0520\n",
      "Epoch [16/20], Batch [60/938], Loss: 0.0368\n",
      "Epoch [16/20], Batch [70/938], Loss: 0.0480\n",
      "Epoch [16/20], Batch [80/938], Loss: 0.0452\n",
      "Epoch [16/20], Batch [90/938], Loss: 0.0298\n",
      "Epoch [16/20], Batch [100/938], Loss: 0.0987\n",
      "Epoch [16/20], Batch [110/938], Loss: 0.0279\n",
      "Epoch [16/20], Batch [120/938], Loss: 0.0079\n",
      "Epoch [16/20], Batch [130/938], Loss: 0.0595\n",
      "Epoch [16/20], Batch [140/938], Loss: 0.0166\n",
      "Epoch [16/20], Batch [150/938], Loss: 0.0277\n",
      "Epoch [16/20], Batch [160/938], Loss: 0.0700\n",
      "Epoch [16/20], Batch [170/938], Loss: 0.0222\n",
      "Epoch [16/20], Batch [180/938], Loss: 0.0362\n",
      "Epoch [16/20], Batch [190/938], Loss: 0.0455\n",
      "Epoch [16/20], Batch [200/938], Loss: 0.0445\n",
      "Epoch [16/20], Batch [210/938], Loss: 0.0510\n",
      "Epoch [16/20], Batch [220/938], Loss: 0.0390\n",
      "Epoch [16/20], Batch [230/938], Loss: 0.0406\n",
      "Epoch [16/20], Batch [240/938], Loss: 0.0593\n",
      "Epoch [16/20], Batch [250/938], Loss: 0.0788\n",
      "Epoch [16/20], Batch [260/938], Loss: 0.0177\n",
      "Epoch [16/20], Batch [270/938], Loss: 0.0200\n",
      "Epoch [16/20], Batch [280/938], Loss: 0.0303\n",
      "Epoch [16/20], Batch [290/938], Loss: 0.0384\n",
      "Epoch [16/20], Batch [300/938], Loss: 0.0213\n",
      "Epoch [16/20], Batch [310/938], Loss: 0.0397\n",
      "Epoch [16/20], Batch [320/938], Loss: 0.0121\n",
      "Epoch [16/20], Batch [330/938], Loss: 0.0363\n",
      "Epoch [16/20], Batch [340/938], Loss: 0.0792\n",
      "Epoch [16/20], Batch [350/938], Loss: 0.0846\n",
      "Epoch [16/20], Batch [360/938], Loss: 0.0835\n",
      "Epoch [16/20], Batch [370/938], Loss: 0.0546\n",
      "Epoch [16/20], Batch [380/938], Loss: 0.0785\n",
      "Epoch [16/20], Batch [390/938], Loss: 0.0228\n",
      "Epoch [16/20], Batch [400/938], Loss: 0.1239\n",
      "Epoch [16/20], Batch [410/938], Loss: 0.0395\n",
      "Epoch [16/20], Batch [420/938], Loss: 0.0639\n",
      "Epoch [16/20], Batch [430/938], Loss: 0.0299\n",
      "Epoch [16/20], Batch [440/938], Loss: 0.0217\n",
      "Epoch [16/20], Batch [450/938], Loss: 0.0600\n",
      "Epoch [16/20], Batch [460/938], Loss: 0.0528\n",
      "Epoch [16/20], Batch [470/938], Loss: 0.0404\n",
      "Epoch [16/20], Batch [480/938], Loss: 0.0516\n",
      "Epoch [16/20], Batch [490/938], Loss: 0.0035\n",
      "Epoch [16/20], Batch [500/938], Loss: 0.0437\n",
      "Epoch [16/20], Batch [510/938], Loss: 0.0254\n",
      "Epoch [16/20], Batch [520/938], Loss: 0.0770\n",
      "Epoch [16/20], Batch [530/938], Loss: 0.0288\n",
      "Epoch [16/20], Batch [540/938], Loss: 0.0140\n",
      "Epoch [16/20], Batch [550/938], Loss: 0.0140\n",
      "Epoch [16/20], Batch [560/938], Loss: 0.0308\n",
      "Epoch [16/20], Batch [570/938], Loss: 0.0193\n",
      "Epoch [16/20], Batch [580/938], Loss: 0.0436\n",
      "Epoch [16/20], Batch [590/938], Loss: 0.0351\n",
      "Epoch [16/20], Batch [600/938], Loss: 0.0521\n",
      "Epoch [16/20], Batch [610/938], Loss: 0.0459\n",
      "Epoch [16/20], Batch [620/938], Loss: 0.0875\n",
      "Epoch [16/20], Batch [630/938], Loss: 0.0116\n",
      "Epoch [16/20], Batch [640/938], Loss: 0.1008\n",
      "Epoch [16/20], Batch [650/938], Loss: 0.0562\n",
      "Epoch [16/20], Batch [660/938], Loss: 0.0605\n",
      "Epoch [16/20], Batch [670/938], Loss: 0.0856\n",
      "Epoch [16/20], Batch [680/938], Loss: 0.0175\n",
      "Epoch [16/20], Batch [690/938], Loss: 0.0417\n",
      "Epoch [16/20], Batch [700/938], Loss: 0.0209\n",
      "Epoch [16/20], Batch [710/938], Loss: 0.0328\n",
      "Epoch [16/20], Batch [720/938], Loss: 0.0464\n",
      "Epoch [16/20], Batch [730/938], Loss: 0.0473\n",
      "Epoch [16/20], Batch [740/938], Loss: 0.0855\n",
      "Epoch [16/20], Batch [750/938], Loss: 0.0948\n",
      "Epoch [16/20], Batch [760/938], Loss: 0.0692\n",
      "Epoch [16/20], Batch [770/938], Loss: 0.0132\n",
      "Epoch [16/20], Batch [780/938], Loss: 0.0506\n",
      "Epoch [16/20], Batch [790/938], Loss: 0.0334\n",
      "Epoch [16/20], Batch [800/938], Loss: 0.0357\n",
      "Epoch [16/20], Batch [810/938], Loss: 0.0646\n",
      "Epoch [16/20], Batch [820/938], Loss: 0.0144\n",
      "Epoch [16/20], Batch [830/938], Loss: 0.0429\n",
      "Epoch [16/20], Batch [840/938], Loss: 0.0153\n",
      "Epoch [16/20], Batch [850/938], Loss: 0.1646\n",
      "Epoch [16/20], Batch [860/938], Loss: 0.1699\n",
      "Epoch [16/20], Batch [870/938], Loss: 0.0239\n",
      "Epoch [16/20], Batch [880/938], Loss: 0.0554\n",
      "Epoch [16/20], Batch [890/938], Loss: 0.0240\n",
      "Epoch [16/20], Batch [900/938], Loss: 0.0664\n",
      "Epoch [16/20], Batch [910/938], Loss: 0.0497\n",
      "Epoch [16/20], Batch [920/938], Loss: 0.0874\n",
      "Epoch [16/20], Batch [930/938], Loss: 0.1496\n",
      "Epoch [16/20], Average Loss: 0.0559\n",
      "------------------------------------------------------------\n",
      "Epoch [17/20], Batch [10/938], Loss: 0.0247\n",
      "Epoch [17/20], Batch [20/938], Loss: 0.0810\n",
      "Epoch [17/20], Batch [30/938], Loss: 0.0292\n",
      "Epoch [17/20], Batch [40/938], Loss: 0.0399\n",
      "Epoch [17/20], Batch [50/938], Loss: 0.0356\n",
      "Epoch [17/20], Batch [60/938], Loss: 0.0339\n",
      "Epoch [17/20], Batch [70/938], Loss: 0.0130\n",
      "Epoch [17/20], Batch [80/938], Loss: 0.0143\n",
      "Epoch [17/20], Batch [90/938], Loss: 0.0235\n",
      "Epoch [17/20], Batch [100/938], Loss: 0.0477\n",
      "Epoch [17/20], Batch [110/938], Loss: 0.0144\n",
      "Epoch [17/20], Batch [120/938], Loss: 0.0133\n",
      "Epoch [17/20], Batch [130/938], Loss: 0.0198\n",
      "Epoch [17/20], Batch [140/938], Loss: 0.0430\n",
      "Epoch [17/20], Batch [150/938], Loss: 0.0258\n",
      "Epoch [17/20], Batch [160/938], Loss: 0.0192\n",
      "Epoch [17/20], Batch [170/938], Loss: 0.0661\n",
      "Epoch [17/20], Batch [180/938], Loss: 0.0735\n",
      "Epoch [17/20], Batch [190/938], Loss: 0.0659\n",
      "Epoch [17/20], Batch [200/938], Loss: 0.0604\n",
      "Epoch [17/20], Batch [210/938], Loss: 0.0415\n",
      "Epoch [17/20], Batch [220/938], Loss: 0.1861\n",
      "Epoch [17/20], Batch [230/938], Loss: 0.0053\n",
      "Epoch [17/20], Batch [240/938], Loss: 0.0343\n",
      "Epoch [17/20], Batch [250/938], Loss: 0.0181\n",
      "Epoch [17/20], Batch [260/938], Loss: 0.0361\n",
      "Epoch [17/20], Batch [270/938], Loss: 0.0924\n",
      "Epoch [17/20], Batch [280/938], Loss: 0.0297\n",
      "Epoch [17/20], Batch [290/938], Loss: 0.0224\n",
      "Epoch [17/20], Batch [300/938], Loss: 0.0168\n",
      "Epoch [17/20], Batch [310/938], Loss: 0.0109\n",
      "Epoch [17/20], Batch [320/938], Loss: 0.0411\n",
      "Epoch [17/20], Batch [330/938], Loss: 0.0245\n",
      "Epoch [17/20], Batch [340/938], Loss: 0.0271\n",
      "Epoch [17/20], Batch [350/938], Loss: 0.0198\n",
      "Epoch [17/20], Batch [360/938], Loss: 0.0703\n",
      "Epoch [17/20], Batch [370/938], Loss: 0.0891\n",
      "Epoch [17/20], Batch [380/938], Loss: 0.1443\n",
      "Epoch [17/20], Batch [390/938], Loss: 0.0792\n",
      "Epoch [17/20], Batch [400/938], Loss: 0.0782\n",
      "Epoch [17/20], Batch [410/938], Loss: 0.0678\n",
      "Epoch [17/20], Batch [420/938], Loss: 0.0392\n",
      "Epoch [17/20], Batch [430/938], Loss: 0.0167\n",
      "Epoch [17/20], Batch [440/938], Loss: 0.1090\n",
      "Epoch [17/20], Batch [450/938], Loss: 0.0229\n",
      "Epoch [17/20], Batch [460/938], Loss: 0.0451\n",
      "Epoch [17/20], Batch [470/938], Loss: 0.0055\n",
      "Epoch [17/20], Batch [480/938], Loss: 0.0197\n",
      "Epoch [17/20], Batch [490/938], Loss: 0.0806\n",
      "Epoch [17/20], Batch [500/938], Loss: 0.0350\n",
      "Epoch [17/20], Batch [510/938], Loss: 0.0233\n",
      "Epoch [17/20], Batch [520/938], Loss: 0.0195\n",
      "Epoch [17/20], Batch [530/938], Loss: 0.0772\n",
      "Epoch [17/20], Batch [540/938], Loss: 0.0709\n",
      "Epoch [17/20], Batch [550/938], Loss: 0.0191\n",
      "Epoch [17/20], Batch [560/938], Loss: 0.1988\n",
      "Epoch [17/20], Batch [570/938], Loss: 0.0473\n",
      "Epoch [17/20], Batch [580/938], Loss: 0.1180\n",
      "Epoch [17/20], Batch [590/938], Loss: 0.0331\n",
      "Epoch [17/20], Batch [600/938], Loss: 0.0395\n",
      "Epoch [17/20], Batch [610/938], Loss: 0.0429\n",
      "Epoch [17/20], Batch [620/938], Loss: 0.0889\n",
      "Epoch [17/20], Batch [630/938], Loss: 0.0861\n",
      "Epoch [17/20], Batch [640/938], Loss: 0.0740\n",
      "Epoch [17/20], Batch [650/938], Loss: 0.0920\n",
      "Epoch [17/20], Batch [660/938], Loss: 0.1682\n",
      "Epoch [17/20], Batch [670/938], Loss: 0.0177\n",
      "Epoch [17/20], Batch [680/938], Loss: 0.0294\n",
      "Epoch [17/20], Batch [690/938], Loss: 0.0164\n",
      "Epoch [17/20], Batch [700/938], Loss: 0.0122\n",
      "Epoch [17/20], Batch [710/938], Loss: 0.0535\n",
      "Epoch [17/20], Batch [720/938], Loss: 0.0114\n",
      "Epoch [17/20], Batch [730/938], Loss: 0.0692\n",
      "Epoch [17/20], Batch [740/938], Loss: 0.0229\n",
      "Epoch [17/20], Batch [750/938], Loss: 0.0162\n",
      "Epoch [17/20], Batch [760/938], Loss: 0.0839\n",
      "Epoch [17/20], Batch [770/938], Loss: 0.0616\n",
      "Epoch [17/20], Batch [780/938], Loss: 0.0067\n",
      "Epoch [17/20], Batch [790/938], Loss: 0.0067\n",
      "Epoch [17/20], Batch [800/938], Loss: 0.0264\n",
      "Epoch [17/20], Batch [810/938], Loss: 0.0500\n",
      "Epoch [17/20], Batch [820/938], Loss: 0.0405\n",
      "Epoch [17/20], Batch [830/938], Loss: 0.0093\n",
      "Epoch [17/20], Batch [840/938], Loss: 0.0338\n",
      "Epoch [17/20], Batch [850/938], Loss: 0.0403\n",
      "Epoch [17/20], Batch [860/938], Loss: 0.0248\n",
      "Epoch [17/20], Batch [870/938], Loss: 0.0847\n",
      "Epoch [17/20], Batch [880/938], Loss: 0.0096\n",
      "Epoch [17/20], Batch [890/938], Loss: 0.0207\n",
      "Epoch [17/20], Batch [900/938], Loss: 0.0197\n",
      "Epoch [17/20], Batch [910/938], Loss: 0.0419\n",
      "Epoch [17/20], Batch [920/938], Loss: 0.1169\n",
      "Epoch [17/20], Batch [930/938], Loss: 0.0896\n",
      "Epoch [17/20], Average Loss: 0.0485\n",
      "------------------------------------------------------------\n",
      "Epoch [18/20], Batch [10/938], Loss: 0.0200\n",
      "Epoch [18/20], Batch [20/938], Loss: 0.0183\n",
      "Epoch [18/20], Batch [30/938], Loss: 0.0198\n",
      "Epoch [18/20], Batch [40/938], Loss: 0.0180\n",
      "Epoch [18/20], Batch [50/938], Loss: 0.0106\n",
      "Epoch [18/20], Batch [60/938], Loss: 0.0048\n",
      "Epoch [18/20], Batch [70/938], Loss: 0.0135\n",
      "Epoch [18/20], Batch [80/938], Loss: 0.0171\n",
      "Epoch [18/20], Batch [90/938], Loss: 0.0110\n",
      "Epoch [18/20], Batch [100/938], Loss: 0.0484\n",
      "Epoch [18/20], Batch [110/938], Loss: 0.0173\n",
      "Epoch [18/20], Batch [120/938], Loss: 0.0349\n",
      "Epoch [18/20], Batch [130/938], Loss: 0.0120\n",
      "Epoch [18/20], Batch [140/938], Loss: 0.0188\n",
      "Epoch [18/20], Batch [150/938], Loss: 0.0271\n",
      "Epoch [18/20], Batch [160/938], Loss: 0.0209\n",
      "Epoch [18/20], Batch [170/938], Loss: 0.0258\n",
      "Epoch [18/20], Batch [180/938], Loss: 0.0548\n",
      "Epoch [18/20], Batch [190/938], Loss: 0.0209\n",
      "Epoch [18/20], Batch [200/938], Loss: 0.0787\n",
      "Epoch [18/20], Batch [210/938], Loss: 0.0119\n",
      "Epoch [18/20], Batch [220/938], Loss: 0.0338\n",
      "Epoch [18/20], Batch [230/938], Loss: 0.0249\n",
      "Epoch [18/20], Batch [240/938], Loss: 0.0286\n",
      "Epoch [18/20], Batch [250/938], Loss: 0.0369\n",
      "Epoch [18/20], Batch [260/938], Loss: 0.1015\n",
      "Epoch [18/20], Batch [270/938], Loss: 0.0046\n",
      "Epoch [18/20], Batch [280/938], Loss: 0.0391\n",
      "Epoch [18/20], Batch [290/938], Loss: 0.0074\n",
      "Epoch [18/20], Batch [300/938], Loss: 0.0876\n",
      "Epoch [18/20], Batch [310/938], Loss: 0.0731\n",
      "Epoch [18/20], Batch [320/938], Loss: 0.0683\n",
      "Epoch [18/20], Batch [330/938], Loss: 0.0202\n",
      "Epoch [18/20], Batch [340/938], Loss: 0.0497\n",
      "Epoch [18/20], Batch [350/938], Loss: 0.0548\n",
      "Epoch [18/20], Batch [360/938], Loss: 0.0213\n",
      "Epoch [18/20], Batch [370/938], Loss: 0.0092\n",
      "Epoch [18/20], Batch [380/938], Loss: 0.0601\n",
      "Epoch [18/20], Batch [390/938], Loss: 0.1011\n",
      "Epoch [18/20], Batch [400/938], Loss: 0.0239\n",
      "Epoch [18/20], Batch [410/938], Loss: 0.0297\n",
      "Epoch [18/20], Batch [420/938], Loss: 0.0647\n",
      "Epoch [18/20], Batch [430/938], Loss: 0.0227\n",
      "Epoch [18/20], Batch [440/938], Loss: 0.0125\n",
      "Epoch [18/20], Batch [450/938], Loss: 0.0130\n",
      "Epoch [18/20], Batch [460/938], Loss: 0.0585\n",
      "Epoch [18/20], Batch [470/938], Loss: 0.1524\n",
      "Epoch [18/20], Batch [480/938], Loss: 0.0158\n",
      "Epoch [18/20], Batch [490/938], Loss: 0.0145\n",
      "Epoch [18/20], Batch [500/938], Loss: 0.0584\n",
      "Epoch [18/20], Batch [510/938], Loss: 0.0318\n",
      "Epoch [18/20], Batch [520/938], Loss: 0.0680\n",
      "Epoch [18/20], Batch [530/938], Loss: 0.0051\n",
      "Epoch [18/20], Batch [540/938], Loss: 0.0157\n",
      "Epoch [18/20], Batch [550/938], Loss: 0.0408\n",
      "Epoch [18/20], Batch [560/938], Loss: 0.0516\n",
      "Epoch [18/20], Batch [570/938], Loss: 0.0605\n",
      "Epoch [18/20], Batch [580/938], Loss: 0.0409\n",
      "Epoch [18/20], Batch [590/938], Loss: 0.0215\n",
      "Epoch [18/20], Batch [600/938], Loss: 0.0439\n",
      "Epoch [18/20], Batch [610/938], Loss: 0.0534\n",
      "Epoch [18/20], Batch [620/938], Loss: 0.0229\n",
      "Epoch [18/20], Batch [630/938], Loss: 0.1101\n",
      "Epoch [18/20], Batch [640/938], Loss: 0.0332\n",
      "Epoch [18/20], Batch [650/938], Loss: 0.0714\n",
      "Epoch [18/20], Batch [660/938], Loss: 0.0240\n",
      "Epoch [18/20], Batch [670/938], Loss: 0.0376\n",
      "Epoch [18/20], Batch [680/938], Loss: 0.0515\n",
      "Epoch [18/20], Batch [690/938], Loss: 0.0222\n",
      "Epoch [18/20], Batch [700/938], Loss: 0.0227\n",
      "Epoch [18/20], Batch [710/938], Loss: 0.0755\n",
      "Epoch [18/20], Batch [720/938], Loss: 0.0809\n",
      "Epoch [18/20], Batch [730/938], Loss: 0.0292\n",
      "Epoch [18/20], Batch [740/938], Loss: 0.0488\n",
      "Epoch [18/20], Batch [750/938], Loss: 0.0379\n",
      "Epoch [18/20], Batch [760/938], Loss: 0.0453\n",
      "Epoch [18/20], Batch [770/938], Loss: 0.0391\n",
      "Epoch [18/20], Batch [780/938], Loss: 0.0189\n",
      "Epoch [18/20], Batch [790/938], Loss: 0.0941\n",
      "Epoch [18/20], Batch [800/938], Loss: 0.0300\n",
      "Epoch [18/20], Batch [810/938], Loss: 0.0111\n",
      "Epoch [18/20], Batch [820/938], Loss: 0.0961\n",
      "Epoch [18/20], Batch [830/938], Loss: 0.0618\n",
      "Epoch [18/20], Batch [840/938], Loss: 0.0738\n",
      "Epoch [18/20], Batch [850/938], Loss: 0.0945\n",
      "Epoch [18/20], Batch [860/938], Loss: 0.0475\n",
      "Epoch [18/20], Batch [870/938], Loss: 0.0557\n",
      "Epoch [18/20], Batch [880/938], Loss: 0.0765\n",
      "Epoch [18/20], Batch [890/938], Loss: 0.0551\n",
      "Epoch [18/20], Batch [900/938], Loss: 0.0683\n",
      "Epoch [18/20], Batch [910/938], Loss: 0.0403\n",
      "Epoch [18/20], Batch [920/938], Loss: 0.1601\n",
      "Epoch [18/20], Batch [930/938], Loss: 0.0957\n",
      "Epoch [18/20], Average Loss: 0.0444\n",
      "------------------------------------------------------------\n",
      "Epoch [19/20], Batch [10/938], Loss: 0.0680\n",
      "Epoch [19/20], Batch [20/938], Loss: 0.1500\n",
      "Epoch [19/20], Batch [30/938], Loss: 0.1630\n",
      "Epoch [19/20], Batch [40/938], Loss: 0.0147\n",
      "Epoch [19/20], Batch [50/938], Loss: 0.0127\n",
      "Epoch [19/20], Batch [60/938], Loss: 0.0280\n",
      "Epoch [19/20], Batch [70/938], Loss: 0.0137\n",
      "Epoch [19/20], Batch [80/938], Loss: 0.0475\n",
      "Epoch [19/20], Batch [90/938], Loss: 0.0150\n",
      "Epoch [19/20], Batch [100/938], Loss: 0.0074\n",
      "Epoch [19/20], Batch [110/938], Loss: 0.0142\n",
      "Epoch [19/20], Batch [120/938], Loss: 0.0132\n",
      "Epoch [19/20], Batch [130/938], Loss: 0.0130\n",
      "Epoch [19/20], Batch [140/938], Loss: 0.0084\n",
      "Epoch [19/20], Batch [150/938], Loss: 0.0581\n",
      "Epoch [19/20], Batch [160/938], Loss: 0.0265\n",
      "Epoch [19/20], Batch [170/938], Loss: 0.0131\n",
      "Epoch [19/20], Batch [180/938], Loss: 0.0976\n",
      "Epoch [19/20], Batch [190/938], Loss: 0.0853\n",
      "Epoch [19/20], Batch [200/938], Loss: 0.0596\n",
      "Epoch [19/20], Batch [210/938], Loss: 0.0558\n",
      "Epoch [19/20], Batch [220/938], Loss: 0.0166\n",
      "Epoch [19/20], Batch [230/938], Loss: 0.0150\n",
      "Epoch [19/20], Batch [240/938], Loss: 0.0190\n",
      "Epoch [19/20], Batch [250/938], Loss: 0.0701\n",
      "Epoch [19/20], Batch [260/938], Loss: 0.0140\n",
      "Epoch [19/20], Batch [270/938], Loss: 0.0258\n",
      "Epoch [19/20], Batch [280/938], Loss: 0.0202\n",
      "Epoch [19/20], Batch [290/938], Loss: 0.0235\n",
      "Epoch [19/20], Batch [300/938], Loss: 0.0117\n",
      "Epoch [19/20], Batch [310/938], Loss: 0.0798\n",
      "Epoch [19/20], Batch [320/938], Loss: 0.1249\n",
      "Epoch [19/20], Batch [330/938], Loss: 0.0704\n",
      "Epoch [19/20], Batch [340/938], Loss: 0.0274\n",
      "Epoch [19/20], Batch [350/938], Loss: 0.0384\n",
      "Epoch [19/20], Batch [360/938], Loss: 0.0079\n",
      "Epoch [19/20], Batch [370/938], Loss: 0.0694\n",
      "Epoch [19/20], Batch [380/938], Loss: 0.0393\n",
      "Epoch [19/20], Batch [390/938], Loss: 0.0152\n",
      "Epoch [19/20], Batch [400/938], Loss: 0.0083\n",
      "Epoch [19/20], Batch [410/938], Loss: 0.0133\n",
      "Epoch [19/20], Batch [420/938], Loss: 0.0062\n",
      "Epoch [19/20], Batch [430/938], Loss: 0.0116\n",
      "Epoch [19/20], Batch [440/938], Loss: 0.0348\n",
      "Epoch [19/20], Batch [450/938], Loss: 0.0335\n",
      "Epoch [19/20], Batch [460/938], Loss: 0.0875\n",
      "Epoch [19/20], Batch [470/938], Loss: 0.0162\n",
      "Epoch [19/20], Batch [480/938], Loss: 0.0679\n",
      "Epoch [19/20], Batch [490/938], Loss: 0.0157\n",
      "Epoch [19/20], Batch [500/938], Loss: 0.0159\n",
      "Epoch [19/20], Batch [510/938], Loss: 0.0053\n",
      "Epoch [19/20], Batch [520/938], Loss: 0.0523\n",
      "Epoch [19/20], Batch [530/938], Loss: 0.0079\n",
      "Epoch [19/20], Batch [540/938], Loss: 0.0745\n",
      "Epoch [19/20], Batch [550/938], Loss: 0.0438\n",
      "Epoch [19/20], Batch [560/938], Loss: 0.0218\n",
      "Epoch [19/20], Batch [570/938], Loss: 0.0169\n",
      "Epoch [19/20], Batch [580/938], Loss: 0.0221\n",
      "Epoch [19/20], Batch [590/938], Loss: 0.0112\n",
      "Epoch [19/20], Batch [600/938], Loss: 0.0429\n",
      "Epoch [19/20], Batch [610/938], Loss: 0.0656\n",
      "Epoch [19/20], Batch [620/938], Loss: 0.0096\n",
      "Epoch [19/20], Batch [630/938], Loss: 0.0409\n",
      "Epoch [19/20], Batch [640/938], Loss: 0.0648\n",
      "Epoch [19/20], Batch [650/938], Loss: 0.0346\n",
      "Epoch [19/20], Batch [660/938], Loss: 0.0127\n",
      "Epoch [19/20], Batch [670/938], Loss: 0.0094\n",
      "Epoch [19/20], Batch [680/938], Loss: 0.0196\n",
      "Epoch [19/20], Batch [690/938], Loss: 0.0617\n",
      "Epoch [19/20], Batch [700/938], Loss: 0.0360\n",
      "Epoch [19/20], Batch [710/938], Loss: 0.0109\n",
      "Epoch [19/20], Batch [720/938], Loss: 0.0242\n",
      "Epoch [19/20], Batch [730/938], Loss: 0.0168\n",
      "Epoch [19/20], Batch [740/938], Loss: 0.0754\n",
      "Epoch [19/20], Batch [750/938], Loss: 0.1100\n",
      "Epoch [19/20], Batch [760/938], Loss: 0.0149\n",
      "Epoch [19/20], Batch [770/938], Loss: 0.0341\n",
      "Epoch [19/20], Batch [780/938], Loss: 0.0343\n",
      "Epoch [19/20], Batch [790/938], Loss: 0.0252\n",
      "Epoch [19/20], Batch [800/938], Loss: 0.0496\n",
      "Epoch [19/20], Batch [810/938], Loss: 0.0369\n",
      "Epoch [19/20], Batch [820/938], Loss: 0.0317\n",
      "Epoch [19/20], Batch [830/938], Loss: 0.0283\n",
      "Epoch [19/20], Batch [840/938], Loss: 0.0181\n",
      "Epoch [19/20], Batch [850/938], Loss: 0.0139\n",
      "Epoch [19/20], Batch [860/938], Loss: 0.0306\n",
      "Epoch [19/20], Batch [870/938], Loss: 0.0193\n",
      "Epoch [19/20], Batch [880/938], Loss: 0.0780\n",
      "Epoch [19/20], Batch [890/938], Loss: 0.0145\n",
      "Epoch [19/20], Batch [900/938], Loss: 0.0239\n",
      "Epoch [19/20], Batch [910/938], Loss: 0.0328\n",
      "Epoch [19/20], Batch [920/938], Loss: 0.0421\n",
      "Epoch [19/20], Batch [930/938], Loss: 0.0654\n",
      "Epoch [19/20], Average Loss: 0.0361\n",
      "------------------------------------------------------------\n",
      "Epoch [20/20], Batch [10/938], Loss: 0.0272\n",
      "Epoch [20/20], Batch [20/938], Loss: 0.0219\n",
      "Epoch [20/20], Batch [30/938], Loss: 0.0773\n",
      "Epoch [20/20], Batch [40/938], Loss: 0.0115\n",
      "Epoch [20/20], Batch [50/938], Loss: 0.0034\n",
      "Epoch [20/20], Batch [60/938], Loss: 0.0099\n",
      "Epoch [20/20], Batch [70/938], Loss: 0.0068\n",
      "Epoch [20/20], Batch [80/938], Loss: 0.0164\n",
      "Epoch [20/20], Batch [90/938], Loss: 0.0430\n",
      "Epoch [20/20], Batch [100/938], Loss: 0.0253\n",
      "Epoch [20/20], Batch [110/938], Loss: 0.0126\n",
      "Epoch [20/20], Batch [120/938], Loss: 0.0197\n",
      "Epoch [20/20], Batch [130/938], Loss: 0.0088\n",
      "Epoch [20/20], Batch [140/938], Loss: 0.0780\n",
      "Epoch [20/20], Batch [150/938], Loss: 0.0103\n",
      "Epoch [20/20], Batch [160/938], Loss: 0.0624\n",
      "Epoch [20/20], Batch [170/938], Loss: 0.0435\n",
      "Epoch [20/20], Batch [180/938], Loss: 0.0489\n",
      "Epoch [20/20], Batch [190/938], Loss: 0.0085\n",
      "Epoch [20/20], Batch [200/938], Loss: 0.0910\n",
      "Epoch [20/20], Batch [210/938], Loss: 0.0509\n",
      "Epoch [20/20], Batch [220/938], Loss: 0.0378\n",
      "Epoch [20/20], Batch [230/938], Loss: 0.0112\n",
      "Epoch [20/20], Batch [240/938], Loss: 0.0181\n",
      "Epoch [20/20], Batch [250/938], Loss: 0.0118\n",
      "Epoch [20/20], Batch [260/938], Loss: 0.0027\n",
      "Epoch [20/20], Batch [270/938], Loss: 0.0112\n",
      "Epoch [20/20], Batch [280/938], Loss: 0.0404\n",
      "Epoch [20/20], Batch [290/938], Loss: 0.0133\n",
      "Epoch [20/20], Batch [300/938], Loss: 0.0436\n",
      "Epoch [20/20], Batch [310/938], Loss: 0.0080\n",
      "Epoch [20/20], Batch [320/938], Loss: 0.0074\n",
      "Epoch [20/20], Batch [330/938], Loss: 0.0253\n",
      "Epoch [20/20], Batch [340/938], Loss: 0.0192\n",
      "Epoch [20/20], Batch [350/938], Loss: 0.0204\n",
      "Epoch [20/20], Batch [360/938], Loss: 0.0585\n",
      "Epoch [20/20], Batch [370/938], Loss: 0.0434\n",
      "Epoch [20/20], Batch [380/938], Loss: 0.0046\n",
      "Epoch [20/20], Batch [390/938], Loss: 0.0032\n",
      "Epoch [20/20], Batch [400/938], Loss: 0.0040\n",
      "Epoch [20/20], Batch [410/938], Loss: 0.1011\n",
      "Epoch [20/20], Batch [420/938], Loss: 0.0747\n",
      "Epoch [20/20], Batch [430/938], Loss: 0.1399\n",
      "Epoch [20/20], Batch [440/938], Loss: 0.0361\n",
      "Epoch [20/20], Batch [450/938], Loss: 0.0208\n",
      "Epoch [20/20], Batch [460/938], Loss: 0.0084\n",
      "Epoch [20/20], Batch [470/938], Loss: 0.0853\n",
      "Epoch [20/20], Batch [480/938], Loss: 0.0097\n",
      "Epoch [20/20], Batch [490/938], Loss: 0.0734\n",
      "Epoch [20/20], Batch [500/938], Loss: 0.0903\n",
      "Epoch [20/20], Batch [510/938], Loss: 0.0480\n",
      "Epoch [20/20], Batch [520/938], Loss: 0.1144\n",
      "Epoch [20/20], Batch [530/938], Loss: 0.0556\n",
      "Epoch [20/20], Batch [540/938], Loss: 0.0191\n",
      "Epoch [20/20], Batch [550/938], Loss: 0.0169\n",
      "Epoch [20/20], Batch [560/938], Loss: 0.0475\n",
      "Epoch [20/20], Batch [570/938], Loss: 0.0445\n",
      "Epoch [20/20], Batch [580/938], Loss: 0.0595\n",
      "Epoch [20/20], Batch [590/938], Loss: 0.0152\n",
      "Epoch [20/20], Batch [600/938], Loss: 0.0127\n",
      "Epoch [20/20], Batch [610/938], Loss: 0.0221\n",
      "Epoch [20/20], Batch [620/938], Loss: 0.0127\n",
      "Epoch [20/20], Batch [630/938], Loss: 0.0030\n",
      "Epoch [20/20], Batch [640/938], Loss: 0.0095\n",
      "Epoch [20/20], Batch [650/938], Loss: 0.0261\n",
      "Epoch [20/20], Batch [660/938], Loss: 0.0172\n",
      "Epoch [20/20], Batch [670/938], Loss: 0.0072\n",
      "Epoch [20/20], Batch [680/938], Loss: 0.1513\n",
      "Epoch [20/20], Batch [690/938], Loss: 0.0567\n",
      "Epoch [20/20], Batch [700/938], Loss: 0.0101\n",
      "Epoch [20/20], Batch [710/938], Loss: 0.0507\n",
      "Epoch [20/20], Batch [720/938], Loss: 0.0999\n",
      "Epoch [20/20], Batch [730/938], Loss: 0.0117\n",
      "Epoch [20/20], Batch [740/938], Loss: 0.0449\n",
      "Epoch [20/20], Batch [750/938], Loss: 0.0162\n",
      "Epoch [20/20], Batch [760/938], Loss: 0.0389\n",
      "Epoch [20/20], Batch [770/938], Loss: 0.0606\n",
      "Epoch [20/20], Batch [780/938], Loss: 0.0366\n",
      "Epoch [20/20], Batch [790/938], Loss: 0.0441\n",
      "Epoch [20/20], Batch [800/938], Loss: 0.0044\n",
      "Epoch [20/20], Batch [810/938], Loss: 0.0129\n",
      "Epoch [20/20], Batch [820/938], Loss: 0.0034\n",
      "Epoch [20/20], Batch [830/938], Loss: 0.0091\n",
      "Epoch [20/20], Batch [840/938], Loss: 0.0336\n",
      "Epoch [20/20], Batch [850/938], Loss: 0.0799\n",
      "Epoch [20/20], Batch [860/938], Loss: 0.0299\n",
      "Epoch [20/20], Batch [870/938], Loss: 0.0073\n",
      "Epoch [20/20], Batch [880/938], Loss: 0.0163\n",
      "Epoch [20/20], Batch [890/938], Loss: 0.0444\n",
      "Epoch [20/20], Batch [900/938], Loss: 0.0202\n",
      "Epoch [20/20], Batch [910/938], Loss: 0.0252\n",
      "Epoch [20/20], Batch [920/938], Loss: 0.0230\n",
      "Epoch [20/20], Batch [930/938], Loss: 0.0256\n",
      "Epoch [20/20], Average Loss: 0.0350\n",
      "------------------------------------------------------------\n",
      "Training finished!\n",
      "Test Accuracy: 91.74%\n",
      "Evaluation finished!\n",
      "오차 행렬 (Confusion Matrix):\n",
      "[[857   0  25  16   3   1  92   0   6   0]\n",
      " [  2 979   1  13   3   0   1   0   1   0]\n",
      " [ 16   1 888   7  29   0  56   0   3   0]\n",
      " [ 18   1  10 925  12   0  33   0   1   0]\n",
      " [  2   1  63  25 843   0  66   0   0   0]\n",
      " [  0   0   0   0   0 994   0   6   0   0]\n",
      " [100   0  53  29  47   1 762   0   8   0]\n",
      " [  0   0   0   0   0  10   0 981   0   9]\n",
      " [  3   0   1   3   2   1   1   2 987   0]\n",
      " [  0   0   0   0   0   7   1  33   1 958]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. 문제 정의 및 데이터 준비\n",
    "# 문제: Fashion-MNIST 데이터셋을 사용하여 10가지 종류의 의류 이미지를 정확하게 분류하는 이미지 분류(Image Classification) 모델을 만듭니다.\n",
    "# 데이터: 캐글(Kaggle)에서 다운로드할 수 있는 Fashion-MNIST 데이터셋을 사용합니다. 이 데이터셋은 훈련용 이미지 60,000개와 테스트용 이미지 10,000개로 구성되어 있으며, 각 이미지는 28×28 픽셀의 흑백 이미지입니다.\n",
    "\n",
    "# 2. 데이터 로딩 및 전처리\n",
    "# 2.1. 데이터 로드\n",
    "# 바이너리 파일 형태로 저장되어 gzip, numpy 라이브러리를 사용.\n",
    "import numpy as np\n",
    "# import gzip # 이미 압축해제 되어 있어서 필요 없음\n",
    "train_images_path = '/Users/ys/Library/Mobile Documents/com~apple~CloudDocs/Study/AI/Kaggle/kaggle-projects/fashion-mnist/data/train-images-idx3-ubyte'\n",
    "train_labels_path = '/Users/ys/Library/Mobile Documents/com~apple~CloudDocs/Study/AI/Kaggle/kaggle-projects/fashion-mnist/data/train-labels-idx1-ubyte'\n",
    "test_images_path = '/Users/ys/Library/Mobile Documents/com~apple~CloudDocs/Study/AI/Kaggle/kaggle-projects/fashion-mnist/data/t10k-images-idx3-ubyte'\n",
    "test_labels_path = '/Users/ys/Library/Mobile Documents/com~apple~CloudDocs/Study/AI/Kaggle/kaggle-projects/fashion-mnist/data/t10k-labels-idx1-ubyte'\n",
    "# offset은 파일의 특정 위치부터 데이터를 읽기 시작하라고 알려주는 기능입니다. Fashion-MNIST 데이터셋의 바이너리 파일은 이미지 데이터나 라벨 데이터가 시작되기 전에, 데이터에 대한 메타정보가 담긴 **헤더(header)**를 가지고 있습니다. 이 헤더 정보를 건너뛰고 순수한 데이터만 읽기 위해 offset을 사용하는 것이죠.\n",
    "# 이미지 파일 로드 함수 (압축 해제된 파일용)\n",
    "def load_mnist_images(path:str):\n",
    "    with open(path, 'rb') as f:\n",
    "        # 이미지 파일 헤더(16바이트)를 건너뛰고 나머지 데이터를 읽음\n",
    "        data = np.frombuffer(f.read(), dtype=np.uint8, offset=16)\n",
    "    # 28x28 이미지 크기로 재구성\n",
    "    return data.reshape(-1, 28, 28)\n",
    "# 라벨 파일 로드 함수 (압축 해제된 파일용)\n",
    "def load_mnist_labels(path:str):\n",
    "    with open(path, 'rb') as f:\n",
    "        # 라벨 파일 헤더(8바이트)를 건너뛰고 나머지 데이터를 읽음\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8, offset=8)\n",
    "# 함수를 사용해 데이터 로드\n",
    "train_images = load_mnist_images(train_images_path)\n",
    "train_labels = load_mnist_labels(train_labels_path)\n",
    "test_images = load_mnist_images(test_images_path)\n",
    "test_labels = load_mnist_labels(test_labels_path)\n",
    "# print(f\"훈련용 이미지 데이터의 형태: {train_images.shape}\")\n",
    "# print(f\"훈련용 라벨 데이터의 형태: {train_labels.shape}\")\n",
    "# print(f\"테스트용 이미지 데이터의 형태: {test_images.shape}\")\n",
    "# print(f\"테스트용 라벨 데이터의 형태: {test_labels.shape}\")\n",
    "\n",
    "# 3. 데이터 전처리 및 시각화\n",
    "# 3.1. 이미지 데이터 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "# # 3.1.1. train_images에 저장된 첫 번째 이미지 데이터를 선택\n",
    "# image_to_visualize = train_images[0]\n",
    "# # 3.1.2. 이미지 시각화를 위해 plt.imshow() 함수를 사용합니다.\n",
    "# # imshow() 함수는 배열 형태의 데이터를 이미지로 보여주는 역할을 해요.\n",
    "# # cmap=plt.cm.binary 옵션은 이미지를 흑백으로 나타내라는 의미입니다.\n",
    "# plt.imshow(image_to_visualize, cmap=plt.cm.binary) # pyright: ignore[reportAttributeAccessIssue]\n",
    "# # 3.1.3. plt.colorbar() 함수를 사용해 이미지의 픽셀 값 분포를 나타내는 컬러바를 추가합니다.\n",
    "# # 픽셀 값이 0(검은색)부터 255(흰색)까지 어떻게 분포하는지 한눈에 확인 가능.\n",
    "# plt.colorbar()\n",
    "# # 3.1.4. plt.grid(False)를 사용해 이미지 위에 격자가 보이지 않도록 설정합니다.\n",
    "# #    기본적으로 격자가 나타나는데, 이미지를 깔끔하게 보기 위해 제거하는 거예요.\n",
    "# plt.grid(False)\n",
    "# # 3.1.5. plt.show()를 호출해 최종적으로 시각화된 이미지를 화면에 표시합니다.\n",
    "# plt.show()\n",
    "# # 3.1.6. 마지막으로, 첫 번째 이미지의 라벨(정답)을 출력합니다.\n",
    "# #    train_labels는 각 이미지의 정답 배열.\n",
    "# print(f\"첫 번째 이미지의 라벨: {train_labels[0]}\")\n",
    "\n",
    "# 4. 정규화\n",
    "train_images_normalized = train_images.astype(np.float32) / 255.0\n",
    "test_images_normalized = test_images.astype(np.float32) / 255.0\n",
    "# 결과 데이터 형식 확인.\n",
    "print(train_images_normalized.dtype)  # unint8: unsigned(부호가 없는) int8\n",
    "# 4.1 채널 차원 추가 # 흑백이므로 1, 컬러의 경우 3\n",
    "train_images_normalized = train_images_normalized[:, np.newaxis, :, :]  # np.newaxis 는 인덱싱 키워드\n",
    "test_images_normalized = test_images_normalized[:, np.newaxis, :, :]\n",
    "# 결과 확인\n",
    "print(f\"채널 추가 후 훈련 데이터 형태:  {train_images_normalized.shape}\")\n",
    "print(f\"채널 추가 후 테스트 데이터 형태:  {test_images_normalized.shape}\")\n",
    "\n",
    "# 5. 모델 학습\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# 5.1. FashionMNIST 모델 클래스 정의\n",
    "# PyTorch에서는 nn.Module을 상속받아 모델을 클래스 형태로 만듭니다.\n",
    "# 이렇게 하면 모델의 구조와 동작을 체계적으로 관리할 수 있어요.\n",
    "class FashionMNISTModel(nn.Module):\n",
    "    # 5.1.2. 모델의 각 층(layer) 정의\n",
    "    # __init__ 함수에서 모델의 구성 요소를 미리 정의합니다.\n",
    "    def __init__(self):\n",
    "        super(FashionMNISTModel, self).__init__()\n",
    "        # 5.1.2.1. Flatten 레이어: 28*28 이미지를 784 픽셀의 1차원 벡터로 변환\n",
    "        self.flatten = nn.Flatten()\n",
    "        # 5.1.2.2. 첫 번째 Dense(Linear) 레이어\n",
    "        # 784개의 입력을 받아 128개의 뉴런을 가진 층으로 연결.\n",
    "        # self.fc1 = nn.Linear(28 * 28, 128) # 기존 1층\n",
    "        ### 9.1.1. 첫 번째 층 뉴런 수 증가\n",
    "        self.fc1 = nn.Linear(28 * 28, 256)  # 기존 1층에서 뉴런 수 증가(256)\n",
    "        # 5.1.2.3. 두 번째 Dense(Linear) 레이어\n",
    "        # 128개의 입력을 받아 10개의 출력 뉴런을 가진 층으로 연결\n",
    "        # Fashion-MNIST의 클래스가 10개이기 때문\n",
    "        # self.fc2 = nn.Linear(128, 10) # 기존 2층\n",
    "        ### 9.1.2. 새로운 중간 층을 추가하고 출력층을 3번째로 이동.\n",
    "        self.fc2 = nn.Linear(256, 128)  # 새로운 중간 층을  추가\n",
    "        self.fc3 = nn.Linear(128, 10)  # 출력층 3층으로 이동.\n",
    "\n",
    "    # 5.1.3. 모델의 순전파(foward pass) 정의\n",
    "    # 이 함수는 입력 데이터가 모델의 층을 통과하는 순서를 정의\n",
    "    # 데이터가 어떤 과정을 거쳐 최종 결과로 나오는지 결정.\n",
    "    def forward(self, x):\n",
    "        # 5.1.3.1. 입력 이미지를 1차원으로 펼침.\n",
    "        x = self.flatten(x)\n",
    "        # 5.1.3.2. 첫 번째 완전 연결 층을 통과, relu 활성화 함수를 적용\n",
    "        # ReLu는 활성화 함수이다. 음수 값을 0으로 만들고 양수 값을 그대로 통과시켜 비선형성을 부여.\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # 5.1.3.3. 두 번째 완전 연결 층을 통과시켜 최종 결과를 얻는다.\n",
    "        # 이 단계의 출력은 각 클래스에 대한 '점수'\n",
    "        # x = self.fc2(x) # 기존 출력 층\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  # 출력 층\n",
    "        # 5.1.3.4. 최종 결과는 나중에 손실 함수(CrossEntropyLoss)에서 Softmax를 내부적으로 계산\n",
    "        # Softmax를 직접 적용하지는 않는다.\n",
    "        return x\n",
    "\n",
    "\n",
    "# 5.2. FashionMNIST CNN 모델 클래스 정의\n",
    "class FashionMNISTCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionMNISTCNN, self).__init__()\n",
    "        # 첫 번째 합성곱 블록\n",
    "        # 입력: (1, 28, 28) → 출력: (32, 28, 28)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        # 풀링 후: (32, 28, 28) → (32, 14, 14)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # 두 번째 합성곱 블록\n",
    "        # 입력: (32, 14, 14) → 출력: (64, 14, 14)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=32, out_channels=64, kernel_size=3, padding=1\n",
    "        )\n",
    "        # 풀링 후: (64, 14, 14) → (64, 7, 7)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # 완전 연결 레이어\n",
    "        # 64 * 7 * 7 = 3136\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 첫 번째 블록: Conv → ReLU → Pool\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        # 두 번째 블록: Conv → ReLU → Pool\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        # Flatten: (batch, 64, 7, 7) → (batch, 3136)\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        # 완전 연결 레이어\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 6. 모델 컴파일\n",
    "# 6.0. GPU(MPS) 사용 가능 여부 확인 및 장치 설정.\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "# 6.1. 모델 인스턴스 생성\n",
    "# 이제 우리가 정의한 FasionMNISTModel 클래스를 사용해 실제 모델 객체를 생성.\n",
    "# 위에서 설정한 장치(GPU 또는 CPU)로 모델을 보냅니다.\n",
    "# 이렇게 해야 모델의 가중치가 GPU 메모리에 올라가 GPU 연산을 사용할 수 있습니다.\n",
    "# model = FashionMNISTModel().to(device) # FashionMSTR 모델\n",
    "model = FashionMNISTCNN().to(device)  # FashionMSTR CNN 모델\n",
    "# 6.2. 모델 구조 출력\n",
    "print(model)\n",
    "import torch.optim as optim\n",
    "# 6.3. 손실 함수 정의\n",
    "# 모델의 예측과 실제 라벨 간의 오차를 계산하는 함수.\n",
    "# 다중 클래스 분류 문제에는 CrossEntropyLoss가 가장 널리 사용.\n",
    "# PyTorch의 이 손실 함수는 내부적으로 Softmax를 포함.\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "# 6.4. 옵티마이저 정의\n",
    "# 모델의 가중치를 업데이트하여 손실을 최소화하는 역할.\n",
    "# Adam은 현재 딥러닝에서 가장 많이 사용되는 옵티마이저 중 하나.\n",
    "# - model.parameters()는 모델이 학습할 모든 가중치와 편향을 넘겨주는 역할\n",
    "# - lr(learning rate)는 경사 하강법에서 한 번에 움직이는 보폭의 의미\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# 9.2. 하이퍼파라미터 튜닝\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.01) # 학습률 크게 증가.\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0008)  # 학습률 크게 감소.\n",
    "\n",
    "# 7. 학습루프 생성.\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# 7.1. 데이터셋 및 데이터로더 생성\n",
    "# 정규화된 numpy 배열 데이터를 PyTorch의 Tensor로 변환.\n",
    "train_images_tensor = torch.from_numpy(train_images_normalized)\n",
    "train_labels_tensor = torch.from_numpy(train_labels).long()\n",
    "# TensorDataset은 이미지와 라벨 텐서를 묶어 데이터셋을 만듭니다.\n",
    "train_dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "# DataLoader는 학습 시 데이터를 배치(batch) 단위로 불러오는 역할을 합니다.\n",
    "# shuffle=True는 매 에포크마다 데이터를 무작위로 섞어 모델의 과적합을 방지합니다.\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "# 7.2. 모델을 장치로 이동\n",
    "# 모델을 CPU 또는 GPU/MPS로 옮겨줍니다.\n",
    "model.to(device)\n",
    "# 7.3. 학습 루프(Training Loop)\n",
    "# num_epochs = 5\n",
    "# 9.3. 에포크 수정\n",
    "num_epochs = 20\n",
    "print(\"Training starts...\")\n",
    "# 각 에포크의 시작에서 모델을 학습 모드로 설정합니다.\n",
    "# 이렇게 하면 드롭아웃 등 학습 시에만 필요한 기능들이 활성화됩니다.\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    # 데이터로더에서 이미지와 라벨을 배치 단위로 가져옵니다.\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        # 데이터를 설정한 장치(device)로 보냅니다.\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # 7.3.1 기울기 초기화\n",
    "        # 이전 배치 학습에서 계산된 기울기를 0으로 초기화합니다.\n",
    "        # 이 과정이 없으면 기울기가 계속 누적되어 학습이 이상해집니다.\n",
    "        optimizer.zero_grad()\n",
    "        # 7.3.2. 순전파(Foward Pass)\n",
    "        # 모델에 이미지 데이터를 넣어 예측값을 계산합니다.\n",
    "        outputs = model(images)\n",
    "        # 7.3.3. 손실 계산(Loss Calculation)\n",
    "        # 예측값과 실제 라벨을 비교해 손실(오차)을 계산\n",
    "        loss = loss_function(outputs, labels)\n",
    "        # 7.3.4. 역전파(Backward Pass)\n",
    "        # 손실을 기반으로 각 매개변수에 대한 기울기를 계산\n",
    "        loss.backward()\n",
    "        # 7.3.5. 가중치 업데이트(Weight Update)\n",
    "        # 계산된 기울기를 사용해 모델의 가중치를 업데이트\n",
    "        optimizer.step()\n",
    "        # 개별 배치 Loss 출력 (10회마다)\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}\"\n",
    "            )\n",
    "        # 누적 손실 확인\n",
    "        running_loss += loss.item()\n",
    "    # 에포크 평균 Loss 출력\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}\")\n",
    "    print(\"-\" * 60)  # 구분선\n",
    "print(\"Training finished!\")\n",
    "\n",
    "# 8. 모델 평가\n",
    "# 8.1. 모델을 평가 모드로 설정.\n",
    "# model.eval()은 학습 시에만 필요한 기능(예: Dropout, Batch Normalization)을 비활성화합니다.\n",
    "# 이렇게 해야 모델이 일관된 예측 결과를 내놓을 수 있습니다.\n",
    "model.eval()\n",
    "# 8.2. 기울기 계산 비활성화\n",
    "# torch.no_grad() 블록 안에서는 기울기 계산이 이루어지지 않습니다.\n",
    "# 평가 단계에서는 가중치를 업데이트할 필요가 없으므로, 메모리와 연산 속도를 절약할 수 있습니다.\n",
    "# 8.2.1. 테스트 데이터셋 및 데이터로더 생성\n",
    "# 테스트 이미지와 라벨을 PyTorch 텐서로 변환\n",
    "test_images_tensor = torch.from_numpy(test_images_normalized)\n",
    "test_labels_tensor = torch.from_numpy(test_labels).long()\n",
    "# TensorDataset으로 묶고 DataLoader를 생성\n",
    "# 평가 시에는 데이터 순서를 섞을 필요가 없으므로 suffle=False로 설정.\n",
    "test_dataset = TensorDataset(test_images_tensor, test_labels_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "# 8.2.2. 정확도(Accuracy) 계산을 위한 변수 초기화(기울기 계산 비활성화 블록)\n",
    "correct_predictions = 0\n",
    "total_samples = 0\n",
    "# 8.2.3. 테스트 데이터로 순전파 실행.\n",
    "# 테스트 데이터로더에서 배치 단위로 데이터를 가져옵니다.\n",
    "for images, labels in test_loader:\n",
    "    # 데이터와 라벨을 설정한 장치(device)로 보냅니다.\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    # 8.2.3.1. 순전파: 모델에 데이터를 넣어 예측값 얻음.\n",
    "    outputs = model(images)\n",
    "    # 8.2.3.2. 예측값 변환\n",
    "    # outputs은 각 클래스에 대한 점수입니다. 가장 높은 점수를 가진 클래스를 예측값으로 선택합니다.\n",
    "    # torch.max() 함수는 최댓값과 그 인덱스를 반환합니다. dim=1은 각 행(이미지)에서 최댓값을 찾으라는 의미입니다.\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    # 8.2.3.3. 정확한 예측 수 계산\n",
    "    # 총 샘플 수를 업데이트\n",
    "    total_samples += labels.size(0)\n",
    "    # 예측값과 실제 라벨이 일치하는 개수를 세어 누적\n",
    "    correct_predictions += (predicted.view(-1) == labels.view(-1)).sum().item()\n",
    "# 8.2.4. 정확도 계산 및 출력\n",
    "# (정확히 예측한 샘플 수) / (총 샘플 수)를 계산하여 정확도를 얻습니다.\n",
    "accuracy = 100 * correct_predictions / total_samples\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "print(\"Evaluation finished!\")\n",
    "# 8.2.5.1. 오차 행렬\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "model.eval()  # 모델을 평가 모드로 설정.\n",
    "# 8.2.5.2. 예측값과 실제 라벨 수집\n",
    "# 전체 테스트 데이터셋에 대한 예측값과 실제 라벨을 저장할 리스트를 만듦.\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "# 기울기 계산을 비활성화하고 평가를 진행.\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        # 데이터와 라벨을 장치로 보냅니다.\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # 순전파: 모델에 이미지를 넣어 예측값을 얻습니다.\n",
    "        outputs = model(images)\n",
    "        # 예측값 변환: 가장 높은 점수를 가진 클래스의 인덱스를 예측값으로 선택합니다.\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        # 텐서를 CPU로 옮겨 NumPy 배열로 변환하고 리스트에 추가합니다.\n",
    "        # Scikit-learn은 PyTorch 텐서 대신 NumPy 배열을 입력으로 받습니다.\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "# 8.2.5.3. 오차 행렬 생성\n",
    "# confusion_matrix 함수를 사용해 예측값과 실제 라벨로 오차 행렬을 만듭니다.\n",
    "# 오차 행렬은 Numpy 배열 형태로 반환됩니다.\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "print(\"오차 행렬 (Confusion Matrix):\")\n",
    "print(cm)\n",
    "# 8.2.5.4. 오차 행렬 시각화\n",
    "# Seaborn 라이브러리를 사용해 오차 행렬을 히트맵 형태로 시각화합니다.\n",
    "# fmt='d'는 값을 정수 형태로 표시하라는 의미입니다.\n",
    "# annot=True는 각 셀에 숫자를 표시하라는 의미입니다.\n",
    "plt.figure(figsize=(10, 8))\n",
    "tick_labels = [str(i) for i in range(10)]\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=tick_labels,\n",
    "    yticklabels=tick_labels,\n",
    ")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# 9. 성능 개선\n",
    "# 9.1 모델 구조 변경\n",
    "# 모델에 층을 추가.\n",
    "# ** 구현을 5.2. 모델 설정에서 수정.\n",
    "# 9.1.1. 첫 번째 층 뉴런 수 증가\n",
    "# 9.1.2. 새로운 중간 층을 추가하고 출력층을 3번째로 이동.\n",
    "# 9.2. 하이퍼파라미터 튜닝(학습률)\n",
    "# ** 구현을 6.4. 옵티마이저 정의를 수정."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a22aed8",
   "metadata": {},
   "source": [
    "1. 데이터 로드 및 전처리\n",
    "   - 정규화 (0~1)\n",
    "   - 채널 차원 추가 (60000, 1, 28, 28)\n",
    "\n",
    "2. CNN 모델 정의\n",
    "   - Conv1: 1→32, Pool1\n",
    "   - Conv2: 32→64, Pool2\n",
    "   - FC1: 3136→128\n",
    "   - FC2: 128→10\n",
    "\n",
    "3. 모델 컴파일\n",
    "   - Loss: CrossEntropyLoss\n",
    "   - Optimizer: Adam (lr=0.0008)\n",
    "\n",
    "4. 학습\n",
    "   - Epochs: 20\n",
    "   - Batch size: 64\n",
    "\n",
    "5. 평가\n",
    "   - 정확도: 91.84%\n",
    "   - 오차 행렬 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b555bac4",
   "metadata": {},
   "source": [
    "채널이 늘어난다고 하더라도 풀링을 진행하여 단순화가 진행되면 좀 더 복잡도 높은 내용을 학습시킬수가 없는거 아니야?\n",
    "\n",
    "와! 정말 날카로운 질문입니다! 🤯\n",
    "\n",
    "이건 CNN을 처음 배울 때 많은 사람들이 혼란스러워하는 **역설적인 부분**이에요!\n",
    "\n",
    "---\n",
    "\n",
    "## **역설처럼 보이는 상황**\n",
    "\n",
    "### **님의 의문:**\n",
    "\n",
    "> \"풀링으로 크기를 줄이면 (28×28 → 14×14 → 7×7) 정보가 줄어드는데, 어떻게 더 복잡한 내용을 학습할 수 있어?\"\n",
    "\n",
    "**직관적으로는 이상해 보입니다!** 🤔\n",
    "\n",
    "---\n",
    "\n",
    "## **핵심 개념: 무엇이 \"복잡도\"인가?**\n",
    "\n",
    "### **오해: 픽셀 개수 = 복잡도 ❌**\n",
    "\n",
    "```\n",
    "28×28 = 784 픽셀  → 단순하다?\n",
    "7×7 = 49 픽셀     → 복잡하다?\n",
    "```\n",
    "\n",
    "**이건 틀렸습니다!**\n",
    "\n",
    "---\n",
    "\n",
    "### **진실: 추상화 수준 = 복잡도 ✅**\n",
    "\n",
    "```\n",
    "낮은 추상화 (초기 레이어):\n",
    "- 픽셀 하나하나를 봄\n",
    "- \"이 픽셀이 밝다/어둡다\"\n",
    "- 간단한 정보, 많은 데이터\n",
    "\n",
    "높은 추상화 (후기 레이어):\n",
    "- 픽셀 조합의 의미를 봄\n",
    "- \"여기에 어깨선이 있다\"\n",
    "- 복잡한 정보, 적은 데이터\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **비유로 이해하기**\n",
    "\n",
    "### **책 읽기 비유:**\n",
    "\n",
    "**낮은 레벨 (글자):**\n",
    "```\n",
    "\"ㄱ\", \"ㅏ\", \"ㅁ\", \"ㅅ\", \"ㅏ\"\n",
    "→ 5개 요소 (많음)\n",
    "→ 간단한 정보 (단순함)\n",
    "```\n",
    "\n",
    "**높은 레벨 (단어):**\n",
    "```\n",
    "\"감사\"\n",
    "→ 1개 요소 (적음)\n",
    "→ 복잡한 정보 (의미 포함)\n",
    "```\n",
    "\n",
    "**더 높은 레벨 (문장):**\n",
    "```\n",
    "\"감사합니다\"\n",
    "→ 더 적은 요소\n",
    "→ 더 복잡한 의미 (예의, 감정 포함)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **CNN에서의 실제 과정**\n",
    "\n",
    "### **Conv1 + Pool1: 저수준 특징 추출**\n",
    "\n",
    "```python\n",
    "입력: (1, 28, 28) = 784개 픽셀 값\n",
    "# 각 픽셀: \"이 위치가 밝은가?\"\n",
    "\n",
    "↓ Conv1 (32 필터)\n",
    "\n",
    "(32, 28, 28) = 25,088개 값\n",
    "# 각 값: \"이 위치에 수평선이 있는가?\"\n",
    "#        \"이 위치에 수직선이 있는가?\"\n",
    "#        \"이 위치에 대각선이 있는가?\"\n",
    "# → 32가지 간단한 패턴 정보\n",
    "\n",
    "↓ Pool1\n",
    "\n",
    "(32, 14, 14) = 6,272개 값\n",
    "# \"이 영역에 수평선이 있는가?\" (위치 덜 중요)\n",
    "# → 공간 해상도는 낮지만 패턴 정보는 유지!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Conv2 + Pool2: 고수준 특징 추출**\n",
    "\n",
    "```python\n",
    "입력: (32, 14, 14)\n",
    "# 각 채널: 이미 \"선\", \"모서리\" 같은 패턴 정보\n",
    "\n",
    "↓ Conv2 (64 필터)\n",
    "\n",
    "(64, 14, 14)\n",
    "# 32개 저수준 패턴을 조합!\n",
    "# 필터 1: \"수평선 + 수직선\" → 직각 코너 감지\n",
    "# 필터 2: \"여러 곡선\" → 둥근 형태 감지\n",
    "# 필터 3: \"대각선 + 곡선\" → 어깨선 감지\n",
    "# → 64가지 복잡한 조합 패턴!\n",
    "\n",
    "↓ Pool2\n",
    "\n",
    "(64, 7, 7) = 3,136개 값\n",
    "# \"이 영역에 어깨선이 있는가?\"\n",
    "# \"이 영역에 목선이 있는가?\"\n",
    "# → 위치 정보는 줄지만, 의미적 정보는 더 풍부!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **핵심: 정보의 \"밀도\"가 증가한다**\n",
    "\n",
    "### **정보량 vs 정보 밀도**\n",
    "\n",
    "```\n",
    "초기 레이어:\n",
    "(1, 28, 28) = 784개\n",
    "- 정보량: 많음 (784개 값)\n",
    "- 정보 밀도: 낮음 (단순 밝기)\n",
    "- 의미: \"픽셀 하나하나의 밝기\"\n",
    "\n",
    "후기 레이어:\n",
    "(64, 7, 7) = 3,136개\n",
    "- 정보량: 더 많음! (3,136개 값)\n",
    "- 정보 밀도: 매우 높음 (추상화된 개념)\n",
    "- 의미: \"64가지 복잡한 패턴의 존재 여부\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **시각화: 레이어별 \"보는\" 것**\n",
    "\n",
    "### **입력 이미지: 티셔츠**\n",
    "\n",
    "```\n",
    "원본 픽셀: (1, 28, 28)\n",
    "[0, 0, 0, 45, 67, 89, ...]\n",
    "→ \"이 좌표의 밝기 값\"\n",
    "```\n",
    "\n",
    "### **Conv1 출력: (32, 28, 28)**\n",
    "\n",
    "```\n",
    "채널 1: 수평선 맵\n",
    "[0, 0, 0.8, 0, 0, ...]\n",
    "→ \"여기에 수평선이 강하게 나타남\"\n",
    "\n",
    "채널 2: 수직선 맵\n",
    "[0.9, 0, 0, 0, 0.7, ...]\n",
    "→ \"여기에 수직선이 강하게 나타남\"\n",
    "\n",
    "...32개 간단한 패턴 맵\n",
    "```\n",
    "\n",
    "### **Pool1 출력: (32, 14, 14)**\n",
    "\n",
    "```\n",
    "\"대략 이 영역에 수평선이 있음\" (위치 조금 모호)\n",
    "→ 세부 위치보다 \"존재 여부\"에 집중\n",
    "```\n",
    "\n",
    "### **Conv2 출력: (64, 14, 14)**\n",
    "\n",
    "```\n",
    "채널 1: 직각 코너 맵\n",
    "→ \"수평선 + 수직선 조합\"\n",
    "\n",
    "채널 5: 어깨 형태 맵\n",
    "→ \"특정 곡선 + 대각선 조합\"\n",
    "\n",
    "채널 20: 목선 형태 맵\n",
    "→ \"여러 패턴의 복잡한 조합\"\n",
    "\n",
    "...64개 복잡한 패턴 맵\n",
    "```\n",
    "\n",
    "### **Pool2 출력: (64, 7, 7)**\n",
    "\n",
    "```\n",
    "\"이 넓은 영역에 어깨 형태가 있음\"\n",
    "→ 정확한 위치는 모르지만\n",
    "→ \"어깨가 있다\"는 추상적 개념은 명확!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **왜 이게 가능한가?**\n",
    "\n",
    "### **1. 채널 증가가 정보 손실을 보상**\n",
    "\n",
    "```\n",
    "크기: 28×28 → 14×14 (÷4 감소)\n",
    "채널: 32 → 64 (×2 증가)\n",
    "\n",
    "총 값 개수:\n",
    "32 × 14 × 14 = 6,272\n",
    "64 × 14 × 14 = 12,544 (오히려 증가!)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. 추상화가 정보를 압축**\n",
    "\n",
    "```\n",
    "저수준:\n",
    "\"(10,15) 밝음, (10,16) 어두움, (10,17) 밝음...\"\n",
    "→ 수백 개 픽셀 정보 필요\n",
    "\n",
    "고수준:\n",
    "\"어깨선 있음\"\n",
    "→ 하나의 값으로 표현 가능\n",
    "```\n",
    "\n",
    "**비유:**\n",
    "- \"ㄱ,ㅏ,ㅁ,ㅅ,ㅏ,ㅎ,ㅏ,ㅂ,ㄴ,ㅣ,ㄷ,ㅏ\" (12개)\n",
    "- \"감사합니다\" (1개) ← 더 적지만 더 많은 의미!\n",
    "\n",
    "---\n",
    "\n",
    "## **실제 증거: 특징 맵 시각화**\n",
    "\n",
    "연구자들이 CNN 레이어를 시각화한 결과:\n",
    "\n",
    "### **Conv1 (초기):**\n",
    "- 간단한 엣지, 색상, 텍스처\n",
    "\n",
    "### **Conv2-3 (중간):**\n",
    "- 눈, 코, 귀 같은 부분적 특징\n",
    "\n",
    "### **Conv4-5 (후기):**\n",
    "- 얼굴 전체, 자동차 전체 같은 복잡한 객체\n",
    "- **픽셀은 적지만 더 복잡한 개념!**\n",
    "\n",
    "---\n",
    "\n",
    "## **핵심 정리**\n",
    "\n",
    "### **님의 질문:**\n",
    "> \"풀링으로 단순화되면 복잡한 내용 학습 불가 아니야?\"\n",
    "\n",
    "### **답변:**\n",
    "\n",
    "**❌ 오해:**\n",
    "- 픽셀 수 감소 = 정보 감소 = 복잡도 감소\n",
    "\n",
    "**✅ 진실:**\n",
    "- 픽셀 수 감소 = 공간 해상도 감소\n",
    "- 채널 수 증가 = 추상화 수준 증가\n",
    "- **결과: 더 복잡한 개념을 학습!**\n",
    "\n",
    "---\n",
    "\n",
    "### **비유 정리:**\n",
    "\n",
    "```\n",
    "초기: \"숲을 이루는 나무 한 그루 한 그루\"\n",
    "     → 많은 정보, 단순한 의미\n",
    "\n",
    "후기: \"이건 소나무 숲이다\"\n",
    "     → 적은 정보, 복잡한 의미\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **수학적 관점:**\n",
    "\n",
    "```\n",
    "정보량 = 값의 개수 × 각 값의 의미 복잡도\n",
    "\n",
    "초기: 784 × 1 (밝기) = 784 units\n",
    "후기: 3,136 × 100 (추상 개념) = 313,600 units\n",
    "\n",
    "→ 오히려 증가!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**정말 본질을 꿰뚫는 질문이었습니다!** 🎉\n",
    "\n",
    "이제 **풀링으로 크기는 줄지만, 추상화로 복잡도는 증가**한다는 걸 이해하셨나요?\n",
    "\n",
    "**또 궁금한 점 있으신가요?** 😊"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_study_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
